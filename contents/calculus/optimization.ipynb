{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T23:13:35.508052Z",
     "start_time": "2020-07-28T23:13:32.337498Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.dpi'] = 120\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "from functools import partial\n",
    "YouTubeVideo_formato = partial(YouTubeVideo, modestbranding=1, disablekb=0,\n",
    "                               width=640, height=360, autoplay=0, rel=0, showinfo=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización matemática\n",
    "\n",
    "La **optimización** es el procedimiento para:\n",
    "\n",
    "> Encontrar la mejor solución para un problema dentro de un conjunto de posibilidades\n",
    "\n",
    "La optimización es un área bastante estudiada de las matemáticas y algunos problemas de optimización requieren de soluciones muy específicas\n",
    "\n",
    "El objetivo de esta lección es entregar una revisión general a los problemas de optimización que podemos resolver usando las herramientas del módulo `scipy.optimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema general de optimización\n",
    "\n",
    "Usualmente un problema matemático de optimización se formula como\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_x &f(x) \\nonumber \\\\\n",
    "\\text{sujeto a: } & g_i(x) = 0, i=1,2\\ldots, I \\\\ \\nonumber \n",
    "& h_j(x) \\leq 0, j=1,2,\\ldots J \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "- $x \\in \\mathbb{R}^D$ se conoce como **variable o variables de decisión**\n",
    "- $f : \\mathbb{R}^D \\to \\mathbb{R}$ se conoce como **función objetivo**\n",
    "- $g_i : \\mathbb{R}^D \\to \\mathbb{R}$ se conocen como **restricciones de igualdad** \n",
    "- $h_j : \\mathbb{R} \\to \\mathbb{R}^H$ se conocen como **restricciones de desigualdad**\n",
    "\n",
    "El problema de optimización es entonces\n",
    "\n",
    "> La búsqueda de un valor extremo de la función objetivo dentro del espacio definido por las restricciones\n",
    "\n",
    "Un valor extremo puede ser un mínimo o un máximo. En un problema particular usualmente sólo nos interesa uno de estos casos. \n",
    "\n",
    "Dado que\n",
    "\n",
    "$$\n",
    "\\max_x f(\\vec x) \\equiv \\min_x - f(\\vec x),\n",
    "$$\n",
    "\n",
    "entonces hablaremos sólo de minimización sin pérdida de generalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconocer y clasificar problemas de optimización\n",
    "\n",
    "Estudiando algunas características del problema podemos seleccionar más fácilmente un algoritmo  apropiado para resolverlo. Algunas preguntas guía que podemos realizar son\n",
    "\n",
    "¿Es mi función objetivo de una variable ($D=1$) versus multi-variable ($D>1$)?\n",
    "\n",
    "> Esto define la dimensionalidad o escala del problema\n",
    "\n",
    "\n",
    "¿Existen restricciones de igualidad y/o desigualidad que debo cumplir?\n",
    "\n",
    "> Algunos algoritmos sólo pueden resolver problemas sin restricciones\n",
    "\n",
    "¿Es mi función objetivo lineal o no lineal con respecto a la entrada?\n",
    "\n",
    "> Si todas las funciones son lineales entonces se pueden usar técnicas de **programación lineal**. Esto problemas son más simples que los no lineales\n",
    "\n",
    "¿Es mi función objetivo convexa o no convexa?\n",
    "\n",
    "> Una función no-convexa (derecha) puede tener múltiples mínimos locales. Por el contrario una función convexa (izquierda) tiene un único mínimo\n",
    "\n",
    "<img src=\"../img/opti1.png\">\n",
    "\n",
    "¿Es mi función objetivo continua y diferenciable o no-diferenciable?\n",
    "\n",
    "> Muchos métodos se basan en el gradiente de la función de costo para encontrar la solución óptima. Si la función objetivo no es suave y no puede diferenciarse entonces no podemos usar dichos métodos\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolviendo un problema de optimización\n",
    "\n",
    "Consideremos primero el caso de una **función objetivo continua y derivable**. \n",
    "\n",
    "Veremos primero una solución analítica, luego una solución exhaustiva y finalmente una solución basada en métodos iterativos\n",
    "\n",
    "\n",
    "### Solución analítica\n",
    "\n",
    "La forma más clásica para obtener la solución en este caso es encontrar las raices (ceros) de la derivada/gradiente de $f$. Es decir\n",
    "\n",
    "$$\n",
    "\\nabla f (x^*) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_D} \\end{pmatrix} = \\vec 0\n",
    "$$\n",
    "\n",
    "Estas soluciones se conocen como **puntos estacionarios** de $f$, que incluyen los mínimos, máximos y puntos silla\n",
    "\n",
    "Luego si las segunda derivada o matriz Hessiana de $f$\n",
    "\n",
    "$$\n",
    "H_{ij}^f (x)  = \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} (x^*)\n",
    "$$\n",
    "\n",
    "es positiva o semi-definida positiva entonces $x^*$ es un **mínimo local**\n",
    "\n",
    "**Receta**\n",
    "\n",
    "1. Obtener $x^*$ tal que $\\nabla f (x^*)=0$\n",
    "1. Probar que es un mínimo el Hessiano\n",
    "\n",
    "**Limitación** \n",
    "\n",
    "Sólo es práctico si podemos despejar una expresión análitica de $x$ a partir de $\\nabla f (x^*)=0$. Esto se puede hacer algebraicamente o usando una librería de cálculo simbólico como [SimPy](https://www.sympy.org/en/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplos**\n",
    "\n",
    "Consideremos el siguiente problema\n",
    "\n",
    "$$\n",
    "\\min_x x^2 - 2x\n",
    "$$\n",
    "\n",
    "Igualando la primera derivada de la función objectivo a cero tenemos que $ 2x - 2 = 0$, es decir $x=1$ es un punto estacionario\n",
    "\n",
    "La segunda derivada es mayor que cero por lo tanto corresponde a un mínimo\n",
    "\n",
    "Considere ahora el siguiente problema no-convexo\n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 2x + 5 \\sin(2x)\n",
    "$$\n",
    "\n",
    "La derivada en este caso es\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 2x - 2 + 10 \\cos(2x) = 0\n",
    "$$\n",
    "\n",
    "En este caso no es posible despejar analiticamente $x$ sin hacer más simplificaciones o supuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda exhaustiva de la mejor solución\n",
    "\n",
    "Podemos encontrar la mejor solución probando una gran cantidad de \"soluciones candidatas\" de forma numérica y guardando la mejor. Esto se suele describir como un \"método de fuerza bruta\". \n",
    "\n",
    "**Receta**\n",
    "\n",
    "1. Definimos una grilla para nuestro espacio de parámetros (dominio y resolución)\n",
    "1. Para cada elemento de la grilla calculamos la función de costo\n",
    "1. Buscamos el elemento con menor función de costo\n",
    "\n",
    "**Ventaja** \n",
    "\n",
    "Si la resolución es lo suficientemente fina podemos encontrar el mínimo global del dominio aunque la función sea no-convexa\n",
    "\n",
    "**Desventaja** \n",
    "\n",
    "El costo computacional crece rapidamente con la dimensión de $x$, **explosión combinatorial**. Esto lo hace infactible en la mayoría de los casos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método iterativos\n",
    "\n",
    "En lugar de evaluar todo el espacio de posibilidades los métodos iterativos parten de una solución inicial y la refinan paso a paso. \n",
    "\n",
    "En cada paso los métodos iterativos buscan la dirección que más los acerque a la solución óptima\n",
    "\n",
    "A continuación veremos algunos métodos iterativos clásicos para funciones continuas y derivables\n",
    "\n",
    "\n",
    "**Método de Newton**\n",
    "\n",
    "Sea el valor actual de la variable de decisión $x_t$. Podemos escribir el valor que tendrá en el siguiente paso como\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t + \\Delta x\n",
    "$$\n",
    "\n",
    "Lo que queremos es encontrar el mejor $\\Delta x$ según nuestra función objetivo. \n",
    "\n",
    "Consideremos la aproximación de Taylor de segundo orden de $f$\n",
    "\n",
    "$$\n",
    "f(x_{t} + \\Delta x) \\approx f(x_t) + \\nabla f (x_t) \\Delta x + \\frac{1}{2} \\Delta x^T H_f (x_t) \\Delta x \n",
    "$$\n",
    "\n",
    "Si derivamos en función de $\\Delta x$ e igualamos a cero se tiene que\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla f (x_t)  +  H_f (x_t) \\Delta x &= 0 \\nonumber \\\\\n",
    "\\Delta x &= - [H_f (x_t)]^{-1}\\nabla f (x_t)  \\nonumber \\\\\n",
    "x_{t+1} &= x_{t} - [H_f (x_t)]^{-1}\\nabla f (x_t)  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Que corresponde a la regla iterativa de Newton. La regla está función del **Gradiente** y del **Hessiano** de $f$\n",
    "\n",
    "Notar que\n",
    "\n",
    "- La solución depende de $x_0$ el valor inicial\n",
    "- Al utilizar el método de Newton estamos suponiendo que la aproximación de segundo orden es suficiente para nuestro problema\n",
    "- Si nuestro modelo tiene $M$ parámetros el Hessiano será una matriz de $M\\times M$. Si $M$ es muy grande usar el Hessiano podría ser infactible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradiente descendente (GD)**\n",
    "\n",
    "Si el Hessiano es prohibitivo podemos usar una aproximación de primer orden de la regla de Newton. Esto resulta en el clásico método conocido como  **gradiente descendente**\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_{t} - \\eta \\nabla f (x_t)\n",
    "$$\n",
    "\n",
    "donde se reemplaza el Hessiano por una constante $\\eta$ llamado \"paso\" o \"tasa de aprendizaje\". \n",
    "\n",
    "Es sumamente importante calibrar adecuadamente este parámetro. A continuación veremos un ejemplo para ilustrar los comportamientos que del gradiente descedente ante distintas tasas de aprendizaje.\n",
    "\n",
    "Luego veremos que ocurre cuando optimizamos una función no convexa usando GD (o método de Newton)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo** Influencia de la tasa de aprendizaje en GD\n",
    "\n",
    "¿Cómo cambia la optimización con distintos $\\eta$?\n",
    "\n",
    "- Un $\\eta$ muy pequeño hará que la convergencia sea muy lenta\n",
    "- Un $\\eta$ muy grande hará que la optimización sea inestable o que diverja\n",
    "\n",
    "Consideremos nuevamente optimizar la función \n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 2x\n",
    "$$\n",
    "\n",
    "esta vez utilizando gradiente descedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:59:30.991523Z",
     "start_time": "2020-07-28T05:59:30.848217Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "fig, ax = plt.subplots(1, 3, figsize=(7, 2.5), tight_layout=True, sharey=True)\n",
    "\n",
    "x_plot = np.linspace(-4, 6, num=100)\n",
    "f = lambda x : x**2 - 2*x\n",
    "df = lambda x : 2*x - 2\n",
    "x = [np.random.rand(5)*10-4 for k in range(3)]\n",
    "etas = [0.011, 0.11, 1.1]\n",
    "sc = []\n",
    "\n",
    "for k in range(3):\n",
    "    ax[k].plot(x_plot, f(x_plot))\n",
    "    sc.append(ax[k].scatter(x[k], f(x[k]), c='k', s=100))\n",
    "    ax[k].set_ylabel(r'$f(x)$')\n",
    "    ax[k].set_xlabel(r'$x$')\n",
    "    ax[k].set_title(f'eta={etas[k]}')\n",
    "\n",
    "def update_plot(n):\n",
    "    for k in range(3):\n",
    "        x_ = sc[k].get_offsets()[:, 0]\n",
    "        x_ -= etas[k]*df(x_)\n",
    "        sc[k].set_offsets(np.c_[x_, f(x_)])\n",
    "    return sc[0], sc[1], sc[2]\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=20, interval=200, repeat=False, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo animado\n",
    "\n",
    "- Cada punto negro es una solución que parte de un valor inicial distinto\n",
    "- La linea azul es la función objetivo \n",
    "- Cada figura representa una tasa de aprendizaje distinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de 20 iteraciones podemos ver que\n",
    "\n",
    "- En el caso de la derecha las soluciones divergen\n",
    "- En el caso de la izquierda las soluciones no alcanzan a converger\n",
    "- En el caso central las soluciones convergen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** Optimización de una función no convexa con GD\n",
    "\n",
    "Consideremos la función no convexa\n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 2x + 5 \\sin(2x)\n",
    "$$\n",
    "\n",
    "la cual optimizaremos usando gradiente descedente. Recordemos que GD sólo puede garantizar que la solución es un punto estacionario. \n",
    "\n",
    "Si la función es no convexa entonces la solución dependerá fuertemente del valor inicial de $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T05:59:31.084827Z",
     "start_time": "2020-07-28T05:59:30.994033Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "x_plot = np.linspace(-4, 6, num=100)\n",
    "f = lambda x : x**2 - 2*x + 5*np.sin(2*x)\n",
    "df = lambda x : 2*x - 2 + 10*np.cos(2*x)\n",
    "x = np.linspace(-4, 6, num=10)\n",
    "eta = 0.005\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4), tight_layout=True)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "ax1 = fig.add_subplot(gs[0:2, :])\n",
    "ax2 = fig.add_subplot(gs[2, :])\n",
    "\n",
    "ax1.plot(x_plot, f(x_plot), label=r'$x^2-2x+5\\sin(2x)$')\n",
    "ax2.plot(x_plot, -df(x_plot))\n",
    "ax2.plot(x_plot, [0]*len(x_plot), 'r--')\n",
    "sc = ax1.scatter(x, f(x), s=100, c='k', label='soluciones')\n",
    "\n",
    "ax1.set_ylabel(r'$f(x)$')\n",
    "ax1.legend()\n",
    "ax2.set_xlabel(r'$x$')\n",
    "ax2.set_ylabel(r'$-\\nabla f(x)$')\n",
    "\n",
    "def update_plot(n):\n",
    "    ax1.set_title(f\"Iteración {n}/50\")\n",
    "    x = sc.get_offsets()[:, 0]\n",
    "    x -= eta*df(x)\n",
    "    sc.set_offsets(np.c_[x, f(x)])\n",
    "    return sc,\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=50, interval=200, repeat=False, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo animado\n",
    "\n",
    "- Cada punto negro es una solución que parte de un valor inicial distinto\n",
    "- El gráfico superior es la función objetivo \n",
    "- El gráfico inferior es el gradiente de al función objetivo y la linea punteada roja son los ceros de la derivada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de 50 iteraciones podemos ver como distintas soluciones iniciales resultan en distintos mínimos\n",
    "\n",
    "Una estrategia cuando se usa GD en funciones no-convexas es justamente utilizar y comparar varias condiciones iniciales distintas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#optimization-scipy-optimize)\n",
    "\n",
    "Podemos realizar optimización numérica usando el módulo `scipy.optimize`. La función principal de este módulo es `minimize` la cual engloba a una larga lista de optimizadores\n",
    "\n",
    "Sus argumentos principales son\n",
    "\n",
    "```python\n",
    "from scipy.optimize import minimize\n",
    "minimize(fun, # Función objetivo \n",
    "         x0, # Valor inicial de la variable de decisión\n",
    "         args=(), # Argumentos adicionales de fun\n",
    "         method=None, # El método de optimización a usar (más detalles a continuación)\n",
    "         jac=None, # Función que calcula la matriz de primeras derivadas (jacobiano)\n",
    "         bounds=None, # Secuencia de tuplas (min, max) con cotas para x \n",
    "         constraints=(), # Diccinario o lista de restricciones (más detalles a continuación)\n",
    "         tol=None, # Tolerancia para el término de la optimización\n",
    "         callback=None, # Una función que se ejecuta luego de cada iteración\n",
    "         options=None, # Diccionario con las opciones especificas para cada método\n",
    "         ...\n",
    "        )\n",
    "```\n",
    "\n",
    "La función objetivo debe estar definida de la siguiente forma\n",
    "\n",
    "```python\n",
    "def fun(x, *args):\n",
    "    ...\n",
    "    return f \n",
    "```\n",
    "\n",
    "donde `x` es la variable a optimizar y `f` debe ser un valor escalar flotante. Los argumentos adicionales a `x` se deben desempaquetar de la tupla `args`\n",
    "\n",
    "La función de primeras derivadas debe seguir una forma similar\n",
    "\n",
    "```python\n",
    "def jac(x, *args):\n",
    "    ...\n",
    "    return dx # Esto es un arreglo con la misma dimesión de x\n",
    "```\n",
    "\n",
    "donde `x` y `args` deben ser coincidir con `fun`. El argumento `jac` es opcional. Si no se especifica las derivadas se calcularán de forma numérica, lo cual es menos eficiente. Además recordar que no todos los métodos requieren de primeras derivadas\n",
    "\n",
    "La función `optimize` retorna un objeto de tipo [`OptimizeResult`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult), cuyos atributos más importantes son\n",
    "\n",
    "- `x`: Mejor valor encontrado de la variable de decisión\n",
    "- `fun`: Valor de la función objetivo en el óptimo encontrado\n",
    "- `jac`: Valor de la matriz de primeras derivadas en el óptimo encontrado\n",
    "- `success`: Booleano que indica si la optimización se llevó a cabo con exito\n",
    "- `message:` Mensaje indicando la razón de término, útil para debuggear\n",
    "\n",
    "A continuación describiremos algunos de los métodos disponibles a través del argumento `method` de `minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización sin restricciones \n",
    "\n",
    "Con estos métodos no se puede especificar el argumento `constraint` o `bounds`. Por ejemplo están\n",
    "\n",
    "- [`method=CG`](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-cg.html#optimize-minimize-cg): Gradiente conjugado. Es una versión de GD con tasa de aprendizaje adaptiva\n",
    "- [`method=BFGS`](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-bfgs.html#optimize-minimize-bfgs): Es un método de tipo [quasi-Newton](https://en.wikipedia.org/wiki/Quasi-Newton_method) con Hessiano inverso aproximado a cada paso. Es el método por defecto en optimize y es en general una buena opción\n",
    "\n",
    "Los cuales usan gradientes, ya sea numérico o especificado mediante el argumento `jac`. Si la derivada puede obtenerse analiticamente y es confiable los siguientes métodos tendrán un desempeño superior a las alternativas\n",
    "    \n",
    "Luego están\n",
    "\n",
    "- [`method=Nelder-Mead`](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html#optimize-minimize-neldermead): Es una heurística tipo simplex. [Animación que muestra su funcionamiento](https://www.youtube.com/watch?v=HUqLxHfxWqU)\n",
    "- [`method=Powell`](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-powell.html#optimize-minimize-powell): Algoritmo de búsqueda de linea siguiendo una dirección a la vez. [Animación que muestra su funcionamiento](https://www.youtube.com/watch?v=4TYJGihyuDg)\n",
    "\n",
    "Los cuales no usan gradientes. Estos métodos pueden usarse cuando la función objetivo es no-derivable o demasiado ruidosa para ser derivada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio práctico\n",
    "\n",
    "Sea la función del \"dromedario invertido\" definida como\n",
    "\n",
    "$$\n",
    "f(x, y) = (4 - 2.1 x^2 + \\frac{1}{3} x^4) x^2 + x y + 4 y^2 (y^2 - 1) \n",
    "$$\n",
    "\n",
    "Encuentre el mínimo usando `minimize`\n",
    "\n",
    "- Implemente la función de costo y su primera derivada\n",
    "- Considere las siguientes soluciones iniciales $[1, 1]$ y $[-1, -1]$\n",
    "- Muestre el mejor valor de $x$, el mejor valor de la función objetivo y el *status* de término\n",
    "- (Opcional) Muestre graficamente la función y las soluciones encontradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T00:53:00.213957Z",
     "start_time": "2020-07-29T00:53:00.208407Z"
    }
   },
   "source": [
    "**Solución paso a paso con comentarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T01:07:40.259804Z",
     "start_time": "2020-07-29T01:07:40.116114Z"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo_formato('rApw8Zhy1Kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con restricciones\n",
    "\n",
    "Con estos métodos se pueden incorporar restricciones al problema ya sea en forma de cotas para las variables o ecuaciones de igualdad/desigualdad que las variables deben cumplir\n",
    "\n",
    "- Las restricciones de igualdad deben ser siempre de la forma $g(x) = 0$\n",
    "- Las restricciones de desigualdad deben ser siempre de la forma $h(x) \\geq 0 $\n",
    "\n",
    "En la práctica las restricciones se entregan como una tupla en el argumento `constraint` de `method`. Cada restricción es un diccionario con las llaves `type` y `fun` para especificar el tipo (string `eq` o `ineq`) y la función, respectivamente. Opcionalmente se puede especificar `jac`, la matriz de primeras derivadas de `fun` y `arg` una tupla con argumentos adicionales para `fun` y `jac`\n",
    "\n",
    "Por ejemplo si tengo la siguiente restricción (de desigualdad)\n",
    "\n",
    "$$\n",
    "x^2 \\geq 1 + 2x\n",
    "$$\n",
    "\n",
    "la tengo que escribir como:\n",
    "\n",
    "```python\n",
    ">>> h1 = {'type': 'ineq', \n",
    "          'fun' : lambda x: x**2 - 2*x -1,\n",
    "          'jac' : lambda x: np.array([2*x - 2])}\n",
    "```\n",
    "\n",
    "Los métodos que permiten especificar restricciones son\n",
    "\n",
    "- `method=L-BFGS-B`: Similar a BFGS pero permite añadir cotas para la variable de decisión\n",
    "- `method=SLSQP`: *Sequential Least Squares Programming*. Este método acepta cotas, restricciones de igualdad y restricciones de desigualdad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio práctico\n",
    "\n",
    "Sea la siguiente función de costo con dos variables de decisión\n",
    "\n",
    "$$\n",
    "\\min f(x, y) = -(2xy+2x-x^2-2y^2) \n",
    "$$\n",
    "\n",
    "sujeta a \n",
    "\n",
    "$$\n",
    "x^3 - y = 0 ~\\wedge~y-(x-1)^4-2 \\geq 0 \n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "0.5\\leq x \\leq 1.5 ~\\wedge~ 1.5 \\leq y \\leq 2.5\n",
    "$$\n",
    "\n",
    "- Escriba la función de costo, restricciones y cotas\n",
    "- Muestre la solución del problema de optimización obtenida con BFGS (ignorando restricciones y cotas), L-BFGS-B (ignorando restricciones) y SLSQP. Use $x_0 = 0$ y $y_0 = 1$ como solución inicial\n",
    "- (Opcional) Muestre graficamente la solución del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución paso a paso con comentarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T01:26:41.616388Z",
     "start_time": "2020-07-29T01:26:41.356173Z"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo_formato('60nw7S7eo8c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/opti2.png\">\n",
    "\n",
    "En la gráfica\n",
    "- El gradiente de color es la función objetivo\n",
    "- La sombra rectangular son las cotas\n",
    "- La linea punteada es la restricción de igualdad\n",
    "- La linea de puntos es la restricción de desigualdad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de la lección\n",
    "\n",
    "En esta lección hemos aprendido a\n",
    "\n",
    "- Reconocer y diferenciar distintos problemas de optimización matemática\n",
    "- Resolver problemas de optimización matemática sin y con restricciones usando `scipy`\n",
    "    - Debemos escoger un optimizador apropiado en función del problema a resolver\n",
    "    - Si nuestro problema es no convexo es conveniente probar varias soluciones iniciales distintas\n",
    "    - Siempre debemos comprobar la convergencia de los algoritmos de optimización que usemos\n",
    "\n",
    "Si quieres profundizar en este temas sugiero revisar\n",
    "\n",
    "- [Comparativa detallada entre los distintos métodos de optimización](https://scipy-lectures.org/advanced/mathematical_optimization/index.html) \n",
    "- [Encontrando raices de una función con `scipy`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html#scipy.optimize.root)\n",
    "- [Problemas de programación lineal con `scipy`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html#scipy.optimize.linprog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
