{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación paralela en Python\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En lecciones anteriores hemos visto como ganar rendimiento en operaciones SIMD usando NumPy. Luego aprendimos a conectar con lenguajes de bajo nivel usando Cython.\n",
    "\n",
    "En este capítulo veremos una opción para ganar rendimiento en tareas limitados en CPU que sean \"separables\". \n",
    "\n",
    "Tarea separable\n",
    ": Tarea que puede dividirse en **subtareas independientes**. Es decir que una subtarea cualquiera no depende de ninguna otra subtarea\n",
    "\n",
    "Al ser independientes significa que podemos resolverlas **al mismo tiempo**, es decir resolver cada una sin esperar el resultado de los demás.\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Hoy en día incluso los CPU de sobremesa son en realidad **múltiples CPU** en un mismo chip.\n",
    "\n",
    ":::\n",
    "\n",
    "Es decir que podemos escribir programas que aprovechan los CPU multi-nucleo y así resolver problemas o tareas separables en un menor tiempo. Esto es lo que llamamos [**computación paralela**](https://computing.llnl.gov/tutorials/parallel_comp/#Whatis). \n",
    "\n",
    ":::{note}\n",
    "\n",
    "En la práctica muchos problemas de computación científica (modelamiento, simulación) son paralelizables o incluso \"masivamente paralelizables\".\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumiendo que el problema al que nos enfrentamos es limitado en CPU (*CPU-bound*) el primer paso es hacer *profiling* para encontrar los cuellos de botella. Luego de esto debemos estudiar las zonas críticas y detectar oportunidades para paralelizar.\n",
    "\n",
    "El objetivo es encontrar sectores del programa que sean separables. Algunas preguntas típicas que pueden servir para esto son:\n",
    "\n",
    "- ¿Existen ciclos `for` donde las iteraciones son independientes entre sí?\n",
    "- ¿Es posible descomponer la operación o los datos?\n",
    "- ¿Existe una estructura de tipo pipeline?\n",
    "\n",
    "Si alguna de estas respuestas es afirmativa entonces lo que resta es usar alguna herramienta de programación paralela para reescribir dicho sector del programa. A continuación veremos algunas herramientas para Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Global interpreter lock (GIL) de Python\n",
    "\n",
    "El manejo de memoria de CPython no es *thread-safe*. Por esta razón todo código escrito en Python está sujeto a un **[mutex](https://en.wikipedia.org/wiki/Lock_(computer_science))** que lo protege conocido como **Global Interpreter Lock (GIL)**.\n",
    "\n",
    "El [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) obliga a ejecutar solo un hilo de código Python a la vez. Además el código escrito en Python no tiene control sobre el GIL. Por esta razón no es directo ni fácil que un proceso Python puedo usar múltiples nucleos de CPU.\n",
    "\n",
    "En esta lección exploraremos dos alternativas generales:\n",
    "\n",
    "- **1:** Realizar cómputo paralelo con **múltiples hilos** que comparten memoria. Para esto usaremos `cython` para levantar el GIL y las directivas de `OpenMP` para implementar este tipo de paralelismo\n",
    "- **2:** Realizar cómputo paralelo con **multiples procesos** (fork). En este escenario los procesos tiene su propio espacio de memoria y su propio GIL, por lo que no es necesario usar `cython`. En general el overhead es mucho mayor que en el caso **1**. Usaremos la librería `ipyparallel` para implementar este tipo de  paralelismo\n",
    "\n",
    "\n",
    "Existe una tercera alternativa más accesible pero exclusiva para hacer **algebra lineal en paralelo** con NumPy:\n",
    "\n",
    "- **3:** Compilar NumPy contra una librería de álgebra lineal de alto rendimiento  como MKL, ATLAS, Openblas. Estas librerías usan código de bajo nivel que levanta el GIL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computación multi-hilo con Cython y OpenMP\n",
    "\n",
    "[OpenMP](https://www.openmp.org/) es una API multiplataforma para computación paralela en C, C++ y Fortran. Por ejemplo en C/C++ se puede escribir un `parallel for` usando directivas de compilador (pragma) de OpenMP como se muestran a continuación\n",
    "\n",
    "```c\n",
    "#pragma omp parallel for\n",
    "for (i = 0; i < N; i++)\n",
    "    a[i] = 2 * i;\n",
    "```\n",
    "\n",
    "Cython tiene un módulo llamado [`parallel`](http://docs.cython.org/en/latest/src/userguide/parallelism.html) que usa OpenMP como *backend*. Para ocupar OpenMP desde Cython es necesario:\n",
    "\n",
    "- Instalar OpenMP en el sistema (conda se puede encargar)\n",
    "- Compilar el código Cython con los siguientes *flags*: `--compile-args=-fopenmp --link-args=-fopenmp`\n",
    "\n",
    "El modulo provee tres funciones principales:\n",
    "\n",
    "- `parallel(num_threads=None)`: Para crear un contexto de cómputo paralelo\n",
    "- `threadid()`: Para obtener la id del hilo\n",
    "- [`prange(start, stop, step, nogil=False, schedule=None, chunksize=None, num_threads=None)`](https://cython.readthedocs.io/en/latest/src/userguide/parallelism.html#cython.parallel.prange): Un iterador similar `range` pero que implemente un ciclo `for` paralelo.\n",
    "\n",
    "También se pueden usar funciones de OpenMP importando\n",
    "\n",
    "```cython\n",
    "cimport openmp\n",
    "```\n",
    "\n",
    "El principal requisito es que las funciones paralelas deben liberar el GIL. En Cython podemos liberar el GIL en una sección de código o en una función con el `keyword` [`nogil`](http://docs.cython.org/en/latest/src/userguide/external_C_code.html#nogil)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** Cálculo paralelo del kernel Gaussiano entre dos vectores definido como \n",
    "\n",
    "$$\n",
    "e^{-\\gamma \\|x-y\\|^2}\n",
    "$$\n",
    "\n",
    "Escribamos un código en Cython de referencia y otro paralelo con OpenMP para calcular esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:00.472669Z",
     "start_time": "2020-08-25T02:51:00.078566Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:16.202797Z",
     "start_time": "2020-08-25T02:51:08.490156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython \n",
    "cimport cython\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double exp (double)\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_cython(double gamma, double [::1] x, double [::1] y, double [::1] z):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    for i in range(N):\n",
    "        z[i] = exp(-gamma*(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midamos el rendimiento de esta rutina sobre datos artificiales y comparémosla contra una versión vectorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:24.926543Z",
     "start_time": "2020-08-25T02:51:23.330689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 395 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "28.3 ms ± 658 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9593189292790054"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 10_000_000\n",
    "x = np.random.randn(N)\n",
    "y = np.random.randn(N)\n",
    "z = np.empty_like(x)\n",
    "\n",
    "# Versión numpy\n",
    "time_numpy = %timeit -r10 -n10 -o np.exp(-1*(x-y)**2) \n",
    "# Versión cython secuencial\n",
    "time_cython = %timeit -r10 -n10 -o suma_vectores_cython(1.0, x, y, z)\n",
    "time_numpy.average/time_cython.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra una versión paralela del código anterior. \n",
    "\n",
    "Los cambios principales son:\n",
    "\n",
    "- Se modifica la magia `%%cython` para compilar con OpenMP.\n",
    "- Agregamos `nogil` en las secciones paralelas. \n",
    "- Importamos `cython.parallel.prange` para reemplazar el `range` original. Configuramos la cantidad de hilos con el argumento `n_threads` de `prange`.\n",
    "\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Existen varios mecanismos para balancear la carga de trabajo de los hilos. Esto se especifica utilizando los argumentos `schedule` y `chunksize` de `prange`. En este caso ocuparemos un modo semi-automático llamado `guided`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:23.325460Z",
     "start_time": "2020-08-25T02:51:16.206111Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp \n",
    "cimport cython\n",
    "\n",
    "from cython.parallel cimport prange \n",
    "\n",
    "cdef extern from \"math.h\" nogil: # Liberamos el GIL\n",
    "    double exp (double)\n",
    "        \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_openmp(double gamma, double [::1] x, double [::1] y, double [::1] z, int n_threads=2):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    with nogil: # Liberamos el GIL\n",
    "        for i in prange(N, num_threads=n_threads, schedule='guided'): \n",
    "            z[i] = exp(-gamma*(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que el resultado es idéntico al de NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:27.711680Z",
     "start_time": "2020-08-25T02:51:27.586990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.empty_like(x)\n",
    "suma_vectores_openmp(1.0, x, y, z, 4)\n",
    "np.allclose(np.exp(-1.*(x-y)**2), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midamos el rendimiento en función del número de hilos utilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5 ms ± 257 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Speed-up 2 nucleos: 1.9566\n",
      "7.73 ms ± 160 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Speed-up 4 nucleos: 3.6625\n",
      "7.84 ms ± 223 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Speed-up 8 nucleos: 3.6100\n"
     ]
    }
   ],
   "source": [
    "for n_cores in [2, 4, 8]:\n",
    "    time_cython_openmp = %timeit -r10 -n10 -o suma_vectores_openmp(1.0, x, y, z, n_cores)\n",
    "    print(f\"Speed-up {n_cores} nucleos: {time_cython.average/time_cython_openmp.average:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{caution}\n",
    "\n",
    "Más hilos no significa necesariamente mayor speed-up. Dividir el trabajo incurre en un overhead. Mientras más dividamos mayor es el overhead. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computación multi-proceso con IPython: *ipyparallel*\n",
    "\n",
    "[ipyparallel](https://ipyparallel.readthedocs.io/en/latest/) es un paquete independiente pero complementario de IPython para hacer computación multi-proceso.\n",
    "\n",
    "**Instalación con conda**\n",
    "\n",
    "```bash\n",
    "conda install ipyparallel\n",
    "```\n",
    "\n",
    "Lo anterior debería instalar en su ambiente los ejecutables  `ipcluster`, `ipcontroller` e `ipengine`. Adicionalmente se crea una pestaña llamada \"Ipython clusters\" en la interfaz de jupyter como muestra la siguiente captura:\n",
    "\n",
    "<img src=\"img/ipyparallel1.png\" width=\"400\">\n",
    "\n",
    "Si la interfaz no se instaló de forma automática utilice el comando:\n",
    "\n",
    "```bash\n",
    "ipcluster nbextension enable\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Conceptos y uso básico**\n",
    "\n",
    "*ipyparallel* considera varios elementos, los más importantes son:\n",
    "\n",
    "- *Engine*: Es el encargado de correr código. Es una extensión del kernel de IPython\n",
    "- *Controller*: Es una interfaz para comunicarnos con el/los engine/s. La conexión se hace a través del objeto `Client`\n",
    "\n",
    "Para iniciar un controlador de forma automática podemos abrir un terminal y escribir\n",
    "\n",
    "```bash\n",
    "ipcluster start -n 4\n",
    "```\n",
    "    \n",
    "o utilizar los controles que se encuentran en la pestaña \"IPython clusters\"\n",
    "\n",
    "<img src=\"img/ipyparallel2.png\" width=\"700\">\n",
    "\n",
    "Con esto hemos creado un controlador y cuatro engines, todos en nuestro ambiente local (localhost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:18.447676Z",
     "start_time": "2020-08-25T02:53:18.424839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos ipyparallel\n",
    "import ipyparallel as ipp\n",
    "# Creamos la clase cliente\n",
    "rc = ipp.Client()\n",
    "# Verificamos que se hayan iniciado nuestro engines\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada engine tiene una id asociada. Para enviarle trabajo a los engines debemos crear una intefaz llamada [`View`](https://ipyparallel.readthedocs.io/en/latest/details.html#views).\n",
    "\n",
    "Existen dos tipos de `View`: [*Direct*](https://ipyparallel.readthedocs.io/en/latest/direct.html#) y [*Task*](https://ipyparallel.readthedocs.io/en/latest/task.html#):\n",
    "\n",
    "- La primera es controlada de forma explicita por el usuario\n",
    "- La segunda es controlada por el sistema para *balancear la carga*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviando trabajos usando interfaz Directa\n",
    "\n",
    "Una `View` de tipo *Direct* requiere que el usuario especifique los *engines* que va a usar. Esto se hace de forma similar a los *slices* en listas/ndarray.\n",
    "\n",
    "Por ejemplo para crear una interfaz que utilice todas las engines, usamos `rc[:]`. En cambio si sólo queremos utilizar las dos primeras engines, usamos `rc[:2]`.\n",
    "\n",
    "La vista puede crearse como bloqueante o no bloqueante (asíncrona) modificando el atributo booleano `block`. Una vista \"bloqueante\" espera a que el resultado de todos los engines sean retornado para devolver el control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:22.963090Z",
     "start_time": "2020-08-25T02:53:22.950721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una view con\n",
    "dview = rc[:]\n",
    "# Por defecto es asíncrono (no bloqueante)\n",
    "dview.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos cambiarlo a ejecución síncrona (bloqueando) con\n",
    "dview.block = True\n",
    "dview.block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los trabajos se envían utilizando las funciones de la `View` directa:\n",
    "\n",
    "- `apply`, `apply_sync`, `apply_async`: Ejecutan una función con argumentos\n",
    "- `map`, `map_sync`, `map_async`: Ejecutan una función sobre una secuencia\n",
    "    \n",
    "Los apellidos `sync`  y `async` cambian el flag del view momentaneamente:\n",
    "\n",
    "- Cuando trabajamos en forma síncrona el resultado retorna al final de la ejecuación\n",
    "- Cuando trabajamos de forma asíncrona se retorna un objeto [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult) que puede ser consultado más tarde por el resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de Python en paralelo con `apply`\n",
    "\n",
    "Sea una función `foo` podemos ejecutarla en todos los engines con \n",
    "\n",
    "```python\n",
    "rc[:].apply(foo, *args, **kwargs)\n",
    "```\n",
    "    \n",
    "En el siguiente ejemplo se ejecuta una función anónima en todos los engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.128480Z",
     "start_time": "2020-08-25T02:53:24.918389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola Mundo', 'Hola Mundo', 'Hola Mundo', 'Hola Mundo']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.apply(lambda x, y: x+\" \"+y, x=\"Hola\", y=\"Mundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compartiendo módulos y datos con los engines\n",
    "\n",
    "Es importante tener claro que, al contrario del paralelismo multi-hilo, los procesos en los engines no comparten memoria y no ven las variables de nuestro entorno local.\n",
    "\n",
    "Por ejemplo si queremos usar una función del módulo `os`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.792436Z",
     "start_time": "2020-08-25T02:53:25.751401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[501328, 501331, 501334, 501341]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os # Este import no lo ven los engines\n",
    "\n",
    "def funcion():\n",
    "    import os # Este si\n",
    "    return os.getpid() \n",
    "\n",
    "# Cada uno tiene un pid distinto\n",
    "dview.apply(funcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible precargar un módulo en todos los engines con la función `sync_imports()`. Los módulos cargados persisten en el entorno de los engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:26.376589Z",
     "start_time": "2020-08-25T02:53:26.302002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing os on engine(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[501328, 501331, 501334, 501341]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with dview.sync_imports(local=True): \n",
    "    import os\n",
    "# El módulo quedará importado también en nuestro ambiente local\n",
    "\n",
    "# Ahora ya no necesitamos importar os\n",
    "def funcion2(): \n",
    "    return os.getpid() \n",
    "\n",
    "dview.apply(funcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos limpiar las variables y módulos de los engines podemos usar el método con `clear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:27.265444Z",
     "start_time": "2020-08-25T02:53:26.990920Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dview.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora ejecutamos \n",
    "\n",
    "```\n",
    "dview.apply(funcion2)\n",
    "```\n",
    "\n",
    "Nos retornaría una excepción\n",
    "\n",
    "```\n",
    "NameError: name 'os' is not defined\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traspasando datos a todos los engines\n",
    "\n",
    "Para enviar un objeto de Python que hayamos definido en el ambiente local podemos usar la función `push`. \n",
    "\n",
    ":::{important}\n",
    "\n",
    "El objeto tiene que ser un diccionario.\n",
    "\n",
    ":::\n",
    "\n",
    "También podemos usar `pull` si queremos extraer una variable remota. Ambas funciones tienen un argumento llamado `targets` que permite apuntar los objetos a un subconjunto de *engines*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:47.620805Z",
     "start_time": "2020-08-25T02:53:47.536661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000, 10000, 10000, 10000]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 100 # Esto no existe dentro de los engines\n",
    "\n",
    "dview.push({'a': a}) # Ahora está en todos los engines\n",
    "\n",
    "def funcion3(): \n",
    "    return a**2\n",
    "\n",
    "dview.apply(funcion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Digamos que quiero recuperar la variable 'a' pero sólo de los dos primeros engines\n",
    "dview.pull('a', targets=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuyendo datos a los engines\n",
    "\n",
    "Si queremos distribuir datos en los engines podemos usar `scatter`. Esto sirve por ejemplo para procesar elementos de una lista en paralelo. \n",
    "\n",
    "La función `scatter` recibe un string con el nombre de la variable (tal como lo recibirá cada proceso) y un arreglo con los valores de la variable.\n",
    "\n",
    "Para recuperar resultados a partir de los engine se utiliza la función `gather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:50.088066Z",
     "start_time": "2020-08-25T02:53:49.992261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 4]), array([ 9, 16, 25]), array([36, 49]), array([64, 81])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Una lista con 7 elementos que será distribuida en los 4 engines usando scatter\n",
    "dview.scatter('c', np.array(range(10)))\n",
    "\n",
    "def funcion3(): \n",
    "    global y # Creo una variable en el workspace del engine\n",
    "    y = c**2 # Le doy un valor\n",
    "    return y\n",
    "\n",
    "display(dview.apply(funcion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recuperamos la salida con gather\n",
    "display(dview.gather('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible distribuir arreglos de NumPy usando `scatter`.\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "Los arreglos de NumPy no se copian, se traspasan *read-only*.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:51.158733Z",
     "start_time": "2020-08-25T02:53:51.084036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 100), (25, 100), (25, 100), (25, 100)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = np.random.randn(100, 100)\n",
    "dview.scatter('x', datos)\n",
    "\n",
    "def funcion4(): \n",
    "    # data[0, 0] = 0 # No podemos modificar los valores!\n",
    "    return x.shape\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "dview.apply(funcion4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos hacer modificaciones de los arreglos tenemos que hacer una copia local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.144846Z",
     "start_time": "2020-08-25T02:53:51.994725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datos = np.random.randn(1000, 1000)\n",
    "dview.scatter('x', datos)\n",
    "\n",
    "def funcion5(): \n",
    "    global x\n",
    "    if not x.flags.writeable:\n",
    "        x = x.copy()\n",
    "    x[0, 0] = 0 # No podemos hacer esto!\n",
    "    return x\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "datos = np.concatenate(dview.apply(funcion5))\n",
    "\n",
    "# Se modificaron los datos originales\n",
    "display(datos[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómputo paralelo con `map`\n",
    "\n",
    "La función *built-in* `map` de Python aplica una función sobre una secuencia de datos uno por uno. En general, si vemos un `map` en nuestro código, paralelizarlo es muy sencillo.\n",
    "\n",
    "La librería `ipyparallel` provee una versión paralela de [`map`](https://ipyparallel.readthedocs.io/en/latest/api/ipyparallel.html#ipyparallel.DirectView.map) que se ocupa sobre una vista:\n",
    "\n",
    "```python\n",
    "rc[:].map(f, *sequences, block=self.block)\n",
    "```   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.829710Z",
     "start_time": "2020-08-25T02:53:52.781655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map de Python\n",
    "resultado_serial = list(map(lambda x: x, range(32)))\n",
    "\n",
    "# Map de ipyparallel\n",
    "resultado_paralelo = dview.map(lambda x: x, range(32))\n",
    "\n",
    "# Resultados\n",
    "np.allclose(resultado_serial, resultado_paralelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entregar iteradores para más de un argumento. Si los iteradores no son del mismo largo, terminará con el iterador más corto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:53.747341Z",
     "start_time": "2020-08-25T02:53:53.695708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9, 12, 15, 18, 21, 24, 27]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.map(lambda x, y, z: x + y + z, range(10), range(10), range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos una función con algunos argumentos escalares (no iterables) podemos usar [`partial`](https://docs.python.org/3/library/functools.html#functools.partial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:54.464361Z",
     "start_time": "2020-08-25T02:53:54.410831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1406543678460891e-07,\n",
       " 0.9997142179608428,\n",
       " 6.583814271790809e-05,\n",
       " 0.009550572752754302,\n",
       " 0.010194352228301411,\n",
       " 0.0017683468588368396,\n",
       " 1.1531198228713008e-15,\n",
       " 0.03617615221712183,\n",
       " 0.6076451926216965,\n",
       " 0.24742410433887654]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def function_args(x, y, gamma=1):\n",
    "    import numpy as np\n",
    "    return np.exp(-gamma*(x-y)**2)\n",
    "\n",
    "dview.map(partial(function_args, gamma=2), np.random.randn(10), np.random.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones remotas y paralelas con decoradores\n",
    "\n",
    "Podemos crear una función que es siempre ejecutada por los engines usando el decorador `remote`. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:55.347819Z",
     "start_time": "2020-08-25T02:53:55.302810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[501328, 501331, 501334, 501341]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dview.remote(block=True)\n",
    "def funcion():\n",
    "    import os\n",
    "    return os.getpid()\n",
    "\n",
    "funcion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función se ejecutó en los cuatro engines sin llamar a `dview.apply` o `dview.map` explicitamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, si tenemos una función que trabaja sobre un arreglo de forma *element-wise* podemos usar el decorador `parallel` para distribuir su carga a los engines. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:56.265784Z",
     "start_time": "2020-08-25T02:53:56.223207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 3), range(3, 6), range(6, 8), range(8, 10)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dview.parallel(block = True)\n",
    "def funcion(x):\n",
    "    return x\n",
    "\n",
    "# Los datos se particionan en 4 grupos (uno por engine)\n",
    "# Los grupos no son todos del mismo tamaño\n",
    "funcion(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden usar arreglos de numpy como muestra el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:57.585941Z",
     "start_time": "2020-08-25T02:53:56.868296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.random((1000, 1000))\n",
    "\n",
    "@dview.parallel(block=True)\n",
    "def pmul(A,B):\n",
    "    return A*B\n",
    "\n",
    "(A*A == pmul(A,A)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado asíncronos\n",
    "\n",
    "El resultado asíncrono es un objeto de clase [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult). Sus funciones más relevantes son\n",
    "\n",
    "- `ready` : Retorna un booleano con el estado de la tarea\n",
    "- `get` : Retorna el resultado\n",
    "\n",
    "Así se lanza una tarea asíncrona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:58.322094Z",
     "start_time": "2020-08-25T02:53:58.263465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_async = dview.map_async(lambda x: x**2, range(10))\n",
    "# ¿Está listo mi tarea?\n",
    "res_async.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    # Puedo hacer cómputo aquí mientras espero que termine mi tarea\n",
    "    if res_async.ready():\n",
    "        # Recupero el resultado\n",
    "        res = res_async.get()\n",
    "        break\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "\n",
    "Otras funcionalidades de ipyparallel no vistas en esta lección:\n",
    "\n",
    "- [Magias de ipyparallel](https://ipyparallel.readthedocs.io/en/latest/magics.html)\n",
    "- Balance de carga automático en ipyparallel con la [interfaz Task](https://ipyparallel.readthedocs.io/en/latest/task.html#)\n",
    "- [Dependencias entre procesos paralelos](https://ipyparallel.readthedocs.io/en/latest/dag_dependencies.html)\n",
    "- **Computación distribuida** en base a [MPI](https://ipyparallel.readthedocs.io/en/latest/mpi.html)  usando [`ipengine` e `ipcontroller`](https://ipyparallel.readthedocs.io/en/latest/process.html#using-the-ipcontroller-and-ipengine-commands)\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Computación distribuida en base a framework [Ray](https://www.ray.io/) en [ambiente local](https://github.com/magister-informatica-uach/hpc-tools-course/blob/main/activities/week7/homework.md) y [en la nube](https://github.com/magister-informatica-uach/hpc-tools-course/blob/main/activities/week8/homework.md)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
