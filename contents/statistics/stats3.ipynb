{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T18:29:11.834669Z",
     "start_time": "2020-07-23T18:29:10.986816Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.dpi'] = 120\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "from functools import partial\n",
    "YouTubeVideo_formato = partial(YouTubeVideo, modestbranding=1, disablekb=0,\n",
    "                               width=640, height=360, autoplay=0, rel=0, showinfo=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística inferencial: Ajuste de Modelos\n",
    "\n",
    "La inferencia busca\n",
    "\n",
    "> Extraer **conclusiones** a partir de **hechos u observaciones** a través de un **método o premisa**\n",
    "\n",
    "En el caso particular de la **inferencia estadística** podemos realizar las siguientes asociaciones\n",
    "\n",
    "- Hechos: Datos\n",
    "- Premisa: Modelo probabilístico\n",
    "- Conclusión: Una cantidad no observada que es interesante\n",
    "\n",
    "Y lo que buscamos es\n",
    "\n",
    "> Cuantificar la incerteza de la conclusión dado los datos y el modelo \n",
    "\n",
    "La inferencia estadística puede dividirse en los siguientes tres niveles\n",
    "\n",
    "1. Ajustar un modelo a nuestros datos\n",
    "1. Verificar que el modelo sea confiable\n",
    "1. Responder una pregunta usando el modelo\n",
    "\n",
    "En las lecciones que siguen estudiaremos las herramientas más utilizadas asociadas a cada uno de estos niveles\n",
    "\n",
    "1. **Estimador de máxima verosimilitud**\n",
    "1. **Bondad de ajuste** e **Intervalos de confianza**\n",
    "1. **Test de hipótesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de modelos: Estimación de máxima verosimilitud\n",
    "\n",
    "En este nivel de inferencia se busca **ajustar** un modelo teórico sobre nuestros datos. En esta lección nos enfocaremos en **modelos de tipo parámetrico**. Un modelo parámetrico es aquel donde **se explicita una distribución de probabilidad**.  \n",
    "\n",
    "Recordemos que una distribución tiene **parámetros**. Por ejemplo la distribución Gaussiana (univariada) se describe por su media $\\mu$ y su varianza $\\sigma^2$. Luego ajustar una distribución Gaussiana corresponde a encontrar el valor de $\\mu$ y $\\sigma$ que hace que el modelo se parezca lo más posible a la distribución empírica de los datos.\n",
    "\n",
    "A continuación veremos los pasos necesarios para ajustar una distribución a nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué distribución ajustar?\n",
    "\n",
    "Antes de ajustar debemos realizar un supuesto sobre la distribución para nuestro modelo. En general podemos ajustar cualquier distribución pero un mal supuesto podría invalidar nuestra inferencia\n",
    "\n",
    "Podemos usar las herramientas de **estadística descriptiva** para estudiar nuestros datos y tomar esta decisión de manera informada\n",
    "\n",
    "En el siguiente ejemplo, un histograma de los datos revela que un modelo gaussiano no es una buena decisión \n",
    "\n",
    "<img src=\"../img/stats6.png\">\n",
    "\n",
    "¿Por qué? La distribución empírica es claramente asimétrica, su cola derecha es más pesada que su cola izquierda. La distribución Gaussiana es simétrica por lo tanto no es apropiada en este caso ¿Qué distribución podría ser más apropiada?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo ajustar mi modelo? Estimación de máxima verosimilitud\n",
    "\n",
    "A continuación describiremos un procedimiento para ajustar modelos paramétricos llamado *maximum likelihood estimation* (MLE)\n",
    "\n",
    "Sea un conjunto de datos $\\{x_1, x_2, \\ldots, x_N\\}$\n",
    "\n",
    "**Supuesto 1** Los datos siguen el modelo $f(x;\\theta)$ donde $f(\\cdot)$ es una distribución y $\\theta$ son sus parámetros\n",
    "\n",
    "$$\n",
    "f(x_1, x_2, \\ldots, x_N |\\theta)\n",
    "$$\n",
    "\n",
    "**Supuesto 2** Las observaciones son independientes e idénticamente distribuidas (iid)\n",
    "\n",
    "- Si dos variables son independientes se cumple que $P(x, y) = P(x)P(y)$\n",
    "- Si son además idénticamente distribuidas entonces tienen **la misma distribución y parámetros**\n",
    "\n",
    "Usando esto podemos escribir\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x_1, x_2, \\ldots, x_N |\\theta) &= f(x_1|\\theta) f(x_2|\\theta) \\ldots f(x_N|\\theta) \\nonumber \\\\\n",
    "& = \\prod_{i=1}^N f(x_i|\\theta) \\nonumber \\\\\n",
    "& = \\mathcal{L}(\\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $\\mathcal{L}(\\theta)$ se conoce como la verosimilitud o probabilidad inversa de $\\theta$ \n",
    "\n",
    "Si consideramos que los datos son fijos podemos buscar el valor de $\\theta$ de máxima verosimilitud\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\mathcal{L}(\\theta) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log \\mathcal{L}(\\theta) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log f(x_i|\\theta) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "El segundo paso es valido por que el máximo de $g(x)$ y $\\log(g(x))$ es el mismo. El logaritmo es monoticamente creciente. Además aplicar el logaritmo es muy conveniente ya que convierte la multiplicatoria en una sumatoria. \n",
    "\n",
    "Ahora sólo falta encontrar el máximo. Podemos hacerlo\n",
    "\n",
    "- Analíticamente, derivando con respecto a $\\theta$ e igualando a cero\n",
    "- Usando técnicas de optimización iterativas como gradiente descedente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** La pesa defectuosa\n",
    "\n",
    "<img src=\"../img/garfield.png\" width=\"250\">\n",
    "\n",
    "Su profesor quiere medir su peso pero sospecha que su pesa está defectuosa. Para comprobarlo mide su peso $N$ veces obteniendo un conjunto de observaciones $\\{x_i\\}$. ¿Es posible obtener un estimador del peso real $\\hat x$ a partir de estas observaciones?\n",
    "\n",
    "Modelaremos las observaciones como\n",
    "\n",
    "$$\n",
    "x_i = \\hat x + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "donde $\\varepsilon_i$ corresponde al ruido o error del instrumento y asumiremos que $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2)$, es decir que el ruido es **independiente** y **Gaussiano** con media cero y **varianza** $\\sigma_\\varepsilon^2$ **conocida**\n",
    "\n",
    "Entonces la distribución de $x_i$ es\n",
    "\n",
    "$$\n",
    "f(x_i|\\hat x) = \\mathcal{N}(\\hat x, \\sigma_\\varepsilon^2)\n",
    "$$\n",
    "\n",
    "Para encontrar $\\hat x$, primero escribimos el logaritmo de la **verosimilitud**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\mathcal{L}(\\hat x) &=  \\sum_{i=1}^N \\log f(x_i|\\hat x) \\nonumber \\\\\n",
    "&= \\sum_{i=1}^N  \\log \\frac{1}{\\sqrt{2\\pi\\sigma_\\varepsilon^2}}  \\exp \\left ( - \\frac{1}{2\\sigma_\\varepsilon^2} (x_i - \\hat x)^2 \\right)  \\nonumber \\\\\n",
    "&= -\\frac{N}{2}\\log(2\\pi\\sigma_\\varepsilon^2)  - \\frac{1}{2\\sigma_\\varepsilon^2}  \\sum_{i=1}^N  (x_i - \\hat x)^2  \\nonumber\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego debemos resolver\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\log \\mathcal{L}(\\theta) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta - \\frac{1}{2\\sigma_\\varepsilon^2}  \\sum_{i=1}^N  (x_i - \\hat x)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde podemos ignorar el primer término de la verosimilitud ya que no depende de $\\theta$. Para encontrar el máximo derivamos la expresión anterior e igualamos a cero \n",
    "\n",
    "$$\n",
    "-\\frac{1}{2\\sigma_\\varepsilon^2} \\sum_{i=1}^N 2(x_i - \\hat x ) = 0.\n",
    "$$\n",
    "\n",
    "Finalmente si despejamos llegamos a que\n",
    "\n",
    "$$\n",
    "\\hat x = \\frac{1}{N} \\sum_{i=1}^N x_i,\n",
    "$$\n",
    "\n",
    "que se conoce como el estimador de máxima verosimilitud **para la media de una Gaussiana**\n",
    "\n",
    "Recordemos que podemos comprobar que es un máximo utilizando la segunda derivada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación MLE con `scipy`\n",
    "\n",
    "Como vimos en la lección anterior el módulo [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) provee de un gran número de distribuciones teóricas organizadas como \n",
    "\n",
    "- continuas de una variable\n",
    "- discretas de una variable\n",
    "- multivariadas\n",
    "\n",
    "Las distribuciones comparten muchos de sus métodos, a continuación revisaremos los más importantes. A modo de ejemplo consideremos la distribución Gaussiana (Normal)\n",
    "\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "dist = norm() # Esto crea una Gaussiana con media 0 y desviación estándar (std) 1\n",
    "dist = norm(loc=2, scale=2) # Esto crea una Gaussiana con media 2 y std 2\n",
    "```\n",
    "\n",
    "**Crear una muestra aleatoria con `rvs`**\n",
    "\n",
    "Luego de crear un objeto distribución podemos obtener una muestra aleatoria usando el método el atributo `rvs` \n",
    "\n",
    "```python\n",
    "dist = norm(loc=2, scale=2)\n",
    "dist.rvs(size=10, # Cantidad de números aleatorios generados\n",
    "         random_state=None #Semilla aleatoria\n",
    "        )\n",
    "```\n",
    "\n",
    "Esto retorna un arreglo de 10 números generados aleatoriamente a partir de `dist`\n",
    "\n",
    "**Evaluar la función de densidad de probabilidad** \n",
    "\n",
    "La función de densidad de la Gaussiana es\n",
    "\n",
    "$$\n",
    "f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left( -\\frac{1}{2\\sigma^2} (x-\\mu)^2 \\right) \n",
    "$$\n",
    "\n",
    "La densidad de un objeto distribución continuo puede obtenerse con el método `pdf` el cual es función de `x`\n",
    "\n",
    "\n",
    "```python\n",
    "dist = norm(loc=2, scale=2)\n",
    "p = dist.pdf(x # Un ndrray que representa x en la ecuación superior\n",
    "            )\n",
    "plt.plot(x, p) # Luego podemos graficar la fdp\n",
    "```\n",
    "\n",
    "De forma equivalente, si deseamos la función de densidad acumulada usamos el método `cdf`\n",
    "\n",
    "Para objetos distribución discretos debemos usar el atributo `pmf` \n",
    "\n",
    "\n",
    "**Ajustar los parámetros con MLE**\n",
    "\n",
    "Para hacer el ajuste se usa el método `fit`\n",
    "\n",
    "```python \n",
    "params = norm.fit(data # Un ndarray con los datos\n",
    "                 ) \n",
    "```\n",
    "\n",
    "En el caso de la Gaussiana el vector `params` tiene dos componentes `loc` y `scale`. La cantidad de parámetros depende de la distribución que estemos ajustando. También es importante notar que para ajustar se usa `norm` (clase abstracta) y no `norm()` (instancia)\n",
    "\n",
    "Una vez que tenemos los parámetros ajustados podemos usarlos con\n",
    "\n",
    "```python\n",
    "dist = norm(loc=params[0], scale=params[1])\n",
    "```\n",
    "\n",
    "Para distribuciones que tienen más de dos parámetros podemos usar\n",
    "\n",
    "```python\n",
    "dist = norm(*params[:-2], loc=params[-2], scale=params[-1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Observe la siguiente distribución y reflexione ¿Qué características resaltan de la misma? ¿Qué distribución sería apropiado ajustar en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T18:29:11.936106Z",
     "start_time": "2020-07-23T18:29:11.836900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cancer.csv', index_col=0)\n",
    "df = df[[\"diagnosis\", \"radius1\", \"texture1\"]]\n",
    "x = df[\"radius1\"].values\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "ax.hist(x, bins=20, density=True)\n",
    "ax.set_xlabel('Radio del nucleo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seleccione una distribución de `scipy.stats`  ajustela a los datos\n",
    "- Grafique la pdf teórica sobre el histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T18:29:11.941145Z",
     "start_time": "2020-07-23T18:29:11.938187Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificación de modelos: Tests de bondad de ajuste\n",
    "\n",
    "Una vez que hemos ajustado un modelo es buena práctica verificar que tan confiable es este ajuste. Las herramientas más típicas para medir que tan bien se ajusta nuestra distribución teórica son\n",
    "\n",
    "- el [test de Akaike](https://en.wikipedia.org/wiki/Akaike_information_criterion)\n",
    "- los [gráficos cuantil-cuantil](https://es.wikipedia.org/wiki/Gr%C3%A1fico_Q-Q) (QQ plot)\n",
    "- el test no-paramétrico de Kolmogorov-Smirnov (KS)\n",
    "\n",
    "A continuación revisaremos el test de KS para bondad de ajuste\n",
    "\n",
    "**El test de Kolmogorov-Smirnov**\n",
    "\n",
    "Es un test no-paramétrico que compara una muestra de datos estandarizados (distribución empírica) con una distribución de densidad acumulada (CDF) teórica. Este test busca refutar la siguiente hipótesis\n",
    "\n",
    "> **Hipótesis nula:** Las distribuciones son idénticas\n",
    "\n",
    "Para aplicar el test primero debemos **estandarizar** los datos. Estandarizar se refiere a la transformación\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu_x}{\\sigma_x}\n",
    "$$\n",
    "\n",
    "es decir los datos estándarizados tienen media cero y desviación estándar uno\n",
    "\n",
    "Esto puede hacerse fácilmente con NumPy usando\n",
    "\n",
    "```python\n",
    "z = (x - np.mean(x))/np.std(x)\n",
    "```\n",
    "\n",
    "### Test de KS con `scipy`\n",
    "\n",
    "Podemos realizar el test de KS con la función [`scipy.stats.kstest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html) donde\n",
    "\n",
    "```python\n",
    "scipy.stats.kstest(rvs, # Una muestra de observaciones estandarizadas\n",
    "                   cdf, # Una distribución acumulada teórica, por ejemplo scipy.stats.norm.cdf\n",
    "                   ...\n",
    "                  )\n",
    "```\n",
    "\n",
    "Esta función retorna el valor del estadístico de KS y su *p-value* asociado. Mientras más cerca de cero sea el estadístico de KS mejor es el ajuste. \n",
    "\n",
    "Más adelante haremos un repaso de tests de hipótesis en detalle. De momento recordemos que si el *p-value* es menor que una confianza $\\alpha=0.05$ entonces rechazamos la hipótesis nula con confianza $1-\\alpha = 0.95$ o $95\\%$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio \n",
    "\n",
    "Considere la muestra de datos anterior\n",
    "- Seleccione un conjunto de distribuciones teóricas \n",
    "- Encuentra la que tiene mejor ajuste usando `kstest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T18:29:12.019596Z",
     "start_time": "2020-07-23T18:29:11.943159Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
