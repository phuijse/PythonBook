{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T18:05:42.621323Z",
     "start_time": "2020-06-13T18:05:42.032886Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos tabulares en formato CSV \n",
    "\n",
    "Un archivo  **CSV** (Comma-Separated Values) es una tabla en formato texto plano cuyas columnas están separadas por comas (u otro delimitador)\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Consideremos la base de datos [\"Dow Jones Index\"](https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index) del repositorio UCI, la cual se distribuye en formato CSV\n",
    "\n",
    ":::{note}\n",
    "\n",
    "El Dow Jones es un índice bursatil muy utilizado ya que refleja el comportamiento del mercado accionario norteamericano\n",
    "\n",
    ":::\n",
    "\n",
    "Descarguémos la base de datos y observemos las primeras cinco lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T18:05:43.833142Z",
     "start_time": "2020-06-13T18:05:42.623608Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSL_INIT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dow_jones_index.zip\n",
      "  inflating: dow_jones_index.data    \n",
      "  inflating: dow_jones_index.names   \n",
      "quarter,stock,date,open,high,low,close,volume,percent_change_price,percent_change_volume_over_last_wk,previous_weeks_volume,next_weeks_open,next_weeks_close,percent_change_next_weeks_price,days_to_next_dividend,percent_return_next_dividend\n",
      "1,AA,1/7/2011,$15.82,$16.72,$15.78,$16.42,239655616,3.79267,,,$16.71,$15.97,-4.42849,26,0.182704\n",
      "1,AA,1/14/2011,$16.71,$16.71,$15.64,$15.97,242963398,-4.42849,1.380223028,239655616,$16.19,$15.79,-2.47066,19,0.187852\n",
      "1,AA,1/21/2011,$16.19,$16.38,$15.60,$15.79,138428495,-2.47066,-43.02495926,242963398,$15.87,$16.13,1.63831,12,0.189994\n",
      "1,AA,1/28/2011,$15.87,$16.63,$15.82,$16.13,151379173,1.63831,9.355500109,138428495,$16.18,$17.14,5.93325,5,0.185989\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -cq https://archive.ics.uci.edu/ml/machine-learning-databases/00312/dow_jones_index.zip\n",
    "unzip -o dow_jones_index.zip\n",
    "head -5 dow_jones_index.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del archivo CSV podemos ver que cada fila tiene un \n",
    "\n",
    "- identificador textual de la acción: `AA`\n",
    "- una fecha de observación: `1/7/2011`\n",
    "- un precio de apertura, máximo, mínimo y cierre para la fecha: `$15.82, $16.72, $15.78, $16.42`\n",
    "- entre otros\n",
    "\n",
    "También podemos notar algunos aspectos típicos de los archivos CSV\n",
    "\n",
    "- Las columnas están separadas por comas\n",
    "- La primera fila del archivo CSV contiene el *header*, es decir los nombres de las columnas\n",
    "- Las columnas son de tipos distintos: ¿Qué tipos puedes identificar en el ejemplo anterior?\n",
    "\n",
    "A continuación veremos como importar y escribir un archivo CSV usando `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función `pd.read_csv`**\n",
    "\n",
    "Leer un archivo CSV como DataFrame es directo usando la función `read_csv`\n",
    "\n",
    "A continuación se resaltan los argumentos principales\n",
    "\n",
    "```python\n",
    "pd.read_csv(\n",
    "    filepath_or_buffer: Union[str, pathlib.Path, IO[~AnyStr]], # path completo al archivo CSV\n",
    "    sep=',', # String o expresión regular que se usará para delimitar las columnas\n",
    "    header='infer', # Puede ser un int (fila donde está el header) o una lista de de int's\n",
    "    names=None, # Lista de strings con nombres de columnas (útil si el CSV no tiene header)\n",
    "    index_col=None, # La columna que se usará como header\n",
    "    usecols=None, # Lista: subconjunto de columnas que se desean importar (por defecto se importan todas)\n",
    "    converters=None, # Se explica en detalle más adelante junto a otros argumentos de parsing\n",
    "    parse_dates=None, # Se explica en detalle más adelante junto a otros argumentos de fecha\n",
    "    ...\n",
    "    )\n",
    "```\n",
    "\n",
    "Más adelante veremos más argumentos y un ejemplo de uso\n",
    "\n",
    "**Atributo `to_csv()`**\n",
    "\n",
    "Podemos crear un archivo CSV desde un DataFrame usando el atributo `to_csv` como se muestra a continuación\n",
    "\n",
    "```python\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"mis_datos.csv\")\n",
    "```\n",
    "\n",
    "- Esto  crea un archivo `mis_data.csv` en el directorio actual\n",
    "- Por defecto guardara las nombres de columna como un header y usará \",\" como delimitador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis sintático o *parsing*\n",
    "\n",
    "En general un archivo de texto plano podría contener\n",
    "\n",
    "- valores numéricos continuos\n",
    "- valores numéricos discretos\n",
    "- fechas\n",
    "- coordenadas \n",
    "- monedas\n",
    "- direcciones\n",
    "- etiquetas de texto\n",
    "- y un largo etcétera\n",
    "\n",
    "Los programas que leen e importan archivos de texto plano como CSV deben interpretar estos valores y convertirlos al formato más adecuado, por ejemplo\n",
    "\n",
    "- flotante\n",
    "- entero\n",
    "- booleano\n",
    "- string\n",
    "\n",
    "Se llama ***parser* o analizador sintático** al programa que analiza los textos y luego \n",
    "\n",
    "- filtra y/o completa los textos invalidos\n",
    "- convierte los datos a un formato estándar\n",
    "\n",
    "Pandas hace este proceso de forma automática y podemos hacer algunos ajustes usando los argumentos disponibles en `read_csv`\n",
    "\n",
    "Por ejemplo \n",
    "\n",
    "\n",
    "```python\n",
    "pd.read_csv(\n",
    "    ...\n",
    "    dtypes=None # Diccionario donde la llave es el nombre de la columna y el valor el tipo requerido\n",
    "    na_values=None, # String o lista de strings con valores que serán reconocidos como NaN\n",
    "    decimal='.', # String que se usará para reconocer el punto decimal\n",
    "    comment=None, # String, todos las lineas que empiezen con este string serán ignoradas\n",
    "    converters=None # Se explica a continuación\n",
    "    ...\n",
    "    )\n",
    "```\n",
    "\n",
    "Si las opciones automáticas no son suficientes se puede hacer *parsing* en base a reglas manualmente creadas usando el argumento `converters`\n",
    "\n",
    "`converters` recibe un diccionario con \"reglas de parseo\" con la siguiente sintaxis\n",
    "\n",
    "```python\n",
    "    {'nombre de la columna 1': funcion_parseadora1, \n",
    "     'nombre de la columna 2': funcion_parseadora2,\n",
    "     ...\n",
    "    }\n",
    "```\n",
    "\n",
    "Notar que `funcion_parseadoraX` puede ser una función explicita o anómina (lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**\n",
    "\n",
    "Los datos de la columna de precio de apertura (open) de \"dow_jones_index.data\" están formateados como \n",
    "\n",
    "`'$15.84'`\n",
    "\n",
    "que corresponde a un signo dolar seguido de un número real con punto decimal\n",
    "\n",
    "Para *parsear* este valor debemos escribir una función que \n",
    "\n",
    "1. Elimine el signo dolar del string\n",
    "1. Convierta el resto del string en flotante\n",
    "\n",
    "Por ejemplo\n",
    "\n",
    "```python\n",
    "def remove_dollar(text):\n",
    "    # return float(x[1:]) # Elimina el primer caracter\n",
    "    return float(x.strip(\"$\")) # Elimina todos los $ del string\n",
    "```\n",
    "\n",
    "Luego agregamos esta función a un diccionario con la llave `open` y se lo entregamos al argumento `converters`, es decir \n",
    "\n",
    "```python\n",
    "parser = {'open': remove_dollar}\n",
    "```\n",
    "\n",
    "Se puede lograr lo mismo usando una función anónima, por ejemplo:\n",
    "\n",
    "```python\n",
    "parser = {'open': lambda x: float(x.strip(\"$\"))}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación/parseo de fechas\n",
    "\n",
    "Un dato textual muy usual en datos tabulares y series de tiempo son las fechas\n",
    "\n",
    "Sin embargo el formato de fecha puede variar considerablemente entre distintas bases de datos\n",
    "\n",
    "`pandas` tiene un tipo denominado `Timestamp` el cual se puede construir con la función `pd.to_datetime()` a partir de un string \n",
    "\n",
    "Pandas identifica automaticamente fechas y horas en distintos formatos\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "```python\n",
    ">>> pd.to_datetime(\"1/5/2018\") # Formato norteamericano Mes/Día/Año \n",
    "Timestamp('2018-01-05 00:00:00')\n",
    "\n",
    ">>> pd.to_datetime(\"May/1/2018\") # También se acepta un string para el mes\n",
    "Timestamp('2018-05-01 00:00:00')\n",
    "\n",
    ">>> pd.to_datetime(\"1st of May of 2018\") # También se puede usar una frase \"Día del Mes del Año\"\n",
    "Timestamp('2018-05-01 00:00:00')\n",
    "\n",
    ">>> pd.to_datetime(\"2018\") # Autocompletación por defecto para fechas incompletas\n",
    "Timestamp('2018-01-01 00:00:00')\n",
    "\n",
    ">>> pd.to_datetime(\"14:45\") # Si usamos sólo la hora se usa la fecha actual\n",
    "Timestamp('2020-06-12 14:45:00')\n",
    "\n",
    ">>> pd.to_datetime(\"May/1/2018 14:45\") # Timestamp completo\n",
    "Timestamp('2018-05-01 14:45:00')\n",
    "```\n",
    "\n",
    "Podemos controlar el parseo de fechas en `read_csv` con los argumentos\n",
    "\n",
    "```python\n",
    "pd.read_csv(\n",
    "    ...\n",
    "    parse_dates=False # Booleano o lista con las columnas que deben ser interpretadas como fechas\n",
    "    infer_datetime_format=False, # Inferir una función parseadora de forma automática\n",
    "    dayfirst=False, # Formato día/mes/año o mes/día/año\n",
    "    date_parser=None, # Función provista por el usuario que toma un string y retorna TimeStamp\n",
    "    ...\n",
    "    )\n",
    "```\n",
    "\n",
    "Las fechas/tiempos en formato `TimeStamp` pueden usarse como índices\n",
    "\n",
    "Esto nos permite recuperar rapidamente todos los eventos dentro de un intervalo de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos tabulares a partir de archivos excel\n",
    "\n",
    "Muchas empresas e instituciones manejan sus datos como hojas de cálculo o *spreadsheets* construidas usando software como Microsoft Excel, Openoffice/Libreoffice calc o Google spreadsheets\n",
    "\n",
    "`pandas` permite importar como `DataFrame` una hoja de cálculo en formatos `xls, xlsx, xlsm, xlsb, odf` usando  la función [`read_excel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)\n",
    "\n",
    "   \n",
    "Muchos de los argumentos de `read_csv` están disponibles en `read_excel`, los \"nuevos\" argumentos son\n",
    "\n",
    "```python\n",
    "pd.read_excel(io, # string o path a la hoja de cálculo\n",
    "              sheet_name=0, # Entero, string o lista, especifica la(s) hoja (s) que vamos a importar\n",
    "              ...\n",
    "             )\n",
    "```\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Para trabajar con archivos `excel` se requieren algunas librerías adicionales las cuales puede instalarse facilmente con conda\n",
    "\n",
    "    conda install openpyxl\n",
    "    \n",
    ":::\n",
    "    \n",
    "**Ejemplo**\n",
    "\n",
    "Consideremos los siguientes datos del censo chileno de 2017 en formato Excel de donde importaremos datos de vivienda por comuna\n",
    "\n",
    "Esto corresponde a la segunda hoja (`sheet_name=1`) y en particular las columnas de 1 a 14\n",
    "\n",
    "Importemos la planilla e inspecciones sus primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T18:05:45.779664Z",
     "start_time": "2020-06-13T18:05:45.619879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOMBRE REGIÓN</th>\n",
       "      <th>Código Región</th>\n",
       "      <th>NOMBRE PROVINCIA</th>\n",
       "      <th>Código Provincia</th>\n",
       "      <th>NOMBRE COMUNA</th>\n",
       "      <th>Código Comuna</th>\n",
       "      <th>Viviendas Particulares Ocupadas con Moradores Presentes</th>\n",
       "      <th>Viviendas Particulares Ocupadas con Moradores Ausentes</th>\n",
       "      <th>Viviendas Particulares Desocupadas (en Venta, para arriendo, Abandonada u otro)</th>\n",
       "      <th>Viviendas Particulares Desocupadas\\n(de Temporada)</th>\n",
       "      <th>Viviendas Colectivas</th>\n",
       "      <th>TOTAL VIVIENDAS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORDEN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARICA Y PARINACOTA</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ARICA</td>\n",
       "      <td>151.0</td>\n",
       "      <td>ARICA</td>\n",
       "      <td>15101.0</td>\n",
       "      <td>62129.0</td>\n",
       "      <td>4574.0</td>\n",
       "      <td>4045.0</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>72639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARICA Y PARINACOTA</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ARICA</td>\n",
       "      <td>151.0</td>\n",
       "      <td>CAMARONES</td>\n",
       "      <td>15102.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARICA Y PARINACOTA</td>\n",
       "      <td>15.0</td>\n",
       "      <td>PARINACOTA</td>\n",
       "      <td>152.0</td>\n",
       "      <td>PUTRE</td>\n",
       "      <td>15201.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARICA Y PARINACOTA</td>\n",
       "      <td>15.0</td>\n",
       "      <td>PARINACOTA</td>\n",
       "      <td>152.0</td>\n",
       "      <td>GENERAL LAGOS</td>\n",
       "      <td>15202.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TARAPACÁ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IQUIQUE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>IQUIQUE</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>56007.0</td>\n",
       "      <td>3673.0</td>\n",
       "      <td>5481.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>66986.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NOMBRE REGIÓN  Código Región NOMBRE PROVINCIA  Código Provincia  \\\n",
       "ORDEN                                                                         \n",
       "1      ARICA Y PARINACOTA           15.0            ARICA             151.0   \n",
       "2      ARICA Y PARINACOTA           15.0            ARICA             151.0   \n",
       "3      ARICA Y PARINACOTA           15.0       PARINACOTA             152.0   \n",
       "4      ARICA Y PARINACOTA           15.0       PARINACOTA             152.0   \n",
       "5                TARAPACÁ            1.0          IQUIQUE              11.0   \n",
       "\n",
       "       NOMBRE COMUNA  Código Comuna  \\\n",
       "ORDEN                                 \n",
       "1              ARICA        15101.0   \n",
       "2          CAMARONES        15102.0   \n",
       "3              PUTRE        15201.0   \n",
       "4      GENERAL LAGOS        15202.0   \n",
       "5            IQUIQUE         1101.0   \n",
       "\n",
       "       Viviendas Particulares Ocupadas con Moradores Presentes  \\\n",
       "ORDEN                                                            \n",
       "1                                                62129.0         \n",
       "2                                                  431.0         \n",
       "3                                                  540.0         \n",
       "4                                                  218.0         \n",
       "5                                                56007.0         \n",
       "\n",
       "       Viviendas Particulares Ocupadas con Moradores Ausentes  \\\n",
       "ORDEN                                                           \n",
       "1                                                 4574.0        \n",
       "2                                                   96.0        \n",
       "3                                                  197.0        \n",
       "4                                                   90.0        \n",
       "5                                                 3673.0        \n",
       "\n",
       "       Viviendas Particulares Desocupadas (en Venta, para arriendo, Abandonada u otro)  \\\n",
       "ORDEN                                                                                    \n",
       "1                                                 4045.0                                 \n",
       "2                                                  158.0                                 \n",
       "3                                                  143.0                                 \n",
       "4                                                  162.0                                 \n",
       "5                                                 5481.0                                 \n",
       "\n",
       "       Viviendas Particulares Desocupadas\\n(de Temporada)  \\\n",
       "ORDEN                                                       \n",
       "1                                                 1666.0    \n",
       "2                                                  242.0    \n",
       "3                                                  995.0    \n",
       "4                                                  216.0    \n",
       "5                                                 1564.0    \n",
       "\n",
       "       Viviendas Colectivas  TOTAL VIVIENDAS  \n",
       "ORDEN                                         \n",
       "1                     225.0          72639.0  \n",
       "2                      21.0            948.0  \n",
       "3                      42.0           1917.0  \n",
       "4                      11.0            697.0  \n",
       "5                     261.0          66986.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -cq http://www.censo2017.cl/wp-content/uploads/2017/12/Cantidad-de-Viviendas-por-Tipo.xlsx\n",
    "df = pd.read_excel(\"Cantidad-de-Viviendas-por-Tipo.xlsx\", \n",
    "                   sheet_name=1, # Importamos la segunda hoja (vivienda)\n",
    "                   usecols=list(range(1, 14)), # Importamos las columnas 1 a 20\n",
    "                   header=1, # El header está en la segunda fila\n",
    "                   skiprows=[2], # Eliminamos la fila 2 ya que es invalida\n",
    "                   index_col='ORDEN' # Usaremos la columna orden como índice\n",
    "                  ).dropna() # Eliminamos las filas con NaN\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de bases de datos SQL\n",
    "\n",
    "Pandas es capaz de conectar y hacer consultas en lenguaje SQL a una base de datos externa y retornar el resultado como un DataFrame usando la función [`read_sql_query`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_query.html) \n",
    "\n",
    "```python\n",
    "pd.read_sql_query(sql, # Consulta SQL en formato string\n",
    "                  con, # dirección a la base de datos o objeto de conexión\n",
    "                  index_col=None, # Selecciona la columna que actuara como índice del DataFrame\n",
    "                  parse_dates=None, # Igual que read_csv y read_excel\n",
    "                  ...\n",
    "                 )\n",
    "```\n",
    "\n",
    "También se puede usar el atributo\n",
    "\n",
    "```python\n",
    "df.to_sql(name, # string: el nombre de la tabla\n",
    "          con, # Engine con conexión\n",
    "          if_exists: str = 'fail', # Que hacer si la tabla ya existe: fail, replace, append\n",
    "          index: bool = True, # Escribir el índice del dataframe como columna\n",
    "          ...\n",
    "         )\n",
    "```\n",
    "\n",
    "**¿Qué es SQL?**\n",
    "\n",
    "Structured Query Languaje (SQL) es un lenguaje estándar ampliamente usado para consultar, crear, modificar y eliminar bases de datos relacionales. \n",
    "\n",
    "**¿Qué es una base de datos relacional?**\n",
    "\n",
    "Es un tipo de base de datos organizada como múltiples tablas. Por ejemplo\n",
    "\n",
    "\n",
    "|id_cliente | nombre | apellido |\n",
    "|----|----|----|\n",
    "|1| Pablo | Huijse |\n",
    "|2| Luis | Alvarez |\n",
    "|3| Cristobal | Navarro |\n",
    "|  | CLIENTES |  |\n",
    "\n",
    "|id_orden | platanos | manzanas | id_cliente |\n",
    "|----|----|----| ---- |\n",
    "|1| 0 | 5 | 1 |\n",
    "|2| 2 | 2 | 3 |\n",
    "|3| 3 | 1 | 1 |\n",
    "|  | ORDENES |  | | \n",
    "\n",
    "- Las filas se llaman entidades y las columnas atributos\n",
    "- Cada tabla tiene una lalve primaria: id_orden e id_cliente\n",
    "- La tabla ORDENES **está relacionada** a la tabla CLIENTES con la llave foranea: id_clientes\n",
    "- Las tablas no pueden tener el mismo nombre \n",
    "\n",
    "\n",
    "\n",
    "**¿Dónde corre la base de datos relacional?**\n",
    "\n",
    "La base de datos relacional corre en un sistema de manejo \n",
    "\n",
    "Algunos ejemplos populares son MySQL, PostgreSQL y SQLite3\n",
    "\n",
    "\n",
    "**Ejemplo básico de una consulta SQL**\n",
    "\n",
    "SQL es un lenguaje de alto nivel. Algunos comandos comunes son\n",
    "\n",
    "- `SELECT`: recuperar un subconjunto de la tabla\n",
    "- `INSERT`: insertar datos en una tabla\n",
    "- `UPDATE`: actualizar datos en una tabla\n",
    "- `DELETE`: eliminar datos de la tabla\n",
    "\n",
    "La tabla que se quiere manipular se selecciona con el keyword `FROM`\n",
    "\n",
    "Se agregan condiciones usando el keyword `WHERE`\n",
    "\n",
    "Se puede usar `*` como alias para \"todas las columnas\"\n",
    "\n",
    "Por ejemplo\n",
    "```SQL\n",
    "    SELECT A, B, C FROM mi_tabla WHERE D > 1\n",
    "```\n",
    "\n",
    "Esto recupera las valores de las columnas A, B y C que tegan un valor de la columna D mayor que 1 a partir de la tabla \"mi_tabla\" \n",
    "\n",
    "**Ejemplo** Crear una tabla en SQLite a partir de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3  # SQLite3 es parte de la librería estándar de Python\n",
    "\n",
    "# Creamos una base de datos persistente\n",
    "with sqlite3.connect('censo.db') as conn:\n",
    "\n",
    "    df.to_sql(\"censo_viviendas\", # Insertamos una tabla llamada censo_viviendos\n",
    "              conn, # Usamos el objeto conexión que acabos de crear\n",
    "              if_exists='replace', \n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** Obtener un DataFrame a partir de la base de datos SQL anterior con las viviendas ocupadas por comuna de la provincia de Valdivia\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "Si los nombres de las columnas tienen espacios en blanco debe encerrarlos con paréntesis cuadrados al hacer la consulta\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT [Viviendas Particulares Ocupadas con Moradores Presentes], [NOMBRE COMUNA] FROM censo_viviendas WHERE [NOMBRE PROVINCIA] = 'VALDIVIA'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Viviendas Particulares Ocupadas con Moradores Presentes</th>\n",
       "      <th>NOMBRE COMUNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53624.0</td>\n",
       "      <td>VALDIVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1842.0</td>\n",
       "      <td>CORRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5643.0</td>\n",
       "      <td>LANCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6446.0</td>\n",
       "      <td>LOS LAGOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2317.0</td>\n",
       "      <td>MÁFIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6808.0</td>\n",
       "      <td>MARIQUINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6476.0</td>\n",
       "      <td>PAILLACO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11615.0</td>\n",
       "      <td>PANGUIPULLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Viviendas Particulares Ocupadas con Moradores Presentes NOMBRE COMUNA\n",
       "0                                            53624.0            VALDIVIA\n",
       "1                                             1842.0              CORRAL\n",
       "2                                             5643.0               LANCO\n",
       "3                                             6446.0           LOS LAGOS\n",
       "4                                             2317.0               MÁFIL\n",
       "5                                             6808.0           MARIQUINA\n",
       "6                                             6476.0            PAILLACO\n",
       "7                                            11615.0         PANGUIPULLI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arg1 = \"Viviendas Particulares Ocupadas con Moradores Presentes\"\n",
    "arg2 = \"NOMBRE COMUNA\"\n",
    "arg3 = \"NOMBRE PROVINCIA\"\n",
    "sql_string = f\"SELECT [{arg1}], [{arg2}] FROM censo_viviendas WHERE [{arg3}] = 'VALDIVIA'\"\n",
    "display(sql_string)\n",
    "with sqlite3.connect('censo.db') as conn:    \n",
    "    df = pd.read_sql_query(sql_string, conn)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "- sqlite permite conectar a una base de datos local: RAM, disco, o disco externo montado\n",
    "- sqlite no está diseñado para soportar múltiples usuarios conectados a una misma base de datos\n",
    "- Otras alternativas: [SQL Alchemy](https://www.sqlalchemy.org/), [PostgreSQL+Python](http://initd.org/psycopg/), [Peewee](http://docs.peewee-orm.com/en/latest/)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar y leer un DataFrame en formato JSON\n",
    "\n",
    "Podemos usar el atributo [`to_json`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html) para convertir un dataframe a este formato\n",
    "\n",
    "```python\n",
    "df.to_json(\n",
    "    path_or_buf = None, # Ubicación en disco\n",
    "    orient = None, # Indica el formato del string JSON\n",
    "    ...\n",
    "    )\n",
    "```\n",
    "\n",
    "Por ejemplo\n",
    "\n",
    "```python\n",
    ">>> df.to_json(\"pandas.json\", orient='table')\n",
    "```\n",
    "\n",
    "crea un string pandas.json en el directorio actual\n",
    "\n",
    "Luego la función `read_json`\n",
    "\n",
    "```python\n",
    ">>> df = pd.read_json(\"pandas.json\", orient='table')\n",
    "```\n",
    "\n",
    "regenera el DataFrame que teniamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
