{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File ‘wdbc.data’ already there; not retrieving.\n",
      "\n",
      "File ‘wdbc.names’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -nc -c https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
    "wget -nc -c https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diag</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Diag  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "ID                                                                     \n",
       "842302       0        17.99         10.38          122.80     1001.0   \n",
       "842517       0        20.57         17.77          132.90     1326.0   \n",
       "84300903     0        19.69         21.25          130.00     1203.0   \n",
       "84348301     0        11.42         20.38           77.58      386.1   \n",
       "84358402     0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "ID                                                            \n",
       "842302            0.11840           0.27760          0.3001   \n",
       "842517            0.08474           0.07864          0.0869   \n",
       "84300903          0.10960           0.15990          0.1974   \n",
       "84348301          0.14250           0.28390          0.2414   \n",
       "84358402          0.10030           0.13280          0.1980   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "ID                                            ...                 \n",
       "842302                0.14710         0.2419  ...         25.38   \n",
       "842517                0.07017         0.1812  ...         24.99   \n",
       "84300903              0.12790         0.2069  ...         23.57   \n",
       "84348301              0.10520         0.2597  ...         14.91   \n",
       "84358402              0.10430         0.1809  ...         22.54   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "ID                                                                       \n",
       "842302            17.33           184.60      2019.0            0.1622   \n",
       "842517            23.41           158.80      1956.0            0.1238   \n",
       "84300903          25.53           152.50      1709.0            0.1444   \n",
       "84348301          26.50            98.87       567.7            0.2098   \n",
       "84358402          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "ID                                                                   \n",
       "842302               0.6656           0.7119                0.2654   \n",
       "842517               0.1866           0.2416                0.1860   \n",
       "84300903             0.4245           0.4504                0.2430   \n",
       "84348301             0.8663           0.6869                0.2575   \n",
       "84358402             0.2050           0.4000                0.1625   \n",
       "\n",
       "          symmetry_worst  fractal dimension_worst  \n",
       "ID                                                 \n",
       "842302            0.4601                  0.11890  \n",
       "842517            0.2750                  0.08902  \n",
       "84300903          0.3613                  0.08758  \n",
       "84348301          0.6638                  0.17300  \n",
       "84358402          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "names = [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \n",
    "         \"concavity\", \"concave points\", \"symmetry\", \"fractal dimension\"]\n",
    "final_names = [\"ID\", \"Diag\"] + [name+'_mean' for name in names] + [name+'_std' for name in names] + [name+'_worst' for name in names]\n",
    "df = pd.read_csv('wdbc.data', index_col=0,names=final_names)\n",
    "df['Diag'] = df['Diag'].map({'M': 0, 'B': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística\n",
    "\n",
    "- Para escribir menos llamemos $f(x_i, \\theta) = \\theta_0 + \\sum_{j=1}^D \\theta_j x_{ij}$\n",
    "- Mis observaciones son $\\{y_i\\}$ que son binarias\n",
    "- Mi modelo para $y_i$ es $\\mathcal{S} (f(x_i, \\theta))$\n",
    "- Los parámetros del modelo son $\\theta$\n",
    "- Asumiendo iid tenemos que la verosimilitud conjunta es igual a la multiplicación de las marginales\n",
    "- Aplicando además logaritmo tenemos\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^M \\log p(y_i | \\mathcal{S} (f(x_i, \\theta)) )\n",
    "$$\n",
    "\n",
    "- Si asumimos que la probabilidad de $y_i$ dado el modelo $\\mathcal{S} (f(x_i, \\theta))$ es Bernoulli entonces\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(y_i | \\mathcal{S} (f(x_i, \\theta) ) &= \\log \\mathcal{S} (f(x_i, \\theta))^{y_i} (1-\\mathcal{S} (f(x_i, \\theta)) )^{1-y_i} \\nonumber \\\\\n",
    "&= y_i \\log (\\mathcal{S} (f(x_i, \\theta)) ) + (1-y_i) \\log(1-\\mathcal{S} (f(x_i, \\theta)) )\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "y todo junto\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^M y_i \\log (\\mathcal{S} (f(x_i, \\theta)) ) + (1-y_i) \\log(1-\\mathcal{S} (f(x_i, \\theta)) )\n",
    "$$\n",
    "\n",
    "y si derivada con respecto a $\\theta_j$\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\theta_j} \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^M \\left ( \\frac{y_i}{\\mathcal{S} (f(x_i, \\theta))} - \\frac{1-y_i}{1-\\mathcal{S} (f(x_i, \\theta))} \\right) \\frac{d \\mathcal{S} (f(x_i, \\theta))}{d f(x_i, \\theta)} \\frac{d f(x_i, \\theta)}{d \\theta_j} \n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{S}(z)}{dz} =  \\mathcal{S}(z) ( 1 - \\mathcal{S}(z))\n",
    "$$\n",
    "\n",
    "entonces\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d\\theta_j} \\log \\mathcal{L}(\\theta) &= \\sum_{i=1}^M \\left( y_i - y_i\\mathcal{S} (f(x_i, \\theta)) - \\mathcal{S} (f(x_i, \\theta))  + y_i \\mathcal{S} (f(x_i, \\theta)) \\right) \\frac{d f(x_i, \\theta)}{d \\theta_j} \\nonumber \\\\\n",
    "&= \\sum_{i=1}^M \\left( y_i  - \\mathcal{S} (f(x_i, \\theta)) \\right) \\frac{d f(x_i, \\theta)}{d \\theta_j} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "y \n",
    "\n",
    "$$\n",
    "\\frac{d f(x_i, \\theta)}{d \\theta_0} =  1\n",
    "$$\n",
    "\n",
    "para $j>0$\n",
    "$$\n",
    "\\frac{d f(x_i, \\theta)}{d \\theta_j} =  x_{ij}\n",
    "$$\n",
    "\n",
    "Podemos simplicar más la verosimilitud usando $\\log(1-\\mathcal{S} (f(x_i, \\theta)) ) = \\log \\mathcal{S} (f(x_i, \\theta)) - f(x_i, \\theta)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\mathcal{L}(\\theta) &= \\sum_{i=1}^M y_i \\log (\\mathcal{S} (f(x_i, \\theta)) ) + (1-y_i) \\log(1-\\mathcal{S} (f(x_i, \\theta)) ) \\nonumber \\\\\n",
    "&=\\sum_{i=1}^M \\log (\\mathcal{S} (f(x_i, \\theta)) ) - (1-y_i) f(x_i, \\theta) \\nonumber\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 129.6141, Test: 22.6140\n",
      "Train: 86.8590, Test: 16.5338\n",
      "Train: 68.1650, Test: 14.9821\n",
      "Train: 56.4627, Test: 15.5080\n",
      "Train: 49.7665, Test: 22.2173\n",
      "Train: 45.5641, Test: 19.6069\n",
      "Train: 42.7212, Test: 18.2291\n",
      "Train: 38.5362, Test: 16.0013\n",
      "Train: 34.7006, Test: 13.4873\n",
      "Train: 33.0691, Test: 13.0948\n",
      "Train: 30.9437, Test: 10.9753\n",
      "Train: 28.1261, Test: 9.2674\n",
      "Train: 25.6230, Test: 8.8313\n",
      "Train: 23.2264, Test: 10.2564\n",
      "Train: 20.8871, Test: 9.6851\n",
      "Train: 19.5138, Test: 10.0940\n",
      "Train: 18.3154, Test: 15.3029\n",
      "Train: 17.4100, Test: 18.7566\n",
      "Train: 16.5428, Test: 23.5208\n",
      "Train: 15.7536, Test: 29.6564\n",
      "Train: 15.0195, Test: 37.7201\n",
      "Train: 14.3276, Test: 46.2564\n",
      "Train: 13.6855, Test: 54.1870\n",
      "Train: 13.1582, Test: 60.7293\n",
      "Train: 12.6570, Test: 66.6111\n",
      "Train: 12.0152, Test: 73.1328\n",
      "Train: 11.2224, Test: 80.7100\n",
      "Train: 10.3463, Test: 92.2113\n",
      "Train: 9.3815, Test: 112.2614\n",
      "Train: 8.6464, Test: 132.7383\n",
      "Train: 8.0693, Test: 151.3934\n",
      "Train: 7.6516, Test: 169.9709\n",
      "Train: 6.9730, Test: 203.9358\n",
      "Train: 5.8660, Test: 268.4689\n",
      "Train: 4.1150, Test: 399.4080\n",
      "Train: 2.2798, Test: 608.8560\n",
      "Train: 1.2322, Test: 824.4790\n",
      "Train: 0.6511, Test: 1045.0207\n",
      "Train: 0.3337, Test: 1272.4803\n",
      "Train: 0.1687, Test: 1502.4790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Parametros'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.01150536, -1.70344626, -0.04014629, -2.0222858 ,  1.75672809,\n",
       "       -0.64158738,  2.26243012, -2.15971349, -0.43965547,  0.1917149 ,\n",
       "        0.44550931, -5.29303115,  0.44579182,  0.83341857,  3.80484004,\n",
       "       -0.39295127, -0.48901102,  0.77793136, -0.64711842,  1.04911165,\n",
       "        0.706907  , -1.54031477, -1.6897125 , -2.20114909,  1.38495793,\n",
       "       -0.70647458,  1.5608941 , -0.85380461, -0.51521024, -1.65336352,\n",
       "       -1.47080948])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Los resultados de clasificación en entrenamiento'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       159\n",
      "           1       0.99      0.99      0.99       267\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.98      0.98      0.98       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Los resultados de clasificación en validación'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "Era 0 y predije 0: 52\n",
      "Era 0 y predije 1: 1\n",
      "Era 1 y predije 0: 0\n",
      "Era 1 y predije 1: 90\n"
     ]
    }
   ],
   "source": [
    "# Crear base de datos\n",
    "y = df[\"Diag\"].values\n",
    "X = df.drop(columns=[\"Diag\"]).values\n",
    "# Estandarizar\n",
    "X = (X - np.mean(X, axis=0))/np.std(X, axis=0)\n",
    "# Partición estratificada\n",
    "import sklearn.model_selection\n",
    "sss = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, train_size=0.75)\n",
    "train_idx, test_idx = next(sss.split(X, y))\n",
    "\n",
    "# Modelo y optimización\n",
    "def sigmoide(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def modelo(theta, X):\n",
    "    f = theta[0] + np.sum(theta[1:]*X, axis=1)     \n",
    "    return sigmoide(f), f\n",
    "\n",
    "def logverosimilitud(theta, *args):\n",
    "    X, y = args\n",
    "    s, f = modelo(theta, X)\n",
    "    # Le pongo un signo menos ya que quiero minimizar en lugar de maximizar\n",
    "    return -np.sum(-np.logaddexp(0, -f) - (1-y)*f, axis=0) # Versión simplificada\n",
    "    #return -np.sum(y*np.log(s+1e-10) + (1-y)*np.log(1-s+1e-10) )\n",
    "\n",
    "def grad_logverosimilitud(theta, *args):\n",
    "    X, y = args\n",
    "    N = len(y)\n",
    "    s, f = modelo(theta, X)\n",
    "    X1 = np.concatenate((np.ones(shape=(N, 1)), X), axis=1)\n",
    "    e = (y - s)\n",
    "    return -np.sum(e[:, np.newaxis]*X1, axis=0)\n",
    "\n",
    "def eval_model(theta):  \n",
    "    global best_theta, best_logl\n",
    "    logltrain = logverosimilitud(theta, *(X[train_idx, :], y[train_idx]))\n",
    "    logltest = logverosimilitud(theta, *(X[test_idx, :], y[test_idx]))\n",
    "    print(\"Train: %0.4f, Test: %0.4f\" %(logltrain, logltest))   \n",
    "    if logltest < best_logl: # Guardar el mejor modelo de test\n",
    "        best_theta = theta\n",
    "        best_logl = logltest\n",
    "\n",
    "import scipy.optimize\n",
    "theta = np.random.randn(1+X.shape[1])\n",
    "best_theta = np.zeros(1+X.shape[1])\n",
    "best_logl = np.inf\n",
    "res = scipy.optimize.minimize(logverosimilitud, x0=theta, method='BFGS', callback=eval_model, tol=1e-1, \n",
    "                              jac=grad_logverosimilitud, args=(X[train_idx, :], y[train_idx]))\n",
    "\n",
    "# Evaluación\n",
    "import sklearn.metrics\n",
    "display(\"Parametros\", best_theta)\n",
    "haty_train, _ = modelo(best_theta, X[train_idx, :])\n",
    "haty_test, _ = modelo(best_theta, X[test_idx, :])\n",
    "# Encontrando el umbral\n",
    "T = np.linspace(0, 1, num=100)\n",
    "f1 = np.array([sklearn.metrics.f1_score(y[test_idx], haty_test > t) for t in T])\n",
    "# Resultados de clasificación\n",
    "display(\"Los resultados de clasificación en entrenamiento\")\n",
    "print(sklearn.metrics.classification_report(y[train_idx], haty_train > T[np.argmax(f1)]))\n",
    "display(\"Los resultados de clasificación en validación\")\n",
    "print(sklearn.metrics.classification_report(y[test_idx], haty_test > T[np.argmax(f1)]))\n",
    "cm = sklearn.metrics.confusion_matrix(y[test_idx], haty_test > T[np.argmax(f1)])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(\"Era {0} y predije {1}: {2}\".format(i, j, cm[i, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
