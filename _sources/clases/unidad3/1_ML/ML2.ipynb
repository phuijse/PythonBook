{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:09.369300Z",
     "start_time": "2020-08-18T03:34:08.972688Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Aprendizaje supervisado: Clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción conceptual\n",
    "\n",
    "En el paradigma de aprendizaje supervisado los datos de entrenamiento tienen asociado un **objetivo** \n",
    "\n",
    "El objetivo corresponde usualmente a una **etiqueta numérica** que un ser humano le asigna al dato. Este conocimiento *a priori* es lo que el algoritmo debe encapsular\n",
    "\n",
    "- Durante el entrenamiento la máquina recibe como entrada datos y etiquetas con tal de aprender reglas que los relacionen\n",
    "- Durante la inferencia la máquina usa las reglas para predecir la etiqueta en datos no vistos previamente\n",
    "\n",
    "Podemos comparar el paradigma de aprendizaje supervisado con el de programación tradicional en base a la siguiente figura\n",
    "\n",
    "<img src=\"../img/intro-ml1.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción matemática\n",
    "\n",
    "Formalmente, lo que se busca es aprender un mapeo o función paramétrica\n",
    "\n",
    "$$ \n",
    "f_{\\theta}: \\mathcal{X} \\rightarrow \\mathcal{Y}, \n",
    "$$\n",
    "\n",
    "donde $\\mathcal{X}$ es el dominio de los datos e $\\mathcal{Y}$ es el dominio del objetivo\n",
    "\n",
    "Típicamente el modelo se entrena en base a un conjunto de $N$ ejemplos:\n",
    "\n",
    "$$ \n",
    "\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\}, \n",
    "$$\n",
    "\n",
    "donde cada ejemplo es una tupla formada de datos (entrada) $x_i \\in \\mathcal{X}$ y objetivo (salida) $y_i \\in \\mathcal{Y}$\n",
    "\n",
    "1. **Datos:** La naturaleza de los datos depende del problema, sin embargo lo más común es que los datos $x_i$ se estructuren como arreglos de $M$ componentes. A los componentes los llamamos **atributos** o características (features)\n",
    "1. **Objetivos:** El objetivo es la variable que deseamos predecir. Si el objetivo es una variable numérica (continua o discreta) estamos ante un problema de regresión. Por el contrario si el objetivo es categórico entonces estamos ante un problema de clasificación. \n",
    "\n",
    "> En esta lección nos concentraremos en el problema de clasificación y revisaremos algunos modelos clásicos\n",
    "\n",
    "En el modelo abstracto $f_{\\theta}$ el vector $\\theta$ corresponde a los **parámetros del modelo**. Luego aprender/entrenar/ajustar el modelo corresponde a encontrar el valor \"óptimo\" de $\\theta$\n",
    "\n",
    "Para encontrar este valor óptimo debemos ser capaces de medir el desempeño del modelo. Esto se hace a través de una **función de pérdida o costo**: $L(\\theta)$. Usualmente esta función está relacionada al error de nuestro modelo en nuestro problema particular. En la unidad anterior utilizamos la verosimilitud como función de costo para problemas de regresión.\n",
    "\n",
    "Recordar que cuando hablamos de $\\theta$ \"óptimo\" lo decimos en el sentido de una función de costo particular\n",
    "\n",
    "La siguiente figura ([referencia](https://www.kdnuggets.com/2019/03/neural-networks-numpy-absolute-beginners-part-2-linear-regression.html/2)) muestra un modelo de regresión lineal que se ajusta a un conjunto de datos (derecha) y la función de costo que está minimizando (izquierda)\n",
    "\n",
    "<img src=\"../img/opti-animation.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Bayesiano \"Ingenuo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este clasificador con interpretación probabilística busca la probabilidad de la etiqueta $y$ dado el ejemplo $x$, es decir $P(y|x)$\n",
    "\n",
    "Usando el teorema de Bayes podemos escribir esto como\n",
    "\n",
    "$$\n",
    "p(y | x) = \\frac{p(x|y) p(y)}{p(x)} = \\frac{p(x|y) p(y)}{\\sum_{y\\in\\mathcal{Y}} p(x|y) p(y)}\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "- $p(y)$ es la probabilidad *a priori*, corresponde a lo que sabemos antes de observar el ejemplo\n",
    "- $p(y|x)$ es la probabilidad *a posteriori*, corresponde a lo que sabemos luego de observar el ejemplo $x$\n",
    "- $p(x|y)$ es la verosimilitud de observar un ejemplo con atributos $x$ suponiendo que la etiqueta es $y$\n",
    "\n",
    "Si tenemos un problema de clasificación binario, es decir con dos etiquetas, podemos escribir\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x)}{p(y=0|x)} = \\frac{p(x|y=1) p(y=1)}{p(x|y=0) p(y=0)}\n",
    "$$\n",
    "\n",
    "Si el cociente anterior es mayor que $1$ entonces la clase de $x$ es $1$, de lo contrario es $0$. Si tenemos un problema de clasificación con $C$ clases entonces decidimos la clase con\n",
    "\n",
    "$$\n",
    "\\hat y = \\text{arg}\\max_{k=1,\\ldots,C} p(x|y=k) p(y=k)\n",
    "$$\n",
    "\n",
    "En ambos casos el denominador del teorema de Bayes no se ocupa, pues es idéntico para todo $y$. Por otro lado el prior generalmente se estima empíricamente a partir de nuestra base de datos de entrenamiento como\n",
    "\n",
    "$$\n",
    "p(y=k) = \\frac{\\text{Cantidad de ejemplos con etiqueta k}}{\\text{Cantidad de ejemplos}}\n",
    "$$\n",
    "\n",
    "En términos prácticos la principal ventaja de este clasificador es que es simple, fácil de entrenar y muy difícil de sobreajustar. Su desventaja es que hace supuestos muy fuertes sobre los datos. Si no se cumplen el desempeño no será bueno. A continuación revisaremos en detalle estos supuestos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos del clasificador bayesiano \"ingenuo\"\n",
    "\n",
    "Digamos que $x$ es un vector que representa $D$ atributos. El primer supuesto de este modelo es que los atributos usados en el clasificador **son independientes**. Por lo tanto la verosimilitud se puede escribir como\n",
    "\n",
    "$$\n",
    "p(x|y) = \\prod_{d=1}^D p(x_d|y)\n",
    "$$\n",
    "\n",
    "En segundo lugar se debe suponer una distribución para los atributos. Por ejemplo si asumimos una distribución Gaussiana \n",
    "\n",
    "$$\n",
    "p(x_d|y) = \\mathcal{N}(\\mu_d, \\sigma_d^2)\n",
    "$$\n",
    "\n",
    "se tiene un clasificador bayesiano ingenuo con verosimilitud Gaussiana\n",
    "\n",
    "Se pueden suponer otras distribuciones dependiendo de los datos\n",
    "\n",
    "- La distribución Gaussiana es típicamente usada para atributos continuos\n",
    "- Para atributos discretos se puede usar la distribución multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Clasificación de biopsias con modelo implementado desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo implementaremos un clasificador bayesiano ingenuo con verosimilitud gaussiana desde cero y lo entrenaremos usando el dataset de [cancer de mama de la Universidad de Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic). \n",
    "\n",
    "Para este ejemplo usaremos dos atributos por paciente\n",
    "\n",
    "- x: radio de la muestra (continua)\n",
    "- z: textura de la muestra (continua)\n",
    "\n",
    "Adicionalmente la variable $y$ se refiere a la etiqueta de la muestra. El dataset tiene 569 pacientes, 212 con tumores malignos (1) y 357 tumores benignos (0)\n",
    "\n",
    "Importemos los datos y analicemos un gráfico de dispersión de los atributos. Reflexione ¿Son los datos separables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:09.682602Z",
     "start_time": "2020-08-18T03:34:09.372343Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/cancer.csv', index_col=0)\n",
    "x, y = df.drop(columns=\"diagnosis\").values, df[\"diagnosis\"].replace({'M':1, 'B':0}). values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Benigno', 'Maligno'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], s=20, marker=marker, label=label, alpha=0.5)\n",
    "ax.set_xlabel('Radio de la muestra')\n",
    "ax.set_ylabel('Textura de la muestra')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser un problema de clasificación binaria podemos escribir\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x, z)}{p(y=0|x, z)} = \\frac{p(x|y=1) p(z|y=1) p(y=1)}{p(x|y=0) p(z|y=0) p(y=0)}\n",
    "$$\n",
    "\n",
    "En primer lugar estiamos los *priors* en base a la frecuencia de casos benignos y malignos en el dataset, es decir\n",
    "\n",
    "$$\n",
    "p(y=1) = \\frac{212}{569} \\approx 0.41\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "p(y=0) = \\frac{357}{569} \\approx 0.59\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# Probabilidades a priori\n",
    "from collections import Counter\n",
    "print(Counter(y))\n",
    "py = [Counter(y)[i]/len(y) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sólo falta encontrar los parámetros $\\mu_x, \\sigma_x, \\mu_z, \\sigma_z$. Los podemos encontrar aplicando el criterio de máxima verosimilitud sobre una distribución normal univariada mediante `scipy.stats.norm.fit`\n",
    "\n",
    "El siguiente gráfico de contornos muestra el resultado del ajuste para las distribuciones de los pacientes sanos y con cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.250375Z",
     "start_time": "2020-08-18T03:34:09.685552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ajuste de verosimilitudes\n",
    "dists = {}\n",
    "for y_ in [0, 1]: # Para cada clase\n",
    "    for d in [0, 1]: # para cada característica\n",
    "        params = scipy.stats.norm.fit(x[y==y_, d])\n",
    "        dists[(y_, d)] = scipy.stats.norm(loc=params[-2], scale=params[-1])\n",
    "\n",
    "def verosimilitud_y_cociente(x, z):\n",
    "    pxzy0 = dists[(0, 0)].pdf(x)*dists[(0, 1)].pdf(z)\n",
    "    pxzy1 = dists[(1, 0)].pdf(x)*dists[(1, 1)].pdf(z)\n",
    "    return pxzy0, pxzy1, (pxzy1*py[1])/(pxzy0*py[0] + 1e-8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Benigno', 'Maligno'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], c='k', s=20, \n",
    "               marker=marker, label=label, alpha=0.5)\n",
    "\n",
    "x_plot = np.linspace(np.amin(x[:, 0]), np.amax(x[:, 0]), num=500)\n",
    "z_plot = np.linspace(np.amin(x[:, 1]), np.amax(x[:, 1]), num=500)\n",
    "X, Z = np.meshgrid(x_plot, z_plot)\n",
    "Y = verosimilitud_y_cociente(X, Z)\n",
    "ax.contour(X, Z, Y[0], zorder=-1, cmap=plt.cm.Reds, levels=20)\n",
    "ax.contour(X, Z, Y[1], zorder=-1, cmap=plt.cm.Blues, levels=20)\n",
    "ax.set_xlim([np.amin(x_plot), np.amax(x_plot)])\n",
    "ax.set_ylim([np.amin(z_plot), np.amax(z_plot)])\n",
    "ax.set_xlabel('Radio de la muestra (x)')\n",
    "ax.set_ylabel('Textura de la muestra (z)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último paso consiste en decidir entre benigno y maligno usando el cociente entre los posterior\n",
    "\n",
    "En el caso binario es típico usar una regla como la siguiente\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x, z)}{p(y=0|x, z)} > R\n",
    "$$\n",
    "\n",
    "donde $R$ es un \"umbral de clasificación\". El siguiente gráfico muestra las fronteras de decisión usando cuatro umbrales distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.279776Z",
     "start_time": "2020-08-18T03:34:10.253868Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 4), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Benigno', 'Maligno'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], c='k', s=20, \n",
    "               marker=marker, label=label, alpha=0.5)\n",
    "\n",
    "cp = ax.contour(X, Z, Y[2] ,  levels=[0.1, 0.5, 1., 1.5], cmap=plt.cm.tab10);\n",
    "ax.clabel(cp, fontsize=15, fmt='%0.1f', manual=[(9.0, 35), (9.0, 30), (9.0, 22), (12.5, 35)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos \"ajustar\" el riesgo $R$ para controlar el compromiso (trade-off) entre los siguientes tipos de errores\n",
    "\n",
    "1. Falso positivo: Predecir que el paciente está enfermo $\\hat y=1$ cuando en realidad estaba sano $y=0$\n",
    "1. Falso negativo: Predecir que el paciente está sano $\\hat y=0$ cuando en realidad estaba enfermo $y=1$\n",
    "\n",
    "Reflexione: En un problema de índole médico como el que acabamos de revisar ¿Cuáles son las repercusiones de cada uno de estos errores? ¿Cuál es más grave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La librería `scikit-learn`\n",
    "\n",
    "La librería de Python [scikit-learn](https://scikit-learn.org) tiene una amplia selección de \n",
    "\n",
    "- clasificadores y regresores\n",
    "- utilitarios para preprocesar y particionar los datos\n",
    "- métricas y gráficas de evaluación\n",
    "\n",
    "entre otros. Puedes instalarla en tu ambiente conda con\n",
    "\n",
    "    conda install scikit-learn\n",
    "\n",
    "A continuación utilizaremos el módulo [`sklearn.naive_bayes`](https://scikit-learn.org/stable/modules/naive_bayes.html) que implementa distintos clasificadores bayesianos ingenuos, entre ellos\n",
    "\n",
    "- Clasificador con verosimilitud Gaussiana: `GaussianNB`\n",
    "- Clasificador con verosimilitud Multinomial: `MultinomialNB`\n",
    "\n",
    "Por ejemplo el constructor de `GaussianNB` es\n",
    "\n",
    "```python\n",
    "sklearn.naive_bayes.GaussianNB(priors=None, # Un ndarray con las probabilidades a priori\n",
    "                               ...\n",
    "                              )\n",
    "```\n",
    "\n",
    "y los métodos más importantes de este modelo (y otros de scikit-learn) son\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(xe, ye) # Ajusta un modelo a los datos y etiquetas\n",
    "pyv = clf.predict_proba(xv) # Retorna la probabilidad de cada clase \n",
    "yv = clf.predict(xv) # Retorna la clase predicha (la de máxima probabilidad)\n",
    "clf.score(xv, yv) # Retorna la precisión (accuracy) promedio del modelo\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos lo aprendido para entrenar el clasificador bayesiano en los datos del ejemplo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB(priors=py) #Usamos los priors calculados antes\n",
    "clf.fit(x[:, :2], y) # Entrenamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos uar el método `predict_proba` para visualizar la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.609933Z",
     "start_time": "2020-08-18T03:34:10.282585Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 4), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Sanos', 'Cancer'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], c='k', s=20, \n",
    "               marker=marker, label=label, alpha=0.5)\n",
    "\n",
    "Y = clf.predict_proba(np.stack((X.ravel(), Z.ravel())).T)[:, 1]\n",
    "#Y = clf.predict(np.stack((X.ravel(), Z.ravel())).T)\n",
    "\n",
    "cf = ax.contourf(X, Z, np.reshape(Y, X.shape), zorder=-1, cmap=plt.cm.RdBu, vmin=0, vmax=1, levels=20, alpha=0.75)\n",
    "ax.set_xlim([np.amin(x_plot), np.amax(x_plot)])\n",
    "ax.set_ylim([np.amin(z_plot), np.amax(z_plot)])\n",
    "ax.set_xlabel('Radio de la muestra (x)')\n",
    "ax.set_ylabel('Textura de la muestra (z)')\n",
    "plt.colorbar(cf)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación veremos como evaluar de manera cuantitativa el desempeño de un modelo clasificador. \n",
    "\n",
    "### Matriz o tabla de confusión\n",
    "\n",
    "Una matriz o tabla de confusión se construye contando los casos que tienen etiqueta real igual a $i$ y etiqueta predicha igual a $j$ para $i \\wedge j=1,2,\\ldots,C$ donde $C$ es el número de clases\n",
    "\n",
    "La siguiente imagen muestra una matriz de confusión para un problema de $10$ clases\n",
    "\n",
    "<img src=\"../img/conf-matrix.png\" width=\"500\">\n",
    "\n",
    "En una matriz de confusión general\n",
    "\n",
    "- los elementos de la diagonal representan las clasificaciones correctas\n",
    "- los elementos fuera de la diagonal representan las clasificaciones erroneas\n",
    "- las filas corresponden a las clases reales\n",
    "- las columnas corresponden a las clases predichas por el clasificador\n",
    "\n",
    "Ejemplo: En la imagen anterior tenemos $2$ ejemplos de clase \"4\" que fueron clasificados como clase \"1\" por el modelo\n",
    "\n",
    "\n",
    "En `scikit-learn` podemos calcular la matriz de confusión usando el módulo [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n",
    "Notar que la matriz de confusión requiere una etiqueta categórica, es decir no acepta probabilidades. Podemos convertir probabilidades en etiquetas categóricas usando `np.argmax(probs, axis=1)`. También podemos usar el método `predict` para obtener la predicción categórica directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.639329Z",
     "start_time": "2020-08-18T03:34:10.613323Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yhat = clf.predict(x[:, :2])\n",
    "cm = confusion_matrix(y,  # Etiqueta real\n",
    "                      yhat # Etiqueta predicha\n",
    "                     )\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos usar `plot_confusion_matrix` si deseamos producir una matriz de confusión como una figura de `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.717508Z",
     "start_time": "2020-08-18T03:34:10.641098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(clf, # Clasificador\n",
    "                      x[:, :2], # Datos\n",
    "                      y, # Etiquetas\n",
    "                      ax=ax, # subeje para gráficar\n",
    "                      display_labels=np.array(['Benigno', 'Maligno']), #Nombres de las clases\n",
    "                      cmap=plt.cm.Blues, # Escala de colores\n",
    "                      normalize=None #Permite escoger entre cantidades y porcentajes\n",
    "                     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intepretación: \n",
    "\n",
    "- Hay 17 casos predichos como maligno que en realidad eran benignos: **Falso positivo**\n",
    "- Hay 48 casos predichos como benignos que en realidad eran malignos: **Falso negativo**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas globales: Accuracy o exactitud\n",
    "\n",
    "El *accuracy* es una métrica de resumen que es útil para hacer una idea global de como funciona el clasificador. Es importante notar que el *accuracy* no reemplaza la tabla de confusión si no que se calcula a partir de la misma\n",
    "\n",
    "El *accuracy* se calcula como la cantidad de ejemplos predichos correctamente dividido por la cantidad total de ejemplos y es un valor en el rango $[0, 1]$. Por definición corresponde a la suma de la diagonal de la matriz de confusión dividido por el total de ejemplos\n",
    "\n",
    "Podemos calcular el *accuracy* de nuestro modelo con `scikit-learn` usando la función `accuracy_score` o el atributo `score` del modelo (si está disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.736321Z",
     "start_time": "2020-08-18T03:34:10.721042Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = clf.predict(x[:, :2])\n",
    "\n",
    "print(accuracy_score(y, yhat))\n",
    "\n",
    "print(clf.score(x[:, :2], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de desempeño\n",
    "\n",
    "La matriz de confusión y la exactitud son métricas que depende de un umbral de clasificación o punto de operación particular\n",
    "\n",
    "En problemas de clasificación binaria es mucho más informativo medir el desempeño utilizando curvas Receiver operating characteristic (ROC)\n",
    "\n",
    "Una curva ROC es la tasa de verdaderos positivos\n",
    "\n",
    "$$\n",
    "TPR = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "en función de la tasa de falsos positivos\n",
    "\n",
    "$$\n",
    "FPR = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "para distintos umbrales de clasificación $R$\n",
    "\n",
    "Podemos obtenerla de forma simple utilizando `sklearn.metrics.roc_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y, clf.predict_proba(x[:, :2])[:, 1])\n",
    "idx = np.where(tpr > 0.9)[0][0]\n",
    "print(f\"{fpr[idx]:0.4f}, {tpr[idx]:0.4f}, {thresholds[idx]:0.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.scatter(fpr[idx], tpr[idx], s=50, c='k')\n",
    "ax.set_xlabel('Tasa de falsos positivos')\n",
    "ax.set_ylabel('Tasa de verdaderos positivos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras más apegada esté la curva al punto TPR=1 y FPR=0, mejor será el modelo. La curva ROC nos permite estudiar todos los puntos de operación a la vez y seleccionar aquel que sea más adecuado para la tarea particular\n",
    "\n",
    "Por ejemplo la curva anterior nos dice que si usamos el umbral $R=0.2137$ (punto negro en la curva) tendremos una tasa de verdaderos positivos de ~91% y una tasa de falsos positivos de ~16%. Esto significa que en dicho punto de operación un ~9% de los pacientes que tienen un cancer maligno no serán pesquisados (falso negativo) mientras que un ~16%  de los pacientes que están sanos serán diagnosticados con cancer (falso positivo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio formativo\n",
    "\n",
    "Entrene un clasificador ingenuo usando esta vez todos los atributos y obtenga su matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.820155Z",
     "start_time": "2020-08-18T03:34:10.739247Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T02:27:59.871614Z",
     "start_time": "2020-08-18T02:27:59.868430Z"
    }
   },
   "source": [
    "## Clasificación usando árboles de decisión\n",
    "\n",
    "El árbol de decisión es una secuencia de operadores relacionales que actuan sobre los atributos y que se organizan como un árbol. El siguiente diagrama esquemático muestra un árbol de decisión (izquierda) que separa datos con dos atributos en dos clases (derecha)\n",
    "\n",
    "<img src=\"../img/ml-dt.png\" width=\"800\">\n",
    "\n",
    "- Los nodos \"hoja\" están asociados a una etiqueta o clase\n",
    "- Los nodos intermedios separan los datos (*splits*). \n",
    "\n",
    "Entrenar o ajustar el árbol consiste en seleccionar los *splits* (A y B en la figura). Antes de entrenar el usuario debe seleccionar algunos hiper-parámetros como la máxima profunidad del árbol o la métrica utilizada para optimizar los *splits*. \n",
    "\n",
    "Las métricas más típicas son la ganancia de información (diferencia entre entropías) y el índice de gini. Ambas miden la pureza del *split*. Un *split* es más puro si cada uno de los nodos hijo está asociado en mayor medida a una sola clase. Puedes profundizar en la teoría tras estás métricas en el siguiente [link](https://docs.google.com/presentation/d/1pxJk4cpI_gpvLhDi86EISHjggdyD95K6PgwKlJplkTg/) en lo que sigue nos enfocaremos en el entrenamiento y evaluación de árboles de decisión usando `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `scikit-learn` usamos el módulo [`tree`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree) que tiene árboles para clasificación y regresión. El constructor del árbol de decisión para clasificación es\n",
    "\n",
    "```python\n",
    "sklearn.tree.DecisionTreeClassifier(criterion='gini', # Criterio para separar un nodo 'gini' o 'entropy' \n",
    "                                    max_depth=None, # Profundidad máxima del árbol\n",
    "                                    max_leaf_nodes=None, # Cantidad máxima de nodos hoja\n",
    "                                    max_features=None, # Cuantos atributos considerar en cada separación\n",
    "                                    class_weight=None, # Ponderación de clase: \"balanced\" o None\n",
    "                                   ...\n",
    "                                   )\n",
    "```\n",
    "\n",
    "El árbol crecerá en complejidad mientras mayor sea `max_depth`. Si se deja como `None` entonces el árbol crecerá hasta que todos los nodos sean puros. \n",
    "\n",
    "Los métodos principales de `DecisionTreeClassifier` son `fit`, `predict_proba` y `predict` que tienen la misma interpretación que vimos anteriormente para el módulo `naive_bayes`\n",
    "\n",
    "A continuación veremos como calibrar un árbol de decisión usando validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada usando `scikit-learn`\n",
    "\n",
    "Como dijimos antes es fundamental hacer particiones del conjunto de datos para \n",
    "- escoger los hiperparámetros del modelo\n",
    "- evaluar posibles sobreajustes del modelo\n",
    "\n",
    "El módulo [`model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) nos da algunas funciones muy utiles para lograr este objetivo\n",
    "\n",
    "En particular cuando se tienen pocos datos es conveniente usar una estrategia de validación cruzada tipo K-Fold, como la que se ve en la figura\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
    "\n",
    "1. Primero se separa el conjunto en subconjuntos de entrenamiento y prueba\n",
    "1. El subconjunto de entrenamiento se separa en $K$ particiones \n",
    "1. Se entrena $K$ veces usando $K-1$ particiones y evaluando en la sobrante\n",
    "1. Podemos retornar promedio y desviación estándar de la correctitud del modelo\n",
    "\n",
    "El constructor de la clase `KFold` es\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.KFold(n_splits=5, # Número de particiones\n",
    "                              shuffle=False, # Barajar los datos antes de dividir\n",
    "                              random_state=None # Semilla aleatoria\n",
    "                             )\n",
    "```\n",
    "\n",
    "Esta clase y otras similares como `ShuffleSplit`, retornan un generador que podemos iterar como se muestra en el siguiente ejemplo\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, val_index in kf.split(x):\n",
    "    ...\n",
    "    model.fit(x[train_index], y[train_index])\n",
    "    model.score(x[val_index], y[val_index])\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibración del árbol de decisión usando  `KFold`\n",
    "\n",
    "Seleccionaremos el mejor valor del parámetro `max_depth` usando validación cruzada. En el siguiente ejemplo probaremos nueve valores distintos e imprimiremos la exactitud promedio y su desviación estándar. En este caso particular el mejor valor para ser $5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:11.262652Z",
     "start_time": "2020-08-18T03:34:10.822925Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "kf = KFold(n_splits=5) # 5 particiones\n",
    "\n",
    "for max_depth in range(1, 10): # para cada profundidad\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=1234)\n",
    "    # crear 5 splits\n",
    "    score = np.zeros(shape=(kf.get_n_splits(), ))\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(x)):\n",
    "        # entrenar en 4 \n",
    "        clf.fit(x[train_index], y[train_index])\n",
    "        # validar en 1 fold\n",
    "        score[i] = clf.score(x[valid_index], y[valid_index])\n",
    "    print(f\"profundidad {max_depth}:\\t correctitud: {np.mean(score):0.4f} +- {np.std(score):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibración del árbol de decisión usando  `GridSearchCV`\n",
    "\n",
    "Cuando la cantidad de parámetros crece la validación puede volverse un poco engorrosa. Podemos automatizar este proceso usando la clase `GridSearchCV` de `model_selection`. El constructor de esta clase es\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.GridSearchCV(estimator, # Modelo clasificador\n",
    "                                     param_grid, # Grilla de parámetros escrita como diccionario\n",
    "                                     scoring=None, # Función o métrica que se usará para evaluar el modelo\n",
    "                                     n_jobs=None, # Número de nucleos de CPU \n",
    "                                     cv=None, # Número de splits de validación cruzada\n",
    "                                     ...\n",
    "                                    )\n",
    "```\n",
    "\n",
    "Los atributos más importantes son\n",
    "\n",
    "- `fit(x, y)`: Entrena el estimador en los distintos splits y busca el mejor\n",
    "- `best_params_`: Retorna los mejores parámetros luego de que se ha hecho `fit`\n",
    "- `best_estimator_`: Retorna el mejor clasificador luego de que se ha hecho `fit`\n",
    "\n",
    "Por ejemplo para el caso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:11.934501Z",
     "start_time": "2020-08-18T03:34:11.264950Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ('entropy', 'gini'), \n",
    "          'max_depth': range(1, 10)}\n",
    "\n",
    "dts = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "dts.fit(x, y)\n",
    "\n",
    "print(dts.best_params_)\n",
    "\n",
    "print(dts.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente la matriz de confusión y la curva ROC del mejor árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:12.011297Z",
     "start_time": "2020-08-18T03:34:11.936969Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(dts.best_estimator_, x, y,\n",
    "                      ax=ax, display_labels=np.array(['Benigno', 'Maligno']), \n",
    "                      cmap=plt.cm.Blues, normalize=None);\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, dts.predict_proba(x)[:, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('Tasa de falsos positivos')\n",
    "ax.set_ylabel('Tasa de verdaderos positivos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de la lección\n",
    "\n",
    "En esta lección hemos aprendido a:\n",
    "\n",
    "- Describir conceptualmente un modelo de aprendizaje supervisado\n",
    "- Clasificar datos usando el clasificador bayesiano ingenuo\n",
    "- Clasificar datos usando árboles de decisión\n",
    "- Calibrar y evaluar modelos supervisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
