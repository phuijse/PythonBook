{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:00.076584Z",
     "start_time": "2020-08-25T02:51:00.063335Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo, Markdown, SVG, Code\n",
    "from functools import partial\n",
    "YouTubeVideo_formato = partial(YouTubeVideo, modestbranding=1, disablekb=0,\n",
    "                               width=640, height=360, autoplay=0, rel=0, showinfo=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:00.472669Z",
     "start_time": "2020-08-25T02:51:00.078566Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext cython\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación paralela en Python\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En las lecciones anteriores hemos visto como ganar rendimiento en operaciones SIMD usando NumPy. Luego aprendimos a conectar con lenguajes de bajo nivel usando Cython\n",
    "\n",
    "En esta lección veremos una opción para ganar rendimiento en problemas limitados en CPU que sean \"separables\". Un problema es **separable** si puede dividirse en **subproblemas** que pueden resolverse de forma **independiente**\n",
    "\n",
    "Al ser independientes significa que podemos resolverlos **al mismo tiempo**, es decir resolver cada uno sin esperar el resultado de los demás\n",
    "\n",
    "> Arquitectura de computadores: Hoy en día incluso los CPU de sobremesa son en realidad **múltiples CPU** unidos\n",
    "\n",
    "Es decir que\n",
    "\n",
    "> Podemos escribir programas que aprovechan los CPU multi-nucleo para resolver problemas separables en un menor tiempo\n",
    "\n",
    "Esto es lo que llamamos [**computación paralela**](https://computing.llnl.gov/tutorials/parallel_comp/#Whatis) y en la práctica muchos problemas de computación científica (modelamiento, simulación) son paralelizables o incluso \"masivamente paralelizables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumiendo que el problema al que nos enfrentamos es limitado en CPU el primer paso es hacer *profiling* para encontrar los cuellos de botella. Luego de esto debemos estudiar las zonas críticas y detectar oportunidades para paralelizar\n",
    "\n",
    "El objetivo de esto es encontrar sectores del programa que sean separables. Algunas preguntas típicas que pueden servir para esto son:\n",
    "\n",
    "- ¿Existen ciclos `for` donde las iteraciones son independientes entre si?\n",
    "- ¿Es posible descomponer la operación o los datos?\n",
    "- ¿Existe una estructura de tipo pipeline?\n",
    "\n",
    "Si alguna de estas respuestas es afirmativa entonces lo que resta es usar alguna herramienta de programación paralela para reescribir dicho sector del programa\n",
    "\n",
    "A continuación veremos algunas herramientas para Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Global interpreter lock (GIL) de Python\n",
    "\n",
    "El manejo de memoria de CPython no es *thread-safe*. Por esta razón todo código escrito en Python está sujeto a un **[mutex](https://en.wikipedia.org/wiki/Lock_(computer_science))** que lo proteje conocido como **Global Interpreter Lock (GIL)**\n",
    "\n",
    "El [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) obliga a ejecutar solo un hilo de código Python a la vez. Además el código escrito en Python no tiene control sobre el GIL. Por esta razón no es directo ni fácil que un proceso Python puedo usar múltiples nucleos de CPU\n",
    "\n",
    "En esta lección exploraremos dos alternativas generales\n",
    "\n",
    "- **1:** Realizar cómputo paralelo con **múltiples hilos** que comparten memoria. Para esto usaremos `cython` para levantar el GIL y las directivas de `OpenMP` para implementar este tipo de paralelismo\n",
    "- **2:** Realizar cómputo paralelo con **multiples procesos** (fork). En este escenario los procesos tiene su propio espacio de memoria y su propio GIL, por lo que no es necesario usar `cython`. En general el overhead es mucho mayor que en el caso **1**. Usaremos la librería `ipyparallel` para implementar este tipo de  paralelismo\n",
    "\n",
    "\n",
    "Existe una tercera alternativa más accesible pero exclusiva para hacer **algebra lineal en paralelo** con NumPy\n",
    "\n",
    "- **3:** Compilar NumPy contra una librería de álgebra lineal de alto rendimiento  como MKL, ATLAS, Openblas. Estas librerías usan código de bajo nivel que levanta el GIL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computación multi-hilo con Cython y OpenMP\n",
    "\n",
    "[OpenMP](https://www.openmp.org/) es una API multiplataforma para computación paralela en C, C++ y Fortran. Por ejemplo en C/C++ se puede escribir un `parallel for` usando directivas de compilador (pragma) de OpenMP \n",
    "\n",
    "```c\n",
    "#pragma omp parallel for\n",
    "for (i = 0; i < N; i++)\n",
    "    a[i] = 2 * i;\n",
    "```\n",
    "\n",
    "Cython tiene un modulo llamado [`parallel`](http://docs.cython.org/en/latest/src/userguide/parallelism.html) que usa OpenMP como backend. Para ocupar OpenMP desde Cython es necesario \n",
    "\n",
    "- instalar OpenMP en el sistema\n",
    "- compilar el código Cython con `--compile-args=-fopenmp --link-args=-fopenmp`\n",
    "\n",
    "El modulo provee tres funciones principales\n",
    "\n",
    "- `parallel(num_threads=None)`: Para crear un contexto de cómputo paralelo\n",
    "- `threadid()`: Para obtener la id del hilo\n",
    "- `prange([start,] stop[, step][, nogil=False][, schedule=None[, chunksize=None]][, num_threads=None])`: Un iterador similar `range` pero que implemente un ciclo `for` paralelo\n",
    "\n",
    "También se pueden usar funciones de OpenMP importando\n",
    "\n",
    "```cython\n",
    "cimport openmp\n",
    "```\n",
    "\n",
    "El principal requisito es que las funciones paralelas deben liberar el GIL. En Cython podemos liberar el GIL en una sección de código o en una función con el `keyword` [`nogil`](http://docs.cython.org/en/latest/src/userguide/external_C_code.html#nogil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Cálculo paralelo del kernel Gaussiano entre dos vectores\n",
    "\n",
    "El kernel Gaussiano se define como \n",
    "\n",
    "$$\n",
    "e^{-\\gamma (x-y)^2}\n",
    "$$\n",
    "\n",
    "En este ejemplo asumiremos $\\gamma=1$. Escribamos un código en Cython de referencia y otro paralelo con OpenMP para calcular esta función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código Cython de referencia es similar a lo que vimos la clase anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:16.202797Z",
     "start_time": "2020-08-25T02:51:08.490156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython -f -c=-O3 -c=-march=native\n",
    "cimport cython\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double exp (double)\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_cython(double [::1] x, double [::1] y, double [::1] z):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    for i in range(N):\n",
    "        z[i] = exp(-(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código paralelo realizaremos tres cambios\n",
    "\n",
    "- Modificamos la magia `%%cython` para compilar contra openmp \n",
    "- Agregamos `nogil` en las secciones paralelas. Todas las funciones llamadas en la sección paralela deben liberar el GIL \n",
    "- Importamos `cython.parallel.prange` para reemplazar el `range` original. En este caso especifiremos $4$ hilos en `prange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:23.325460Z",
     "start_time": "2020-08-25T02:51:16.206111Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force \n",
    "# Compilamos con directivas OpenMP\n",
    "cimport cython\n",
    "\n",
    "from cython.parallel import prange # Importamos prange\n",
    "\n",
    "cdef extern from \"math.h\" nogil: # Liberamos el GIL\n",
    "    double exp (double)\n",
    "        \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_openmp(double [::1] x, double [::1] y, double [::1] z):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    with nogil: # Liberamos el GIL\n",
    "        for i in prange(N, num_threads=4): # For paralelo con 4 hilos\n",
    "            z[i] = exp(-(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realiza un profiling en base a datos creados artificialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:24.926543Z",
     "start_time": "2020-08-25T02:51:23.330689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un vector grande\n",
    "N = 1000000\n",
    "x = np.random.randn(N)\n",
    "y = np.random.randn(N)\n",
    "z = np.empty_like(x)\n",
    "# Versión numpy\n",
    "%timeit -r10 -n3 z = np.exp(-(x-y)**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versión cython\n",
    "%timeit -r10 -n3 suma_vectores_cython(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versión cython con openmp\n",
    "%timeit -r10 -n3 suma_vectores_openmp(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente comprobamos que el resultado es idéntico al de NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:27.711680Z",
     "start_time": "2020-08-25T02:51:27.586990Z"
    }
   },
   "outputs": [],
   "source": [
    "z = np.empty_like(x)\n",
    "suma_vectores_openmp(x, y, z)\n",
    "np.allclose(np.exp(-(x-y)**2), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Fractal de Julia en paralelo con Cython y OpenMP\n",
    "\n",
    "A continuación se muestra una versión paralela del código cython para calcular el fractal de Julia de la lección anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:36.531711Z",
     "start_time": "2020-08-25T02:51:28.674620Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force \n",
    "import cython\n",
    "cimport numpy as npc\n",
    "import numpy as np\n",
    "\n",
    "from cython.parallel import prange # Importamos prange\n",
    "\n",
    "ctypedef npc.float32_t TIPOF_t\n",
    "ctypedef npc.int64_t TIPOI_t\n",
    "\n",
    "cdef TIPOI_t evaluate_z(TIPOF_t zi, TIPOF_t zr, int maxiters=50, TIPOF_t cr=-0.835, TIPOF_t ci=-0.2321) nogil:\n",
    "    cdef:\n",
    "        TIPOI_t nit = 0\n",
    "        TIPOF_t zi2 = zi**2\n",
    "        TIPOF_t zr2 = zr**2\n",
    "        \n",
    "    while zi2 + zr2 <= 4. and nit < maxiters:\n",
    "        zi = 2.*zr*zi + ci\n",
    "        zr = zr2 - zi2 + cr\n",
    "        zr2 = zr**2\n",
    "        zi2 = zi**2 \n",
    "        nit +=1\n",
    "    return nit\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def make_fractal_cython(int N, TIPOI_t [:, ::1] image_view, int maxiters=50):\n",
    "    cdef:\n",
    "        Py_ssize_t i, j\n",
    "    for i in range(N):\n",
    "        for j in range(2*N):\n",
    "            image_view[i, j] = evaluate_z(-1.+i*2./N, -2.+j*2./N, maxiters)\n",
    "            \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def make_fractal_openmp(int N, TIPOI_t [:, ::1] image_view, int maxiters=50):\n",
    "    cdef:\n",
    "        Py_ssize_t i, j\n",
    "    \n",
    "    with nogil:\n",
    "        for i in prange(N, num_threads=4):        \n",
    "            for j in range(2*N):\n",
    "                image_view[i, j] = evaluate_z(-1.+i*2./N, -2.+j*2./N, maxiters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiempos de cómputo para implementación serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "image_cython = np.empty(shape=(N, 2*N), dtype=np.int64)\n",
    "image_openmp = np.empty(shape=(N, 2*N), dtype=np.int64)\n",
    "\n",
    "%timeit -r3 -n1 make_fractal_cython(N, image_cython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e implementación paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r3 -n1 make_fractal_openmp(N, image_openmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:40.293042Z",
     "start_time": "2020-08-25T02:51:39.719845Z"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(image_cython, image_openmp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computación multi-proceso con IPython: *ipyparallel*\n",
    "\n",
    "[ipyparallel](https://ipyparallel.readthedocs.io/en/latest/) es un paquete independiente pero complementario de IPython para hacer computación multi-proceso\n",
    "\n",
    "**Instalación**\n",
    "\n",
    "Si tienes conda \n",
    "\n",
    "```bash\n",
    "conda install ipyparallel\n",
    "```\n",
    "\n",
    "Esto debería instalar en su ambiente los ejecutables  `ipcluster`, `ipcontroller` e `ipengine`. Adicionalmente, en las versiones más nuevas, se crea una pestaña llamada \"Ipython clusters\" en la interfaz de jupyter\n",
    "\n",
    "<img src=\"../img/ipyparallel1.png\" >\n",
    "\n",
    "Si la interfaz no se instaló de forma automática se puede usar el comando\n",
    "\n",
    "```bash\n",
    "ipcluster nbextension enable\n",
    "```    \n",
    "    \n",
    "**Conceptos y uso básico**\n",
    "\n",
    "*ipyparallel* considera varios elementos, los más importantes son:\n",
    "\n",
    "- Engine: Es el encargado de correr código. Es una extensión del kernel de IPython\n",
    "- Controller: Es una interfaz para comunicarnos con el/los engine/s. La conexión se hace a través del objeto `Client`\n",
    "\n",
    "Para iniciar un controlador de forma automática podemos abrir un terminal y escribir\n",
    "\n",
    "```bash\n",
    "ipcluster start -n 4\n",
    "```\n",
    "    \n",
    "o utilizar los controles que se encuentran en la pestaña \"IPython clusters\"\n",
    "\n",
    "<img src=\"../img/ipyparallel2.png\" >\n",
    "\n",
    "Con esto hemos creado un controlador y cuatro engines, todos en nuestra máquina (localhost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:18.447676Z",
     "start_time": "2020-08-25T02:53:18.424839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos ipyparallel\n",
    "import ipyparallel as ipp\n",
    "# Creamos la clase cliente\n",
    "rc = ipp.Client()\n",
    "# Verificamos que se hayan iniciado nuestro engines\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada engine tiene una id asociada. Para enviarle trabajo a los engines debemos crear una intefaz llamada [`View`](https://ipyparallel.readthedocs.io/en/latest/details.html#views)\n",
    "\n",
    "Existen dos tipos de `View`: [*Direct*](https://ipyparallel.readthedocs.io/en/latest/direct.html#) y [*Task*](https://ipyparallel.readthedocs.io/en/latest/task.html#)\n",
    "\n",
    "- La primera es controlada de forma explicita por el usuario\n",
    "- La segunda es controlada por el sistema para *balancear la carga*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviando trabajos usando interfaz Directa\n",
    "\n",
    "Una `View` de tipo *Direct* requiere que el usuario especifique los engines que va a usar. Esto se hace de forma similar a los *slices* en listas/ndarray\n",
    "\n",
    "Por ejemplo para crear una interfaz que utilice todas las engines, usamos `rc[:]`. En cambio si sólo queremos utilizar las dos primeras engines, usamos `rc[:2]`\n",
    "\n",
    "La vista puede crearse como bloqueante o no bloqueante (asíncrona) modificando el atributo booleano `block`. Una vista \"bloqueante\" espera a que el resultado de todos los engines sean retornado para devolver el control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:22.963090Z",
     "start_time": "2020-08-25T02:53:22.950721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos una view con\n",
    "dview = rc[:]\n",
    "# Por defecto es asíncrono (no bloqueante)\n",
    "dview.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos cambiarlo a ejecución síncrona (bloqueando) con\n",
    "dview.block = True\n",
    "dview.block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los trabajos se envían usando las funciones de la `View` directa\n",
    "\n",
    "- `apply`, `apply_sync`, `apply_async`: Ejecutan una función con argumentos\n",
    "- `map`, `map_sync`, `map_async`: Ejecutan una función sobre una secuencia\n",
    "    \n",
    "Los apellidos `sync`  y `async` cambian el flag del view momentaneamente\n",
    "\n",
    "- Cuando trabajamos en forma síncrona el resultado retorna al final de la ejecuación\n",
    "- Cuando trabajamos de forma asíncrona se retorna un objeto [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult) que puede ser consultado más tarde por el resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de Python en paralelo con `apply`\n",
    "\n",
    "Sea una función `f` podemos ejecutarla en todos los engines usando \n",
    "\n",
    "```python\n",
    "rc[:].apply(f, *args, **kwargs)\n",
    "```\n",
    "    \n",
    "En el siguiente ejemplo se ejecuta una función anónima en todos los engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.128480Z",
     "start_time": "2020-08-25T02:53:24.918389Z"
    }
   },
   "outputs": [],
   "source": [
    "dview.apply(lambda x, y: x+\" \"+y, x=\"Hola\", y=\"Mundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compartiendo módulos y datos con los engines\n",
    "\n",
    "Es importante tener claro que, al contrario del paralelismo multi-hilo, los procesos en los engines no comparten memoria y no ven las variables de nuestro entorno local\n",
    "\n",
    "Por ejemplo si queremos usar una función del módulo `os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.792436Z",
     "start_time": "2020-08-25T02:53:25.751401Z"
    }
   },
   "outputs": [],
   "source": [
    "#import os # Este import no lo ven los engines\n",
    "\n",
    "def funcion():\n",
    "    import os # Este si\n",
    "    return os.getpid() \n",
    "\n",
    "# Cada uno tiene un pid distinto\n",
    "dview.apply(funcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible precargar un módulo en todos los engines con la función `sync_imports()`. Los módulos cargados persisten en el entorno de los engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:26.376589Z",
     "start_time": "2020-08-25T02:53:26.302002Z"
    }
   },
   "outputs": [],
   "source": [
    "with dview.sync_imports(local=True): \n",
    "    import os\n",
    "# El módulo quedará importado también en nuestro ambiente local\n",
    "\n",
    "# Ahora ya no necesitamos importar os\n",
    "def funcion2(): \n",
    "    return os.getpid() \n",
    "\n",
    "dview.apply(funcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos limpiar las variables y módulos de los engines podemos usar el método con `clear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:27.265444Z",
     "start_time": "2020-08-25T02:53:26.990920Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limpiamos el entorno de las engines\n",
    "dview.clear()\n",
    "# Ahora el siguiente comando arrojará un NameError\n",
    "dview.apply(funcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traspasando datos a todos los engines\n",
    "\n",
    "Para enviar un objeto de Python que hayamos definido en el ambiente local podemos usar la función `push`. El objeto tiene que ser un diccionario\n",
    "\n",
    "Luego podemos usar `pull` si queremos extraer una variable remota\n",
    "\n",
    "Estas funciones tienen un atributo llamado `targets` que permite apuntar los objetos a un subconjunto de *engines*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:47.620805Z",
     "start_time": "2020-08-25T02:53:47.536661Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 100 # Esto no existe dentro de los engines\n",
    "\n",
    "dview.push({'a': a}) # Ahora está en todos los engines\n",
    "\n",
    "def funcion3(): \n",
    "    return a**2\n",
    "\n",
    "dview.apply(funcion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digamos que quiero recuperar la variable 'a' pero sólo de los dos primeros engines\n",
    "dview.pull('a', targets=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuyendo datos a los engines\n",
    "\n",
    "Si queremos distribuir datos en los engines podemos usar `scatter`. Esto sirve por ejemplo para procesar elementos de una lista en paralelo. `scatter` recibe un string con el nombre de la variable (tal como lo recibirá cada proceso) y un arreglo con los valores de la variable\n",
    "\n",
    "Para recuperar resultados a partir de los engine podemos usar `gather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:50.088066Z",
     "start_time": "2020-08-25T02:53:49.992261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Una lista con 7 elementos que será distribuida en los 4 engines usando scatter\n",
    "dview.scatter('c', np.array(range(10)))\n",
    "\n",
    "def funcion3(): \n",
    "    global y # Creo una variable en el workspace del engine\n",
    "    y = c**2 # Le doy un valor\n",
    "    return y\n",
    "\n",
    "display(dview.apply(funcion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperamos la salida con gather\n",
    "display(dview.gather('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible distribuir arreglos de NumPy usando `scatter`. Notar que los arreglos de NumPy no se copian, se traspasan *read-only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:51.158733Z",
     "start_time": "2020-08-25T02:53:51.084036Z"
    }
   },
   "outputs": [],
   "source": [
    "datos = np.random.randn(100, 100)\n",
    "dview.scatter('x', datos)\n",
    "\n",
    "def funcion4(): \n",
    "    # data[0, 0] = 0 # No podemos modificar los valores!\n",
    "    return x.shape\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "dview.apply(funcion4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos hacer modificaciones de los arreglos tenemos que hacer una copia local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.144846Z",
     "start_time": "2020-08-25T02:53:51.994725Z"
    }
   },
   "outputs": [],
   "source": [
    "datos = np.random.randn(1000, 1000)\n",
    "dview.scatter('x', datos)\n",
    "\n",
    "def funcion5(): \n",
    "    global x\n",
    "    if not x.flags.writeable:\n",
    "        x = x.copy()\n",
    "    x[0, 0] = 0 # No podemos hacer esto!\n",
    "    return x\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "datos = np.concatenate(dview.apply(funcion5))\n",
    "\n",
    "# Se modificaron los datos originales\n",
    "display(datos[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómputo paralelo con `map`\n",
    "\n",
    "La función *built-in* `map` de Python aplica una función sobre una secuencia de datos uno por uno. En general, si vemos un `map` en nuestro código, paralelizarlo es muy sencillo\n",
    "\n",
    "La librería `ipyparallel` provee una versión paralela de [`map`](https://ipyparallel.readthedocs.io/en/latest/api/ipyparallel.html#ipyparallel.DirectView.map) que se ocupa sobre una vista\n",
    "\n",
    "```python\n",
    "rc[:].map(f, *sequences, block=self.block)\n",
    "```   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.829710Z",
     "start_time": "2020-08-25T02:53:52.781655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map de Python\n",
    "resultado_serial = list(map(lambda x: x, range(32)))\n",
    "\n",
    "# Map de ipyparallel\n",
    "resultado_paralelo = dview.map(lambda x: x, range(32))\n",
    "\n",
    "# Resultados\n",
    "np.allclose(resultado_serial, resultado_paralelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entregar iteradores para más de un argumento. Los iteradores deben ser del mismo largo (de lo contrario la secuencia más corta manda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:53.747341Z",
     "start_time": "2020-08-25T02:53:53.695708Z"
    }
   },
   "outputs": [],
   "source": [
    "dview.map(lambda x, y, z: x + y + z, range(10), range(10), range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos una función con algunos argumentos escalares (no iterables) podemos usar partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:54.464361Z",
     "start_time": "2020-08-25T02:53:54.410831Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def function_args(x, y, gamma=1):\n",
    "    import numpy as np\n",
    "    return np.exp(-gamma*(x-y)**2)\n",
    "\n",
    "dview.map(partial(function_args, gamma=2), np.random.randn(10), np.random.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones remotas y paralelas con decoradores\n",
    "\n",
    "Podemos crear una función que es siempre ejecutada por los engines usando el decorador `remote`. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:55.347819Z",
     "start_time": "2020-08-25T02:53:55.302810Z"
    }
   },
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def funcion():\n",
    "    import os\n",
    "    return os.getpid()\n",
    "\n",
    "funcion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función se ejecutó en los cuatro engines sin llamar a `dview.apply` o `dview.map` explicitamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, si tenemos una función que trabaja sobre un arreglo de forma *element-wise* podemos usar el decorador `parallel` para distribuir su carga a los engines. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:56.265784Z",
     "start_time": "2020-08-25T02:53:56.223207Z"
    }
   },
   "outputs": [],
   "source": [
    "@dview.parallel(block = True)\n",
    "def funcion(x):\n",
    "    return x\n",
    "\n",
    "# Los datos se particionan en 4 grupos (uno por engine)\n",
    "# Los grupos no son todos del mismo tamaño\n",
    "funcion(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto también se pueden usar arreglos de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:57.585941Z",
     "start_time": "2020-08-25T02:53:56.868296Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.random((1000, 1000))\n",
    "\n",
    "@dview.parallel(block=True)\n",
    "def pmul(A,B):\n",
    "    return A*B\n",
    "\n",
    "(A*A == pmul(A,A)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado asíncronos\n",
    "\n",
    "El resultado asíncrono es un objeto de clase [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult). Sus funciones más relevantes son\n",
    "\n",
    "- `ready` : Retorna un booleano con el estado de la tarea\n",
    "- `get` : Retorna el resultado\n",
    "\n",
    "Así se lanza una tarea asíncrona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:58.322094Z",
     "start_time": "2020-08-25T02:53:58.263465Z"
    }
   },
   "outputs": [],
   "source": [
    "res_async = dview.map_async(lambda x: x**2, range(10))\n",
    "# ¿Está listo mi tarea?\n",
    "res_async.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Puedo hacer cómputo aquí mientras espero que termine mi tarea\n",
    "    if res_async.ready():\n",
    "        # Recupero el resultado\n",
    "        res = res_async.get()\n",
    "        break\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras funcionalidades de ipyparallel no vistas en esta lección\n",
    "\n",
    "- [Magias de ipyparallel](https://ipyparallel.readthedocs.io/en/latest/magics.html)\n",
    "- Balance de carga automático en ipyparallel con la [interfaz Task](https://ipyparallel.readthedocs.io/en/latest/task.html#)\n",
    "- [Dependencias entre procesos paralelos](https://ipyparallel.readthedocs.io/en/latest/dag_dependencies.html)\n",
    "\n",
    "\n",
    "También es posible conectar controladores y engines en distintas máquinas para hacer **computación distribuida** en base a [MPI](https://ipyparallel.readthedocs.io/en/latest/mpi.html)  usando [`ipengine` e `ipcontroller`](https://ipyparallel.readthedocs.io/en/latest/process.html#using-the-ipcontroller-and-ipengine-commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
