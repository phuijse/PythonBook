{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:00.076584Z",
     "start_time": "2020-08-25T02:51:00.063335Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo, Markdown, SVG, Code\n",
    "from functools import partial\n",
    "YouTubeVideo_formato = partial(YouTubeVideo, modestbranding=1, disablekb=0,\n",
    "                               width=640, height=360, autoplay=0, rel=0, showinfo=0)\n",
    "\n",
    "display(Markdown(filename='../../preamble.md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:00.472669Z",
     "start_time": "2020-08-25T02:51:00.078566Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Computación paralela\n",
    "\n",
    "En la clase pasada vimos como ganar rendimiento en operaciones SIMD usando NumPy\n",
    "\n",
    "También aprendimos a conectar con lenguaje de bajo nivel usando Cython\n",
    "\n",
    "Existe otra forma en que podemos ganar rendimiento en problemas que son \"limitados en CPU\"\n",
    "\n",
    "El requisito adicional es que estos problemas sean separables\n",
    "\n",
    "> Un problema es **separable** si puede dividirse en **subproblemas** que pueden resolverse de forma **independiente**\n",
    "\n",
    "Al ser independientes significa que podemos resolverlos **al mismo tiempo**, es decir resolver cada uno sin esperar el resultado de los demás\n",
    "\n",
    "> Arquitectura de computadores: Hoy en día incluso los CPU de sobremesa son en realidad **múltiples CPU** unidos\n",
    "\n",
    "Es decir que\n",
    "\n",
    "> Podemos escribir programas que aprovechan los CPU multi-nucleo para resolver problemas separables en un menor tiempo\n",
    "\n",
    "Esto es lo que llamamos [**computación paralela**](https://computing.llnl.gov/tutorials/parallel_comp/#Whatis)\n",
    "\n",
    "> En la práctica muchos problemas de computación científica (modelamiento, simulación) son paralelizables o incluso \"masivamente paralelizables\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralelizando una rutina\n",
    "\n",
    "Asumiendo que el problema al que nos enfrentamos es limitado en CPU el primer paso es \n",
    "\n",
    "> Hacer *profiling* para encontrar los cuellos de botella\n",
    "\n",
    "Luego de esto debemos\n",
    "\n",
    "> Estudiar las zonas críticas y detectar oportunidades para paralelizar\n",
    "\n",
    "El objetivo es encontrar sectores del programa que sean separables\n",
    "\n",
    "Algunas preguntas típicas que pueden servir para esto son:\n",
    "- ¿Existen ciclos `for` donde las iteraciones son independientes entre si?\n",
    "- ¿Es posible descomponer la operación o los datos?\n",
    "- ¿Existe una estructura de tipo pipeline?\n",
    "\n",
    "Si alguna de estas respuestas es afirmativa entonces lo que resta es usar alguna herramienta de programación paralela para reescribir dicho sector del programa\n",
    "\n",
    "A continuación veremos algunas herramientas para Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python y rendimiento | Parte 3\n",
    "\n",
    "En esta clase veremos distintas formas para paralelizar código escrito en Python\n",
    "\n",
    "Antes de empezar debemos estar al tanto de que\n",
    "\n",
    "> El manejo de memoria de CPython no es *thread-safe*\n",
    "\n",
    "Es por esto que todo código escrito en Python está sujeto a un **mutex** que lo proteje: **Global Interpreter Lock (GIL)**\n",
    "\n",
    "> El [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) obliga a ejecutar solo un hilo de código Python a la vez\n",
    "\n",
    "Además \n",
    "\n",
    "> El código escrito en Python no tiene control sobre el GIL\n",
    "\n",
    "Por esta razón no es directo ni fácil que un proceso Python puedo usar múltiples CPU\n",
    "\n",
    "En esta clase exploraremos dos alternativas generales\n",
    "\n",
    "> **1:** No manipular el GIL y usar **multiples procesos**: *ipyparallel* y *joblib*\n",
    "\n",
    "\n",
    "> **2:** Levantar el GIL con Cython y usar **múltiples hilos**: *openmp*, *joblib*\n",
    "\n",
    "\n",
    "Existe una tercera alternativa más accesible pero exclusiva para hacer **algebra lineal en paralelo** con NumPy\n",
    "\n",
    "> **3:** Compilar NumPy contra una librería de algebra lineal de alto rendimiento (MKL, ATLAS, Openblas)\n",
    "\n",
    "Estas librerías usan código de bajo nivel que levanta el GIL\n",
    "\n",
    "## Diferencias entre computación multi-proceso y multi-hilo\n",
    "\n",
    "- Multi-proceso: Levantar **varios procesos** de Python (fork)\n",
    "    - Los procesos tiene su propio espacio de memoria y su propio GIL\n",
    "- Multi-hilo: Levantar varios hilos en **un proceso** de Python\n",
    "    - Los hilos comparten memoria\n",
    "    - Los hilos no se pueden ejecutar en paralelo a menos de que levanten el GIL (Cython)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación multi-hilo con Cython y OpenMP\n",
    "\n",
    "[OpenMP](https://www.openmp.org/) es una API multiplataforma para computación paralela en C, C++ y Fortran\n",
    "\n",
    "Ejemplo: En C/C++ se puede escribir un `parallel for` usando directivas de compilador (pragma) de OpenMP \n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (i = 0; i < N; i++)\n",
    "        a[i] = 2 * i;\n",
    "\n",
    "Cython tiene un modulo llamado [`parallel`](http://docs.cython.org/en/latest/src/userguide/parallelism.html) que usa OpenMP como backend\n",
    "\n",
    "Para ocupar OpenMP desde Cython es necesario \n",
    "- instalar OpenMP en el sistema\n",
    "- compilar el código Cython con `--compile-args=-fopenmp --link-args=-fopenmp`\n",
    "\n",
    "El modulo provee tres funciones principales\n",
    "\n",
    "- prange([start,] stop[, step][, nogil=False][, schedule=None[, chunksize=None]][, num_threads=None]): Para escribir un `parallel for`\n",
    "- parallel(num_threads=None): Para crear un contexto de cómputo paralelo\n",
    "- threadid(): Para obtener la id del hilo\n",
    "\n",
    "También se pueden usar funciones de OpenMP importando\n",
    "\n",
    "    cimport openmp\n",
    "\n",
    "> El requisito es que las funciones paralelas deben liberar el GIL\n",
    "\n",
    "En Cython podemos liberar el GIL en una sección de código o en una función con el `keyword` llamado [`nogil`](http://docs.cython.org/en/latest/src/userguide/external_C_code.html#nogil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Cálculo paralelo del kernel Gaussiano entre dos vectores\n",
    "\n",
    "El kernel Gaussiano se define como \n",
    "\n",
    "$$e^{-\\gamma (x-y)^2}$$\n",
    "\n",
    "Asumiremos $\\gamma=1$\n",
    "\n",
    "Escribamos un código en Cython de referencia y otro paralelo con OpenMP para calcular esta función\n",
    "\n",
    "Primero cargamos la extensión Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:08.429548Z",
     "start_time": "2020-08-25T02:51:07.380960Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código Cython de referencia es similar a lo que vimos la clase anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:16.202797Z",
     "start_time": "2020-08-25T02:51:08.490156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython -f -c=-O3 -c=-march=native\n",
    "cimport cython\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double exp (double)\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_cython(double [::1] x, double [::1] y, double [::1] z):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    for i in range(N):\n",
    "        z[i] = exp(-(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código paralelo hacemos tres cambios\n",
    "\n",
    "- Modificamos la magia `%%cython` para compilar contra openmp \n",
    "- Agregamos `nogil` en las secciones paralelas\n",
    "    - Todas las funciones llamadas en la sección paralela deben liberar el GIL \n",
    "- Importamos `cython.parallel.prange` para reemplazar el `range` original\n",
    "\n",
    "Especificamos 4 hilos en `prange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:23.325460Z",
     "start_time": "2020-08-25T02:51:16.206111Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force \n",
    "# Compilamos con directivas OpenMP\n",
    "cimport cython\n",
    "\n",
    "from cython.parallel import prange # Importamos prange\n",
    "\n",
    "cdef extern from \"math.h\" nogil: # Liberamos el GIL\n",
    "    double exp (double)\n",
    "        \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def suma_vectores_openmp(double [::1] x, double [::1] y, double [::1] z):\n",
    "    cdef:\n",
    "        Py_ssize_t i\n",
    "        int N = x.shape[0]\n",
    "    with nogil: # Liberamos el GIL\n",
    "        for i in prange(N, num_threads=4): # For paralelo con 4 hilos\n",
    "            z[i] = exp(-(x[i] - y[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos datos artificiales y medimos los tiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:24.926543Z",
     "start_time": "2020-08-25T02:51:23.330689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un vector grande\n",
    "N = 1000000\n",
    "x = np.random.randn(N)\n",
    "y = np.random.randn(N)\n",
    "z = np.empty_like(x)\n",
    "# Tiempos de cómputo\n",
    "%timeit -r10 -n3 z = np.exp(-(x-y)**2)\n",
    "%timeit -r10 -n3 suma_vectores_cython(x, y, z)\n",
    "%timeit -r10 -n3 suma_vectores_openmp(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es idéntico al de NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:27.711680Z",
     "start_time": "2020-08-25T02:51:27.586990Z"
    }
   },
   "outputs": [],
   "source": [
    "z = np.empty_like(x)\n",
    "suma_vectores_openmp(x, y, z)\n",
    "np.allclose(np.exp(-(x-y)**2), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Fractal de Julia en paralelo con Cython y OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:36.531711Z",
     "start_time": "2020-08-25T02:51:28.674620Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force \n",
    "import cython\n",
    "cimport numpy as npc\n",
    "import numpy as np\n",
    "\n",
    "from cython.parallel import prange # Importamos prange\n",
    "\n",
    "ctypedef npc.float32_t TIPOF_t\n",
    "ctypedef npc.int64_t TIPOI_t\n",
    "\n",
    "cdef TIPOI_t evaluate_z(TIPOF_t zi, TIPOF_t zr, int maxiters=50, TIPOF_t cr=-0.835, TIPOF_t ci=-0.2321) nogil:\n",
    "    cdef:\n",
    "        TIPOI_t nit = 0\n",
    "        TIPOF_t zi2 = zi**2\n",
    "        TIPOF_t zr2 = zr**2\n",
    "        \n",
    "    while zi2 + zr2 <= 4. and nit < maxiters:\n",
    "        zi = 2.*zr*zi + ci\n",
    "        zr = zr2 - zi2 + cr\n",
    "        zr2 = zr**2\n",
    "        zi2 = zi**2 \n",
    "        nit +=1\n",
    "    return nit\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def make_fractal_cython(int N, TIPOI_t [:, ::1] image_view, int maxiters=50):\n",
    "    cdef:\n",
    "        Py_ssize_t i, j\n",
    "    for i in range(N):\n",
    "        for j in range(2*N):\n",
    "            image_view[i, j] = evaluate_z(-1.+i*2./N, -2.+j*2./N, maxiters)\n",
    "            \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def make_fractal_openmp(int N, TIPOI_t [:, ::1] image_view, int maxiters=50):\n",
    "    cdef:\n",
    "        Py_ssize_t i, j\n",
    "    \n",
    "    with nogil:\n",
    "        for i in prange(N, num_threads=4):        \n",
    "            for j in range(2*N):\n",
    "                image_view[i, j] = evaluate_z(-1.+i*2./N, -2.+j*2./N, maxiters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:51:40.293042Z",
     "start_time": "2020-08-25T02:51:39.719845Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "image_cython = np.empty(shape=(N, 2*N), dtype=np.int64)\n",
    "image_openmp = np.empty(shape=(N, 2*N), dtype=np.int64)\n",
    "%timeit -r3 -n1 make_fractal_cython(N, image_cython)\n",
    "%timeit -r3 -n1 make_fractal_openmp(N, image_openmp)\n",
    "np.allclose(image_cython, image_openmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación multi-proceso con IPython: *ipyparallel*\n",
    "\n",
    "[ipyparallel](https://ipyparallel.readthedocs.io/en/latest/) es un paquete independiente pero complementario de IPython para hacer computación multi-proceso\n",
    "\n",
    "## Instalación\n",
    "\n",
    "Si tienes conda \n",
    "\n",
    "    conda install ipyparallel\n",
    "    \n",
    "Esto debería instalar en tu ambiente los ejecutables  `ipcluster`, `ipcontroller` e `ipengine`\n",
    "\n",
    "Adicionalmente, en las versiones más nuevas, se crea una interfaz en la pestaña \"Ipython clusters\" del servidor jupyter llamada\n",
    "\n",
    "Si la interfaz no aparece, se puede forzar con\n",
    "    \n",
    "    ipcluster nbextension enable\n",
    "    \n",
    "    \n",
    "## Conceptos y uso básico\n",
    "\n",
    "*ipyparallel* considera varios elementos, los más importantes son:\n",
    "- Engine: Es el encargado de correr código. Es una extensión del kernel de IPython\n",
    "- Controller: Es una interfaz para comunicarnos con el/los engine/s. La conexión se hace a través del objeto `Client`\n",
    "\n",
    "Para iniciar un controlador de forma automática abrimos un terminal y escribimos\n",
    "\n",
    "    ipcluster start -n 4\n",
    "    \n",
    "o usamos los controles que se encuentran en la pestaña \"IPython clusters\" del servidor jupyter\n",
    "\n",
    "Con esto hemos creado un controlador y cuatro engines, todos en nuestra máquina (localhost)\n",
    "\n",
    "## Creación de un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:18.447676Z",
     "start_time": "2020-08-25T02:53:18.424839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos ipyparallel\n",
    "import ipyparallel as ipp\n",
    "# Creamos la clase cliente\n",
    "rc = ipp.Client()\n",
    "# Verificamos que se hayan iniciado nuestro engines\n",
    "display(rc.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada engine tiene una id asociada\n",
    "\n",
    "Para enviarle trabajo a los engines debemos crear una intefaz llamada [`View`](https://ipyparallel.readthedocs.io/en/latest/details.html#views)\n",
    "\n",
    "Existen dos tipos de `View`: [*Direct*](https://ipyparallel.readthedocs.io/en/latest/direct.html#) y [*Task*](https://ipyparallel.readthedocs.io/en/latest/task.html#)\n",
    "\n",
    "- La primera es controlada de forma explicita por el usuario\n",
    "- La segunda es controlada por el sistema para *balancear la carga*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviando  trabajos usando interfaz Directa\n",
    "\n",
    "Una `View` de tipo *Direct* requiere que el usuario especifique los engines que va a usar\n",
    "\n",
    "Esto se hace de forma similar a los *slices* en listas/ndarray\n",
    "\n",
    "\n",
    "Para crear una interfaz que utilice\n",
    "- todas las engines, usamos `rc[:]`    \n",
    "- las dos primeras engines, usamos `rc[:2]`\n",
    "\n",
    "La vista puede hacerse bloqueante o no bloqueante (asíncrona) modificando el atributo booleano `block`\n",
    "\n",
    "Una vista \"bloqueante\" espera a que el resultado de todos los engines sean retornado para devolver el control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:22.963090Z",
     "start_time": "2020-08-25T02:53:22.950721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos una view con\n",
    "dview = rc[:]\n",
    "# Por defecto es asíncrono (no bloqueante)\n",
    "display(dview.block)\n",
    "# Lo podemos cambiar con\n",
    "dview.block = True\n",
    "display(dview.block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los trabajos se envían usando las funciones de la `View` directa\n",
    "\n",
    "- `apply`, `apply_sync`, `apply_async`: Ejecutan una función con argumentos\n",
    "- `map`, `map_sync`, `map_async`: Ejecutan una función sobre una secuencia\n",
    "    \n",
    "Los apellidos `sync`  y `async` cambian el flag del view momentaneamente\n",
    "\n",
    "- Cuando trabajamos en forma síncrona el resultado retorna al final de la ejecuación\n",
    "- Cuando trabajamos de forma asíncrona se retorna un objeto [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult) que puede ser consultado más tarde por el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Python en paralelo con `apply`\n",
    "\n",
    "Se ocupa como \n",
    "\n",
    "    rc[:].apply(f, *args, **kwargs)\n",
    "\n",
    "    \n",
    "Por ejemplo usando una función anónima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.128480Z",
     "start_time": "2020-08-25T02:53:24.918389Z"
    }
   },
   "outputs": [],
   "source": [
    "dview.apply(lambda x, y: x+\" \"+y, x=\"Hola\", y=\"Mundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartiendo módulos y datos con los engines\n",
    "\n",
    "Es importante tener claro que\n",
    "\n",
    "> Los procesos en los engines no comparten memoria y no ven las variables de nuestro entorno local\n",
    "\n",
    "Por ejemplo si queremos usar una función del módulo `os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:25.792436Z",
     "start_time": "2020-08-25T02:53:25.751401Z"
    }
   },
   "outputs": [],
   "source": [
    "#import os # Este import no lo ven los engines\n",
    "\n",
    "def funcion():\n",
    "    import os # Este si\n",
    "    return os.getpid() \n",
    "\n",
    "# Cada uno tiene un pid distinto\n",
    "dview.apply(funcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos precargar un módulo en todos los engines con la función `sync_imports()` \n",
    "\n",
    "Los módulos se mantienen en el entorno de los engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:26.376589Z",
     "start_time": "2020-08-25T02:53:26.302002Z"
    }
   },
   "outputs": [],
   "source": [
    "with dview.sync_imports(local=True): \n",
    "    import os\n",
    "# El módulo quedará importado también en nuestro ambiente local\n",
    "\n",
    "# Ahora ya no necesitamos importar os\n",
    "def funcion2(): \n",
    "    return os.getpid() \n",
    "\n",
    "dview.apply(funcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos limpiar las variables y módulos de los engines con `clear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:27.265444Z",
     "start_time": "2020-08-25T02:53:26.990920Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limpiamos el entorno de las engines\n",
    "dview.clear()\n",
    "# Ahora esto ya no funciona\n",
    "dview.apply(funcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasando un dato a todos los engines\n",
    "\n",
    "Para enviar un objeto de Python que hayamos definido en el ambiente local podemos usar la función `push`\n",
    "\n",
    "El objeto tiene que ser un diccionario\n",
    "\n",
    "Luego podemos usar `pull` si queremos extraer una variable remota\n",
    "\n",
    "Estas funciones tienen el atributo `targets` que permite apuntar a un subconjunto de *engines*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:47.620805Z",
     "start_time": "2020-08-25T02:53:47.536661Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 100 # Esto no existe dentro de los engines\n",
    "\n",
    "dview.push({'a': a}) # Ahora está en todos los engines\n",
    "\n",
    "def funcion3(): \n",
    "    return a**2\n",
    "\n",
    "display(dview.apply(funcion3)) # Ahora la función retorna correctamente\n",
    "\n",
    "display(dview.pull('a', targets=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuyendo datos a los engines\n",
    "\n",
    "Si queremos distribuir datos en los engines podemos usar `scatter`\n",
    "\n",
    "Luego podemos recuperar su valor usando `gather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:50.088066Z",
     "start_time": "2020-08-25T02:53:49.992261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Una lista con 7 elementos que será distribuida en los 4 engines usando scatter\n",
    "dview.scatter('c', np.array(range(10)))\n",
    "\n",
    "\n",
    "def funcion3(): \n",
    "    global y # Creo una variable en el workspace del engine\n",
    "    y = c**2 # Le doy un valor\n",
    "    return y\n",
    "\n",
    "display(dview.apply(funcion3))\n",
    "\n",
    "# Recuperamos la salida con gather\n",
    "display(dview.gather('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible distribuir arreglos de NumPy\n",
    "\n",
    "> Los arreglos de NumPy no se copian, se traspasan *read-only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:51.158733Z",
     "start_time": "2020-08-25T02:53:51.084036Z"
    }
   },
   "outputs": [],
   "source": [
    "datos = np.random.randn(100, 100)\n",
    "dview.scatter('data', datos)\n",
    "\n",
    "def funcion4(): \n",
    "    # data[0, 0] = 0 # No podemos hacer esto!\n",
    "    return data.shape\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "display(dview.apply(funcion4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos hacer modificaciones inplace tenemos que hacer una copia local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.144846Z",
     "start_time": "2020-08-25T02:53:51.994725Z"
    }
   },
   "outputs": [],
   "source": [
    "datos = np.random.randn(1000, 1000)\n",
    "dview.scatter('data', datos)\n",
    "\n",
    "def funcion5(): \n",
    "    global data\n",
    "    if not data.flags.writeable:\n",
    "        data = data.copy()\n",
    "    data[0, 0] = 0 # No podemos hacer esto!\n",
    "    return data\n",
    "\n",
    "# Se particiona en 4 matrices por fila (row-major)\n",
    "datos = np.concatenate(dview.apply(funcion5))\n",
    "\n",
    "display(datos[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cómputo paralelo con `map`\n",
    "\n",
    "La función *built-in* `map` de Python aplica una función sobre una secuencia de datos uno por uno\n",
    "\n",
    "En general, si vemos un `map` en nuestro código, paralelizarlo es muy sencillo\n",
    "\n",
    "*ipyparallel* provee una versión paralela de [`map`](https://ipyparallel.readthedocs.io/en/latest/api/ipyparallel.html#ipyparallel.DirectView.map) que se ocupa sobre una vista\n",
    "\n",
    "    rc[:].map(f, *sequences, block=self.block)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:52.829710Z",
     "start_time": "2020-08-25T02:53:52.781655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map de Python\n",
    "resultado_serial = list(map(lambda x: x, range(32)))\n",
    "\n",
    "# Map de ipyparallel\n",
    "resultado_paralelo = dview.map(lambda x: x, range(32))\n",
    "\n",
    "# Resultados\n",
    "np.allclose(resultado_serial, resultado_paralelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entregar iteradores para más de un argumento\n",
    "\n",
    "Los iteradores deben ser del mismo largo (de lo contrario la secuencia más corta manda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:53.747341Z",
     "start_time": "2020-08-25T02:53:53.695708Z"
    }
   },
   "outputs": [],
   "source": [
    "dview.map(lambda x, y, z: x + y + z, range(10), range(10), range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos una función con algunos argumentos escalares podemos usar partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:54.464361Z",
     "start_time": "2020-08-25T02:53:54.410831Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_args(x, y, gamma=1):\n",
    "    import numpy as np\n",
    "    return np.exp(-gamma*(x-y)**2)\n",
    "\n",
    "dview.map(partial(function_args, gamma=2), np.random.randn(10), np.random.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones remotas con decoradores\n",
    "\n",
    "Podemos crear una función que es siempre ejecutada por los engines usando el decorador `remote`\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:55.347819Z",
     "start_time": "2020-08-25T02:53:55.302810Z"
    }
   },
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def funcion():\n",
    "    import os\n",
    "    return os.getpid()\n",
    "\n",
    "funcion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones paralelas con decoradores\n",
    "\n",
    "Si tenemos una función que trabaja sobre un arreglo de forma *element-wise* podemos usar el decorador `parallel` para distribuir su carga a los engines\n",
    "\n",
    "Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:56.265784Z",
     "start_time": "2020-08-25T02:53:56.223207Z"
    }
   },
   "outputs": [],
   "source": [
    "@dview.parallel(block = True)\n",
    "def funcion(x):\n",
    "    return x\n",
    "\n",
    "# Los datos se particionan en 4 grupos (uno por engine)\n",
    "# Los grupos no son todos del mismo tamaño\n",
    "funcion(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden usar arreglos de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:57.585941Z",
     "start_time": "2020-08-25T02:53:56.868296Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.random((10000, 1000))\n",
    "\n",
    "@dview.parallel(block=True)\n",
    "def pmul(A,B):\n",
    "    return A*B\n",
    "\n",
    "C_local = A*A\n",
    "\n",
    "C_remote = pmul(A,A)\n",
    "\n",
    "(C_local == C_remote).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado asíncrono\n",
    "\n",
    "El resultado asíncrono es un objeto de clase [`AsyncResult`](https://ipyparallel.readthedocs.io/en/latest/asyncresult.html#parallel-asyncresult)\n",
    "\n",
    "Luego podemos usar su función\n",
    "- `ready` : Retorna un booleano con el estado de la tarea\n",
    "- `get` : Retorna el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T02:53:58.322094Z",
     "start_time": "2020-08-25T02:53:58.263465Z"
    }
   },
   "outputs": [],
   "source": [
    "res_async = dview.map_async(lambda x: x, range(10))\n",
    "# Resultado asincrono\n",
    "display(res_async)\n",
    "# Está listo?\n",
    "display(res_async.ready())\n",
    "# Esperamos hasta que este listo y lo recuperamos\n",
    "while not res_async.ready():\n",
    "    res = res_async.get()\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tópicos extra\n",
    "\n",
    "- [Magias de ipyparallel](https://ipyparallel.readthedocs.io/en/latest/magics.html)\n",
    "- Balance de carga automático con la [interfaz Task](https://ipyparallel.readthedocs.io/en/latest/task.html#)\n",
    "- [Depedencias entre procesos paralelos](https://ipyparallel.readthedocs.io/en/latest/dag_dependencies.html)\n",
    "- Es posible conectar controladores y engines en distintas máquinas para hacer **computación distribuida** en base a [MPI](https://ipyparallel.readthedocs.io/en/latest/mpi.html)  usando [`ipengine` e `ipcontroller`](https://ipyparallel.readthedocs.io/en/latest/process.html#using-the-ipcontroller-and-ipengine-commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
