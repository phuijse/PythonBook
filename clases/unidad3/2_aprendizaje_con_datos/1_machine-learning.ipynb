{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:08.969501Z",
     "start_time": "2020-08-18T03:34:08.953765Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo, Markdown, SVG, Code\n",
    "from functools import partial\n",
    "YouTubeVideo_formato = partial(YouTubeVideo, modestbranding=1, disablekb=0,\n",
    "                               width=640, height=360, autoplay=0, rel=0, showinfo=0)\n",
    "\n",
    "display(Markdown(filename='../../preamble.md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:09.369300Z",
     "start_time": "2020-08-18T03:34:08.972688Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir *Machine Learning* o Aprendizaje de Máquinas como\n",
    "\n",
    "> El estudio de sistemas que aprenden reglas o patrones en base a ejemplos para resolver una tarea\n",
    "\n",
    "Donde\n",
    "\n",
    "- Máquina/Sistema: Algoritmo o modelo matemático que entrenamos en base a ejemplos y que mejora su desempeño a medida que recibe más ejemplos\n",
    "- Ejemplos: Datos y/o etiquetas asociados a la tarea que se quiere resolver\n",
    "\n",
    "Las tareas más típicas son\n",
    "- Clasificación: Identificar a que categoría corresponde el ejemplo\n",
    "- Regresión: Predecir una variable de interés en base al ejemplo\n",
    "- Agrupamiento (clustering): Encontrar grupos de ejemplos similares\n",
    "\n",
    "El esquema general de ML se muestra en la siguiente figura\n",
    "\n",
    "<img src=\"../img/intro-ml2.png\" width=\"700\">\n",
    "\n",
    "donde\n",
    "1. Conceptualización: Se refiere a identificar el problema\n",
    "1. Datos: Se refiere a la recolección, importación, pre-precesamiento y etiquetado de datos\n",
    "1. Modelamiento: Se referiere a la selección, entrenamiento y validación del o los modelos\n",
    "1. Inferencia: Se refiere a utilizar el modelo para inferir, predecir y/o tomar decisiones sobre ejemplos nuevos\n",
    "\n",
    "En este último punto yace el objetivo principal de ML\n",
    "\n",
    "> Entrenamos modelos para clasificar/predecir/agrupar ejemplos que el modelo no ha visto\n",
    "\n",
    "Para que el modelo sea útil debemos comprobar que es capaz de **generalizar lo aprendido**\n",
    "\n",
    "Para que el modelo sea capaz de aprender y generalizar ML combina técnicas de estadísticas y optimización computacional\n",
    "\n",
    "En este cuadernillo aprenderemos sobre uno de los paradigmas de Machine Learning: **Aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado: Conceptual\n",
    "\n",
    "En el paradigma de aprendizaje supervisado los datos de entrenamiento tienen asociado un **objetivo** \n",
    "\n",
    "El objetivo corresponde usualmente a una **etiqueta numérica** que un ser humano le asigna al dato. Este conocimiento *a priori* es lo que el algoritmo debe encapsular\n",
    "\n",
    "- Durante el entrenamiento la máquina recibe como entrada datos y etiquetas con tal de aprender reglas que los relacionen\n",
    "- Durante la inferencia la máquina usa las reglas para predecir la etiqueta en datos no vistos previamente\n",
    "\n",
    "Podemos comparar el paradigma de aprendizaje supervisado con el de programación tradicional en base a la siguiente figura\n",
    "\n",
    "<img src=\"../img/intro-ml1.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado: Matemático\n",
    "\n",
    "Formalmente, en este paradigma se busca aprender un mapeo o función paramétrica\n",
    "\n",
    "$$ \n",
    "f_{\\theta}: \\mathcal{X} \\rightarrow \\mathcal{Y}, \n",
    "$$\n",
    "\n",
    "donde $\\mathcal{X}$ es el dominio de nuestros datos e $\\mathcal{Y}$ es el dominio del objetivo\n",
    "\n",
    "Entrenamos nuestro modelo a partir de un conjunto de $N$ ejemplos:\n",
    "\n",
    "$$ \n",
    "\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\}, \n",
    "$$\n",
    "\n",
    "donde cada ejemplo es una tupla formada de datos $x_i \\in \\mathcal{X}$ y objetivo $y_i \\in \\mathcal{Y}$\n",
    "\n",
    "En el modelo anterior el vector $\\theta$ corresponde a los **parámetros del modelo**\n",
    "\n",
    "Luego\n",
    "\n",
    "> Aprender, entrenar o ajustar el modelo corresponde a encontrar el valor \"óptimo\" de $\\theta$\n",
    "\n",
    "Para medir el desempeño del modelo usamos una función de pérdida o costo: $L(\\theta)$ \n",
    "\n",
    "Usualmente esta función está relacionada al error de nuestro modelo en nuestro problema particular\n",
    "\n",
    "Luego\n",
    "\n",
    "> Minimizamos la función de costo para encontrar el valor óptimo $\\theta$\n",
    "\n",
    "Cuando hablamos de $\\theta$ \"óptimo\" lo decimos en el sentido de una función de costo particular\n",
    "\n",
    "### Datos\n",
    "\n",
    "La naturaleza de los datos depende del problema \n",
    "\n",
    "Lo más común es que los datos $x_i$ se estructuren como arreglos de $M$ componentes\n",
    "\n",
    "A los componentes los llamamos **atributos o características (features)**\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "Si la variable objetivo es\n",
    "\n",
    "- Continua: hablamos de un problema de regresión o aproximación de funciones\n",
    "- Categórica: hablamos de un problema de clasificación\n",
    "\n",
    "El ámbito de regresión ya fue estudiado en la unidad 2\n",
    "\n",
    "> En este cuadernillo nos concentraremos en el problema de clasificación y revisaremos algunos modelos clásicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complejidad y Sobreajuste\n",
    "\n",
    "En general mientras más parámetros tenga $f_\\theta$ más **flexible** será nuestro modelo\n",
    "\n",
    "Por un lado esto es bueno: Podremos aproximar funciones más **complejas**\n",
    "\n",
    "Pero por otro lado es malo: Si la flexibilidad es excesiva podríamos aprender nuestro ejemplos de memoria y perder capacidad de generalización\n",
    "\n",
    "Esto se conoce como **sobreajuste**\n",
    "\n",
    "En la siguiente figura las lineas naranja y azul representan dos modelos de clasificación\n",
    "\n",
    "<img src=\"../img/intro-ml3.png\" width=\"400\">\n",
    "\n",
    "\n",
    "El modelo naranjo ha aproximado los datos con cero error, es decir que \"se ha sobreajustado a los datos de entrenamiento\"\n",
    "\n",
    "Debemos considerar que los datos pueden tener ruido, por ende aproximarlos con una flexibilidad arbitrariamente grande nos llevará a \"aprender el ruido\". Luego el modelo sobreajustado predecirá muy mal los datos \"que no ha visto\"\n",
    "\n",
    "> El sobreajuste es inversamente proporcional a la capacidad de generalización\n",
    "\n",
    "Para evitar el problema de sobreajuste y calibrar el modelo realizamos procedimientos de **validación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación\n",
    "\n",
    "Para combatir el sobreajuste podemos usar estrategias de validación\n",
    "\n",
    "Consisten en separar el conjunto etiquetado en dos o más subconjuntos\n",
    "\n",
    "1. Validación tipo *Holdout*: Separamos el conjunto en tres: Entrenamiento, Validación y Prueba\n",
    "1. Validación cruzada: De tipo K-fold o *Leave one-out* (N-fold)\n",
    "\n",
    "Para que nuestros conjuntos de entrenamiento y validación sigan siendo representativos del total los debemos seleccionar aleatoriamente. Idealmente debemos preservar el balance de las clases, esto se llama hacer \"particiones estratíficadas\"\n",
    "\n",
    "Una vez que hemos separado el conjunto de datos podemos medir $L(\\theta)$ en cada uno\n",
    "\n",
    "- Optimizamos nuestro modelo minimizando el costo en el conjunto de entrenamiento\n",
    "- Seleccionamos los parámetros e hiper-parámetros que dan mínimo costo de validación\n",
    "- Comparamos distintas familias de modelos con el costo de prueba\n",
    "\n",
    "\n",
    "En general si un modelo\n",
    "- Tiene bajo costo de entrenamiento y de validación: Vamos por el buen camino\n",
    "- Tiene bajo costo de entrenamiento pero alto de validación: El modelo está sobreajustado\n",
    "- Tiene alto costo de entrenamiento y de validación: El modelo no es adecuado o hay un bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador Bayesiano \"Ingenuo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Este clasificador con interpretación probabilística busca \n",
    "\n",
    "> la probabilidad de la etiqueta $y$ dado el ejemplo $x$, es decir $P(y|x)$\n",
    "\n",
    "Usando el teorema de Bayes podemos escribir esto como\n",
    "\n",
    "$$\n",
    "p(y | x) = \\frac{p(x|y) p(y)}{p(x)} = \\frac{p(x|y) p(y)}{\\sum_{y\\in\\mathcal{Y}} p(x|y) p(y)}\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "- $p(y)$ es la probabilidad *a priori*, corresponde a lo que sabemos antes de observar el ejemplo\n",
    "- $p(y|x)$ es la probabilidad *a posteriori*, corresponde a lo que sabemos luego de observar el ejemplo $x$\n",
    "- $p(x|y)$ es la verosimilitud de observar un ejemplo con atributos $x$ suponiendo que la etiqueta es $y$\n",
    "\n",
    "Si tenemos un problema de clasificación binario, es decir con dos etiquetas, podemos escribir\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x)}{p(y=0|x)} = \\frac{p(x|y=1) p(y=1)}{p(x|y=0) p(y=0)}\n",
    "$$\n",
    "\n",
    "Si el cociente anterior es mayor que $1$ entonces la clase de $x$ es $1$, de lo contrario es $0$\n",
    "\n",
    "Si tenemos un problema de clasificación con $C$ clases entonces decidimos la clase con\n",
    "\n",
    "$$\n",
    "\\hat y = \\text{arg}\\max_{k=1,\\ldots,C} p(x|y=k) p(y=k)\n",
    "$$\n",
    "\n",
    "En ambos casos el denominador del teorema de Bayes no se ocupa, pues es idéntico para todo $y$\n",
    "\n",
    "El prior lo podemos estimar empiricamente de nuestra base de datos de entrenamiento como\n",
    "\n",
    "$$\n",
    "p(y=k) = \\frac{\\text{Cantidad de ejemplos con etiqueta k}}{\\text{Cantidad de ejemplos}}\n",
    "$$\n",
    "\n",
    "\n",
    "- La principal ventaja de este clasificador es que es simple, fácil de entrenar y muy dificil de sobreajustar\n",
    "- La desventaja, como veremos a continuación, es que hace supuestos muy fuertes. Si no se cumplen el desempeño no será bueno\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supuestos\n",
    "\n",
    "Digamos que $x$ es un vector que representa $D$ atributos\n",
    "\n",
    "### Primer supuesto\n",
    "\n",
    "Los atributos usados en el clasificador son independientes\n",
    "\n",
    "Por lo tanto la verosimilitud\n",
    "\n",
    "$$\n",
    "p(x|y) = \\prod_{d=1}^D p(x_d|y)\n",
    "$$\n",
    "\n",
    "### Segundo supuesto\n",
    "\n",
    "La distribución de los atributos es Gaussiana\n",
    "\n",
    "$$\n",
    "p(x_d|y) = \\mathcal{N}(\\mu_d, \\sigma_d^2)\n",
    "$$\n",
    "\n",
    "En este caso tenemos un clasificador bayesiano ingenuo con verosimilitud Gaussiana\n",
    "\n",
    "Se pueden suponer otras distribuciones dependiendo de los datos\n",
    "\n",
    "- La distribución Gaussiana puede usarse si los atributos son continuos\n",
    "- Para atributos discretos se puede usar la distribución multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de cancer \"a mano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset de cancer de mama de la Universidad de Wisconsin\n",
    "\n",
    "Representaremos cada paciente como\n",
    "- x: radio de la muestra (continua)\n",
    "- z: textura de la muestra (continua)\n",
    "- y: etiqueta de la muestra \n",
    "\n",
    "El dataset tiene 569 pacientes, 212 con tumores malignos (1) y 357 tumores benignos (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:09.682602Z",
     "start_time": "2020-08-18T03:34:09.372343Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/cancer.csv', index_col=0)\n",
    "x, y = df.drop(columns=\"diagnosis\").values, df[\"diagnosis\"].replace({'M':1, 'B':0}). values\n",
    "fig, ax = plt.subplots(figsize=(7, 3), tight_layout=True)\n",
    "ax.scatter(x[y==0, 0], x[y==0, 1], c='k', s=10, marker='o', label='Sanos', alpha=0.5)\n",
    "ax.scatter(x[y==1, 0], x[y==1, 1], c='k', s=10, marker='x', label='Cancer', alpha=0.5)\n",
    "ax.set_xlabel('Radio de la muestra')\n",
    "ax.set_ylabel('Textura de la muestra')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos escribir\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x, z)}{p(y=0|x, z)} = \\frac{p(x|y=1) p(z|y=1) p(y=1)}{p(x|y=0) p(z|y=0) p(y=0)}\n",
    "$$\n",
    "\n",
    "y los *priors* son: \n",
    "\n",
    "$$\n",
    "p(y=1) = \\frac{212}{569} \\approx 0.41\n",
    "$$\n",
    "\n",
    "y\n",
    "$$\n",
    "p(y=0) = \\frac{357}{569} \\approx 0.59\n",
    "$$\n",
    "\n",
    "Ahora sólo falta encontrar los parámetros $\\mu_x, \\sigma_x, \\mu_z, \\sigma_z$\n",
    "\n",
    "Los podemos encontrar usando el criterio de máxima verosimilitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.250375Z",
     "start_time": "2020-08-18T03:34:09.685552Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# Probabilidades a priori\n",
    "from collections import Counter\n",
    "print(Counter(y))\n",
    "py = [Counter(y)[i]/len(y) for i in range(2)]\n",
    "\n",
    "\n",
    "# Ajuste de verosimilitudes\n",
    "dists = {}\n",
    "for y_ in [0, 1]: # Para cada clase\n",
    "    for d in [0, 1]: # para cada característica\n",
    "        params = scipy.stats.norm.fit(x[y==y_, d])\n",
    "        dists[(y_, d)] = scipy.stats.norm(loc=params[-2], scale=params[-1])\n",
    "\n",
    "def likelihoods(x, z):\n",
    "    pxzy0 = dists[(0, 0)].pdf(x)*dists[(0, 1)].pdf(z)\n",
    "    pxzy1 = dists[(1, 0)].pdf(x)*dists[(1, 1)].pdf(z)\n",
    "    return pxzy0, pxzy1, (pxzy1*py[1])/(pxzy0*py[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Sanos', 'Cancer'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], c='k', s=10, \n",
    "               marker=marker, label=label, alpha=0.5)\n",
    "\n",
    "x_plot = np.linspace(np.amin(x[:, 0]), np.amax(x[:, 0]), num=500)\n",
    "z_plot = np.linspace(np.amin(x[:, 1]), np.amax(x[:, 1]), num=500)\n",
    "X, Z = np.meshgrid(x_plot, z_plot)\n",
    "Y = likelihoods(X, Z)\n",
    "ax.contourf(X, Z, Y[1] - Y[0], zorder=-1, cmap=plt.cm.RdBu, \n",
    "            vmin=-2e-2, vmax=2e-2, levels=20)\n",
    "ax.set_xlim([np.amin(x_plot), np.amax(x_plot)])\n",
    "ax.set_ylim([np.amin(z_plot), np.amax(z_plot)])\n",
    "ax.set_xlabel('Radio de la muestra (x)')\n",
    "ax.set_ylabel('Textura de la muestra (z)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos entre sano y enfermo usando el cociente entre los posterior\n",
    "\n",
    "$$\n",
    "\\frac{p(y=1|x, z)}{p(y=0|x, z)} > R\n",
    "$$\n",
    "\n",
    "Dos tipos de errores:\n",
    "1. Falso positivo: Predecir que está enfermo $\\hat y=1$ cuando en realidad estaba sano $y=0$\n",
    "1. Falso negativo: Predecir que está sano $\\hat y=0$ cuando en realidad estaba enfermo $y=1$\n",
    "\n",
    "Nosotros podemos \"ajustar\" el riesgo $R$ para reflejar la diferencia entre equivocarse con un FP o un FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.279776Z",
     "start_time": "2020-08-18T03:34:10.253868Z"
    }
   },
   "outputs": [],
   "source": [
    "ax.contour(X, Z, Y[2] > 1., zorder=-1, levels=[0]);\n",
    "#ax.contour(X, Z, Y[2] > 0.5, zorder=-1, levels=[0]);\n",
    "#ax.contour(X, Z, Y[2] > 0.1, zorder=-1, levels=[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con scikit-learn\n",
    "\n",
    "La librería de Python [scikit-learn](https://scikit-learn.org) tiene una amplia selección de \n",
    "\n",
    "- clasificadores y regresores\n",
    "- utilitarios para preprocesar y particionar los datos\n",
    "- métricas y gráficas de evaluación\n",
    "\n",
    "entre otros\n",
    "\n",
    "Puedes instalarla en tu ambiente conda con\n",
    "\n",
    "    conda install scikit-learn\n",
    "\n",
    "En particular existe un módulo [`sklearn.naive_bayes`](https://scikit-learn.org/stable/modules/naive_bayes.html) que implementa distintos clasificadores bayesianos ingenuos, entre ellos\n",
    "- Clasificador con verosimilitud Gaussiana: `GaussianNB`\n",
    "- Clasificador con verosimilitud Multinomial: `MultinomialNB`\n",
    "\n",
    "Por ejemplo el constructor de `GaussianNB`\n",
    "\n",
    "```python\n",
    "sklearn.naive_bayes.GaussianNB(priors=None, # Un ndarray con las probabilidades a priori\n",
    "                               ...\n",
    "                              )\n",
    "```\n",
    "\n",
    "Los atributos más importantes de este modelo (y otros de scikit-learn) son\n",
    "\n",
    "```python\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> clf = GaussianNB()\n",
    ">>> clf.fit(xe, ye) # Ajusta un modelo a los datos y etiquetas\n",
    ">>> pyv = clf.predict_proba(xv) # Retorna la probabilidad de cada clase \n",
    ">>> yv = clf.predict(xv) # Retorna la clase predicha (la de máxima probabilidad)\n",
    ">>> clf.score(xv, yv) # Retorna la precisión (accuracy) promedio del modelo\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de cancer con `scikit-learn`\n",
    "\n",
    "Usemos lo aprendido para entrenar el clasificador bayesiano en los datos de cancer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.609933Z",
     "start_time": "2020-08-18T03:34:10.282585Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB(priors=py) #Usamos los priors calculados antes\n",
    "clf.fit(x[:, :2], y) # Entrenamos\n",
    "\n",
    "# Visualizamos el resultado\n",
    "fig, ax = plt.subplots(figsize=(7, 3), tight_layout=True)\n",
    "for k, (label, marker) in enumerate(zip(['Sanos', 'Cancer'], ['o', 'x'])):\n",
    "    ax.scatter(x[y==k, 0], x[y==k, 1], c='k', s=10, \n",
    "               marker=marker, label=label, alpha=0.5)\n",
    "\n",
    "Y = clf.predict_proba(np.stack((X.ravel(), Z.ravel())).T)[:, 1]\n",
    "#Y = clf.predict(np.stack((X.ravel(), Z.ravel())).T)\n",
    "\n",
    "ax.contourf(X, Z, np.reshape(Y, X.shape), zorder=-1, cmap=plt.cm.RdBu, \n",
    "            vmin=0, vmax=1, levels=20)\n",
    "ax.set_xlim([np.amin(x_plot), np.amax(x_plot)])\n",
    "ax.set_ylim([np.amin(z_plot), np.amax(z_plot)])\n",
    "ax.set_xlabel('Radio de la muestra (x)')\n",
    "ax.set_ylabel('Textura de la muestra (z)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión\n",
    "\n",
    "Un clasificador se evalua tipicamente usando **matrices de confusión**\n",
    "\n",
    "Para esto se necesita la etiqueta real y la etiqueta predicha\n",
    "\n",
    "Si el clasificador retorna probabilidades podemos obtener la etiqueta predicha con `np.argmax(probs, axis=1)`\n",
    "\n",
    "Una matriz o tabla de confusión se construye contando los casos que tienen etiqueta real igual a $i$ y etiqueta predicha igual a $j$ para $i \\wedge j=1,2,\\ldots,C$ donde $C$ es el número de clases\n",
    "\n",
    "Podemos calcular la matriz de confusión usando el módulo [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.639329Z",
     "start_time": "2020-08-18T03:34:10.613323Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yhat = clf.predict(x[:, :2])\n",
    "cm = confusion_matrix(y,  # Etiqueta real\n",
    "                      yhat # Etiqueta predicha\n",
    "                     )\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo queremos visualizarla podemos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.717508Z",
     "start_time": "2020-08-18T03:34:10.641098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(clf, # Clasificador\n",
    "                      x[:, :2], # Datos\n",
    "                      y, # Etiquetas\n",
    "                      ax=ax, # subeje para gráficar\n",
    "                      display_labels=np.array(['Benigno', 'Maligno']), #Nombres de las clases\n",
    "                      cmap=plt.cm.Blues, # Escala de colores\n",
    "                      normalize=None #Permite escoger entre cantidades y porcentajes\n",
    "                     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde las filas corresponden a la etiqueta real y la columna a la etiqueta predicha\n",
    "\n",
    "Por ejemplo \n",
    "- Hay 17 casos predichos como maligno que en realidad eran benignos: **Falso positivo**\n",
    "- Hay 48 casos predichos como benignos que en realidad eran malignos: **Falso negativo**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy o correctitud\n",
    "\n",
    "El *accuracy* es una métrica de resumen que es útil para hacer una idea global de como funciona el clasificador\n",
    "\n",
    "El *accuracy* no reemplaza la tabla de confusión si no que se calcula a partir de la misma\n",
    "\n",
    "El *accuracy* se calcula como la cantidad de ejemplos predichos correctamente dividido por la cantidad total de ejemplos, es un valor en el rango $[0, 1]$\n",
    "\n",
    "Es decir la suma de la diagonal de la matriz de confusión dividido por el total de ejmplos\n",
    "\n",
    "Podemos calcular el *accuracy* de nuestro modelo con `scikit-learn` usando la función `accuracy_score` o el atributo `score` del modelo (si está disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.736321Z",
     "start_time": "2020-08-18T03:34:10.721042Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = clf.predict(x[:, :2])\n",
    "\n",
    "print(accuracy_score(y, yhat))\n",
    "\n",
    "print(clf.score(x[:, :2], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Entrene un clasificador ingenuo usando esta vez todos los atributos y obtenga su matriz de confusión\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:10.820155Z",
     "start_time": "2020-08-18T03:34:10.739247Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB(priors=py) \n",
    "clf.fit(x, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(clf,x, y, \n",
    "                      ax=ax, display_labels=np.array(['Benigno', 'Maligno']), \n",
    "                      cmap=plt.cm.Blues, normalize=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionando los datos\n",
    "\n",
    "Como dijimos antes es fundamental hacer particiones del conjunto de datos para \n",
    "- escoger los hiperparámetros del modelo\n",
    "- evaluar posibles sobreajustes del modelo\n",
    "\n",
    "El módulo [`model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) nos da algunas funciones muy utiles para lograr este objetivo\n",
    "\n",
    "En particular cuando se tienen pocos datos es conveniente usar una estrategia de validación cruzada tipo K-Fold, como la que se ve en la figura\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
    "\n",
    "1. Primero se separa el conjunto en subconjuntos de entrenamiento y prueba\n",
    "1. El subconjunto de entrenamiento se separa en $K$ particiones \n",
    "1. Se entrena $K$ veces usando $K-1$ particiones y evaluando en la sobrante\n",
    "1. Podemos retornar promedio y desviación estándar de la correctitud del modelo\n",
    "\n",
    "El constructor de la clase `KFold` \n",
    "\n",
    "```python\n",
    "sklearn.model_selection.KFold(m_splits=5, # Número de particiones\n",
    "                              shuffle=False, # Barajar los datos antes de dividir\n",
    "                              random_state=None # Semilla aleatoria\n",
    "                             )\n",
    "```\n",
    "\n",
    "Esta clase y otras similares como `ShuffleSplit`, retornan un generador que podemos iterar como\n",
    "\n",
    "```python\n",
    ">>> from sklearn.model_selection import KFold\n",
    ">>> kf = KFold(n_splits=10)\n",
    ">>> for train_index, val_index in kf.split(x):\n",
    ">>>     ...\n",
    ">>>     model.fit(x[train_index], y[train_index])\n",
    ">>>     model.score(x[val_index], y[val_index])\n",
    ">>>     ...\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T02:27:59.871614Z",
     "start_time": "2020-08-18T02:27:59.868430Z"
    }
   },
   "source": [
    "# Arbol de decisión\n",
    "\n",
    "\n",
    "El árbol de decisión es una secuencia de operadores relacionales que actuan sobre los atributos y que se organizan como un árbol\n",
    "- Los nodos \"hoja\" están asociados a una etiqueta (clasificación)\n",
    "- Los nodos intermedios separan los datos (splits)\n",
    "- Las separaciones se seleccionan usando la ganancia de información (entropy) o el índice de gini\n",
    "\n",
    "En `scikit-learn` usamos el módulo `tree` que tiene árboles para clasificación y regresión\n",
    "\n",
    "El constructor del árbol de decisión es\n",
    "\n",
    "```python\n",
    "sklearn.tree.DecisionTreeClassifier(criterion='gini', # Criterio para separar un nodo 'gini' o 'entropy' \n",
    "                                    max_depth=None, # Profunidad máxima del árbol\n",
    "                                    max_leaf_nodes=None, # Cantidad máxima de nodos hoja\n",
    "                                    max_features=None, # Cuantos atributos considerar en cada separación\n",
    "                                    class_weight=None, # Ponderación de clase: \"balanced\" o None\n",
    "                                   ...\n",
    "                                   )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el mejor árbol usando validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando  `KFold`\n",
    "\n",
    "Seleccionemos el mejor valor del parámetro `max_depth` usando validación cruzada\n",
    "\n",
    "Probaremos 9 valores distintos e imprimiremos la correctitud promedio y su desviación estándar\n",
    "\n",
    "En este caso el mejor valor para ser $5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:11.262652Z",
     "start_time": "2020-08-18T03:34:10.822925Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "kf = KFold(n_splits=5) # 5 particiones\n",
    "\n",
    "for max_depth in range(1, 10): # para cada profundidad\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=1234)\n",
    "    # crear 5 splits\n",
    "    score = np.zeros(shape=(kf.get_n_splits(), ))\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(x)):\n",
    "        # entrenar en 4 \n",
    "        clf.fit(x[train_index], y[train_index])\n",
    "        # validar en 1 fold\n",
    "        score[i] = clf.score(x[valid_index], y[valid_index])\n",
    "    print(f\"profundidad {max_depth}:\\t correctitud: {np.mean(score):0.4f} +- {np.std(score):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `GridSearchCV`\n",
    "\n",
    "Cuando la cantidad de parámetros crece la validación puede volverse un poco engorrosa\n",
    "\n",
    "Podemos automatizar este proceso usando la clase `GridSearchCV` de `model_selection`\n",
    "\n",
    "El constructor de esta clase\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.GridSearchCV(estimator, # Modelo clasificador\n",
    "                                     param_grid, # Grilla de parámetros escrita como diccionario\n",
    "                                     scoring=None, # Función o métrica que se usará para evaluar el modelo\n",
    "                                     n_jobs=None, # Número de nucleos de CPU \n",
    "                                     cv=None, # Número de splits de validación cruzada\n",
    "                                     ...\n",
    "                                    )\n",
    "```\n",
    "\n",
    "Los atributos más importantes son\n",
    "\n",
    "- `fit(x, y)`: Entrena el estimador en los distintos splits y busca el mejor\n",
    "- `best_params_`: Retorna los mejores parámetros luego de que se ha hecho `fit`\n",
    "- `best_estimator_`: Retorna el mejor clasificador luego de que se ha hecho `fit`\n",
    "\n",
    "Por ejemplo para el caso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:11.934501Z",
     "start_time": "2020-08-18T03:34:11.264950Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ('entropy', 'gini'), \n",
    "          'max_depth': range(1, 10)}\n",
    "\n",
    "dts = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "dts.fit(x, y)\n",
    "\n",
    "print(dts.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desempeño del mejor árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T03:34:12.011297Z",
     "start_time": "2020-08-18T03:34:11.936969Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(dts.best_estimator_, x, y,\n",
    "                      ax=ax, display_labels=np.array(['Benigno', 'Maligno']), \n",
    "                      cmap=plt.cm.Blues, normalize=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
