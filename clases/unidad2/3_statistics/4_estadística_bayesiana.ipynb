{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum a posteriori (MAP)\n",
    "\n",
    "- Hasta ahora nos hemos enfocado en la verosimilitud $p(\\mathcal{D}|\\theta)$\n",
    "- En realidad lo que más nos interesa es el *posterior* $p(\\theta|\\mathcal{D})$\n",
    "\n",
    "Bayes nos dice que\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}) = \\frac{p(\\mathcal{D}|\\theta)p(\\theta)}{p(\\mathcal{D})}\n",
    "$$\n",
    "\n",
    "El criterio MAP busca encontrar $\\theta$ que maximiza el posterior. \n",
    "\n",
    "Es decir la moda del posterior\n",
    "\n",
    "Usando el logaritmo para escribir\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg}\\max_\\theta \\log p(\\theta|\\mathcal{D}) \\nonumber \\\\\n",
    "&= \\text{arg}\\max_\\theta \\log p(\\mathcal{D}|\\theta) + \\log p(\\theta) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "donde omitimos la evidencia $p(\\mathcal{D})$ ya que no depende de $\\theta$\n",
    "\n",
    "- El criterio MAP consiste en maximizar la **verosimilitud** más el **prior**\n",
    "- Usamos el **prior** para agregar información sobre $\\theta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Regresión  con MAP\n",
    "\n",
    "Quiero modelar una regresión de $N$ parámetros\n",
    "$$\n",
    "\\begin{align}\n",
    "y_i = & \\Phi(x_i) \\theta + \\varepsilon_i \\nonumber \\\\\n",
    "&\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2) \\nonumber \\\\\n",
    "&y_i|\\theta \\sim \\mathcal{N}(\\Phi(x_i) \\theta, \\sigma_\\epsilon^2) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "es decir **verosimilitud** Gaussiana tal como antes\n",
    "\n",
    "Adicionalmente asumiremos que $p(\\theta) = \\mathcal{N}(0, \\sigma_\\theta^2)$, es decir **prior** Gaussiano\n",
    "\n",
    "El estimador MAP es \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta -\\frac{1}{2} \\log(2\\pi\\sigma_\\varepsilon^2) M - \\frac{1}{2\\sigma_\\varepsilon^2} \\sum_{i=1}^M (y_i - \\Phi(x_i) \\theta)^2 -\\frac{1}{2} \\log(2\\pi \\sigma_\\theta^2) N - \\frac{1}{2\\sigma_\\theta^2} \\sum_{j=1}^N \\theta_j^2 \\nonumber \\\\\n",
    "&= \\text{arg} \\min_\\theta  \\sum_{i=1}^M (y_i - \\Phi(x_i) \\theta)^2 + \\frac{\\sigma_\\varepsilon^2}{\\sigma_\\theta^2} \\sum_{j=1}^N \\theta_j^2 \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Reflexión\n",
    "- Si hay mucho ruido ($\\sigma_\\varepsilon^2 \\to \\infty$) entonces ignoro la verosimilitud y le creo al prior\n",
    "- Si uso un prior que no me da información ($\\sigma_\\theta^2 \\to \\infty$) entonces lo ignoro y me enfoco en la verosimilitud\n",
    "\n",
    "#### Relación con lo visto sobre regularización\n",
    "\n",
    "- Si decimos $\\lambda = \\frac{\\sigma_\\varepsilon^2}{\\sigma_\\theta^2}$ entonces la formulación es equivalente a Mínimos cuadrados regularizado, Ridge Regressión, Tikhonov!\n",
    "- Si hubieramos asumido una distribución Laplaciana para $p(\\theta)$ hubieramos obtenido el [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia Bayesiana\n",
    "\n",
    "- Asumimos que $\\theta$ es una variable aleatoria y que tiene cierta distribución\n",
    "- Buscamos estimar el posterior completo $p(\\theta|\\mathcal{D})$\n",
    "- El problema es que $p(\\mathcal{D})$ es generalmente incalculable\n",
    "- Para proseguir tenemos tres opciones\n",
    "    1. Usar distribuciones que sean conjugadas\n",
    "    1. Usar una aproximación (inferencia variacional)\n",
    "    1. Aprender un sistema que se comporte como el posterior (Markov Chain Monte Carlo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "temperatura, consumo = df[\"temperatura\"].values, df[\"consumo\"].values\n",
    "with pm.Model() as helados:\n",
    "    sigma = pm.HalfNormal('sigma', sd=10, shape=1)\n",
    "    theta0 = pm.Normal('intercept', mu=0, sd=10, shape=1)\n",
    "    theta1 = pm.Normal('slope', mu=0, sd=10, shape=1)\n",
    "    mu = temperatura*theta1 + theta0\n",
    "    x_observed = pm.Normal('x_obs', mu=mu, sd=sigma, observed=consumo)\n",
    "    trace = pm.sample(draws=500, tune=200, init='advi', n_init=30000, \n",
    "                      cores=4, chains=2, live_plot=False)\n",
    "display(pm.summary(trace))\n",
    "pm.traceplot(trace, figsize=(9, 6), combined=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre estos temas en el [repositorio de INFO337](https://github.com/magister-informatica-uach/INFO337/blob/master/MCMC/lecture.ipynb) del magíster de informática y en [Ipython](https://ipython-books.github.io/73-getting-started-with-bayesian-methods/) [cookbook](https://ipython-books.github.io/77-fitting-a-bayesian-model-by-sampling-from-a-posterior-distribution-with-a-markov-chain-monte-carlo-method/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUTURO\n",
    "\n",
    "Más sobre métodos de monte-carlo\n",
    "- https://towardsdatascience.com/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50\n",
    "- https://skymind.ai/wiki/markov-chain-monte-carlo\n",
    "- https://help.xlstat.com/customer/en/portal/articles/2062457-which-statistical-test-should-you-use-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
